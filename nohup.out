Using TensorFlow backend.
/home/mrahman/.local/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint8 = np.dtype([("qint8", np.int8, 1)])
/home/mrahman/.local/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint8 = np.dtype([("quint8", np.uint8, 1)])
/home/mrahman/.local/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint16 = np.dtype([("qint16", np.int16, 1)])
/home/mrahman/.local/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint16 = np.dtype([("quint16", np.uint16, 1)])
/home/mrahman/.local/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint32 = np.dtype([("qint32", np.int32, 1)])
/home/mrahman/.local/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  np_resource = np.dtype([("resource", np.ubyte, 1)])
/home/mrahman/.local/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint8 = np.dtype([("qint8", np.int8, 1)])
/home/mrahman/.local/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint8 = np.dtype([("quint8", np.uint8, 1)])
/home/mrahman/.local/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint16 = np.dtype([("qint16", np.int16, 1)])
/home/mrahman/.local/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint16 = np.dtype([("quint16", np.uint16, 1)])
/home/mrahman/.local/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint32 = np.dtype([("qint32", np.int32, 1)])
/home/mrahman/.local/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  np_resource = np.dtype([("resource", np.ubyte, 1)])
WARNING:tensorflow:From /home/mrahman/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.

WARNING:tensorflow:From /home/mrahman/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.

WARNING:tensorflow:From /home/mrahman/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.

WARNING:tensorflow:From /home/mrahman/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:3976: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.

WARNING:tensorflow:From /home/mrahman/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:4115: The name tf.random_normal is deprecated. Please use tf.random.normal instead.

WARNING:tensorflow:From /home/mrahman/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:2018: The name tf.image.resize_nearest_neighbor is deprecated. Please use tf.compat.v1.image.resize_nearest_neighbor instead.

__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
s_input (InputLayer)            (None, 28, 28, 1)    0                                            
__________________________________________________________________________________________________
conv2d_1 (Conv2D)               (None, 28, 28, 16)   160         s_input[0][0]                    
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 14, 14, 16)   0           conv2d_1[0][0]                   
__________________________________________________________________________________________________
conv2d_2 (Conv2D)               (None, 14, 14, 32)   2080        max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
max_pooling2d_2 (MaxPooling2D)  (None, 7, 7, 32)     0           conv2d_2[0][0]                   
__________________________________________________________________________________________________
flatten_1 (Flatten)             (None, 1568)         0           max_pooling2d_2[0][0]            
__________________________________________________________________________________________________
s_z_mean (Dense)                (None, 10)           15690       flatten_1[0][0]                  
__________________________________________________________________________________________________
s_z_log_var (Dense)             (None, 10)           15690       flatten_1[0][0]                  
__________________________________________________________________________________________________
s_z (Lambda)                    (None, 10)           0           s_z_mean[0][0]                   
                                                                 s_z_log_var[0][0]                
==================================================================================================
Total params: 33,620
Trainable params: 33,620
Non-trainable params: 0
__________________________________________________________________________________________________
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
t_input (InputLayer)            (None, 16, 16, 1)    0                                            
__________________________________________________________________________________________________
conv2d_5 (Conv2D)               (None, 16, 16, 16)   160         t_input[0][0]                    
__________________________________________________________________________________________________
max_pooling2d_3 (MaxPooling2D)  (None, 8, 8, 16)     0           conv2d_5[0][0]                   
__________________________________________________________________________________________________
conv2d_6 (Conv2D)               (None, 8, 8, 32)     2080        max_pooling2d_3[0][0]            
__________________________________________________________________________________________________
max_pooling2d_4 (MaxPooling2D)  (None, 4, 4, 32)     0           conv2d_6[0][0]                   
__________________________________________________________________________________________________
flatten_2 (Flatten)             (None, 512)          0           max_pooling2d_4[0][0]            
__________________________________________________________________________________________________
t_z_mean (Dense)                (None, 10)           5130        flatten_2[0][0]                  
__________________________________________________________________________________________________
t_z_log_var (Dense)             (None, 10)           5130        flatten_2[0][0]                  
__________________________________________________________________________________________________
z (Lambda)                      (None, 10)           0           t_z_mean[0][0]                   
                                                                 t_z_log_var[0][0]                
==================================================================================================
Total params: 12,500
Trainable params: 12,500
Non-trainable params: 0
__________________________________________________________________________________________________
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
s_input (InputLayer)            (None, 28, 28, 1)    0                                            
__________________________________________________________________________________________________
conv2d_1 (Conv2D)               (None, 28, 28, 16)   160         s_input[0][0]                    
__________________________________________________________________________________________________
t_input (InputLayer)            (None, 16, 16, 1)    0                                            
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 14, 14, 16)   0           conv2d_1[0][0]                   
__________________________________________________________________________________________________
conv2d_5 (Conv2D)               (None, 16, 16, 16)   160         t_input[0][0]                    
__________________________________________________________________________________________________
conv2d_2 (Conv2D)               (None, 14, 14, 32)   2080        max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
max_pooling2d_3 (MaxPooling2D)  (None, 8, 8, 16)     0           conv2d_5[0][0]                   
__________________________________________________________________________________________________
max_pooling2d_2 (MaxPooling2D)  (None, 7, 7, 32)     0           conv2d_2[0][0]                   
__________________________________________________________________________________________________
conv2d_6 (Conv2D)               (None, 8, 8, 32)     2080        max_pooling2d_3[0][0]            
__________________________________________________________________________________________________
flatten_1 (Flatten)             (None, 1568)         0           max_pooling2d_2[0][0]            
__________________________________________________________________________________________________
max_pooling2d_4 (MaxPooling2D)  (None, 4, 4, 32)     0           conv2d_6[0][0]                   
__________________________________________________________________________________________________
s_z_mean (Dense)                (None, 10)           15690       flatten_1[0][0]                  
__________________________________________________________________________________________________
s_z_log_var (Dense)             (None, 10)           15690       flatten_1[0][0]                  
__________________________________________________________________________________________________
flatten_2 (Flatten)             (None, 512)          0           max_pooling2d_4[0][0]            
__________________________________________________________________________________________________
s_z (Lambda)                    (None, 10)           0           s_z_mean[0][0]                   
                                                                 s_z_log_var[0][0]                
__________________________________________________________________________________________________
t_z_mean (Dense)                (None, 10)           5130        flatten_2[0][0]                  
__________________________________________________________________________________________________WARNING:tensorflow:From /home/mrahman/anaconda3/lib/python3.7/site-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.

WARNING:tensorflow:From /home/mrahman/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:3376: The name tf.log is deprecated. Please use tf.math.log instead.

WARNING:tensorflow:From /home/mrahman/.local/lib/python3.7/site-packages/tensorflow/python/ops/nn_impl.py:180: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use tf.where in 2.0, which has the same broadcast rule as np.where
2020-04-26 00:05:53.096255: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2000204999 Hz
2020-04-26 00:05:53.099177: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x5621310ceb90 executing computations on platform Host. Devices:
2020-04-26 00:05:53.099238: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>
2020-04-26 00:05:53.101391: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcuda.so.1
2020-04-26 00:05:53.121861: F tensorflow/stream_executor/lib/statusor.cc:34] Attempting to fetch value instead of handling error Internal: failed initializing StreamExecutor for CUDA device ordinal 0: Internal: failed call to cuDevicePrimaryCtxRetain: CUDA_ERROR_OUT_OF_MEMORY: out of memory; total memory reported: 12806062080
Using TensorFlow backend.
/home/mrahman/.local/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint8 = np.dtype([("qint8", np.int8, 1)])
/home/mrahman/.local/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint8 = np.dtype([("quint8", np.uint8, 1)])
/home/mrahman/.local/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint16 = np.dtype([("qint16", np.int16, 1)])
/home/mrahman/.local/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint16 = np.dtype([("quint16", np.uint16, 1)])
/home/mrahman/.local/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint32 = np.dtype([("qint32", np.int32, 1)])
/home/mrahman/.local/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  np_resource = np.dtype([("resource", np.ubyte, 1)])
/home/mrahman/.local/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint8 = np.dtype([("qint8", np.int8, 1)])
/home/mrahman/.local/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint8 = np.dtype([("quint8", np.uint8, 1)])
/home/mrahman/.local/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint16 = np.dtype([("qint16", np.int16, 1)])
/home/mrahman/.local/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint16 = np.dtype([("quint16", np.uint16, 1)])
/home/mrahman/.local/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint32 = np.dtype([("qint32", np.int32, 1)])
/home/mrahman/.local/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  np_resource = np.dtype([("resource", np.ubyte, 1)])
WARNING:tensorflow:From /home/mrahman/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.

WARNING:tensorflow:From /home/mrahman/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.

WARNING:tensorflow:From /home/mrahman/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.

WARNING:tensorflow:From /home/mrahman/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:3976: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.

WARNING:tensorflow:From /home/mrahman/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:4115: The name tf.random_normal is deprecated. Please use tf.random.normal instead.

WARNING:tensorflow:From /home/mrahman/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:2018: The name tf.image.resize_nearest_neighbor is deprecated. Please use tf.compat.v1.image.resize_nearest_neighbor instead.

__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
s_input (InputLayer)            (None, 28, 28, 1)    0                                            
__________________________________________________________________________________________________
conv2d_1 (Conv2D)               (None, 28, 28, 16)   160         s_input[0][0]                    
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 14, 14, 16)   0           conv2d_1[0][0]                   
__________________________________________________________________________________________________
conv2d_2 (Conv2D)               (None, 14, 14, 32)   2080        max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
max_pooling2d_2 (MaxPooling2D)  (None, 7, 7, 32)     0           conv2d_2[0][0]                   
__________________________________________________________________________________________________
flatten_1 (Flatten)             (None, 1568)         0           max_pooling2d_2[0][0]            
__________________________________________________________________________________________________
s_z_mean (Dense)                (None, 10)           15690       flatten_1[0][0]                  
__________________________________________________________________________________________________
s_z_log_var (Dense)             (None, 10)           15690       flatten_1[0][0]                  
__________________________________________________________________________________________________
s_z (Lambda)                    (None, 10)           0           s_z_mean[0][0]                   
                                                                 s_z_log_var[0][0]                
==================================================================================================
Total params: 33,620
Trainable params: 33,620
Non-trainable params: 0
__________________________________________________________________________________________________
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
t_input (InputLayer)            (None, 16, 16, 1)    0                                            
__________________________________________________________________________________________________
conv2d_5 (Conv2D)               (None, 16, 16, 16)   160         t_input[0][0]                    
__________________________________________________________________________________________________
max_pooling2d_3 (MaxPooling2D)  (None, 8, 8, 16)     0           conv2d_5[0][0]                   
__________________________________________________________________________________________________
conv2d_6 (Conv2D)               (None, 8, 8, 32)     2080        max_pooling2d_3[0][0]            
__________________________________________________________________________________________________
max_pooling2d_4 (MaxPooling2D)  (None, 4, 4, 32)     0           conv2d_6[0][0]                   
__________________________________________________________________________________________________
flatten_2 (Flatten)             (None, 512)          0           max_pooling2d_4[0][0]            
__________________________________________________________________________________________________
t_z_mean (Dense)                (None, 10)           5130        flatten_2[0][0]                  
__________________________________________________________________________________________________
t_z_log_var (Dense)             (None, 10)           5130        flatten_2[0][0]                  
__________________________________________________________________________________________________
z (Lambda)                      (None, 10)           0           t_z_mean[0][0]                   
                                                                 t_z_log_var[0][0]                
==================================================================================================
Total params: 12,500
Trainable params: 12,500
Non-trainable params: 0
__________________________________________________________________________________________________
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
s_input (InputLayer)            (None, 28, 28, 1)    0                                            
__________________________________________________________________________________________________
conv2d_1 (Conv2D)               (None, 28, 28, 16)   160         s_input[0][0]                    
__________________________________________________________________________________________________
t_input (InputLayer)            (None, 16, 16, 1)    0                                            
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 14, 14, 16)   0           conv2d_1[0][0]                   
__________________________________________________________________________________________________
conv2d_5 (Conv2D)               (None, 16, 16, 16)   160         t_input[0][0]                    
__________________________________________________________________________________________________
conv2d_2 (Conv2D)               (None, 14, 14, 32)   2080        max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
max_pooling2d_3 (MaxPooling2D)  (None, 8, 8, 16)     0           conv2d_5[0][0]                   
__________________________________________________________________________________________________
max_pooling2d_2 (MaxPooling2D)  (None, 7, 7, 32)     0           conv2d_2[0][0]                   
__________________________________________________________________________________________________
conv2d_6 (Conv2D)               (None, 8, 8, 32)     2080        max_pooling2d_3[0][0]            
__________________________________________________________________________________________________
flatten_1 (Flatten)             (None, 1568)         0           max_pooling2d_2[0][0]            
__________________________________________________________________________________________________
max_pooling2d_4 (MaxPooling2D)  (None, 4, 4, 32)     0           conv2d_6[0][0]                   
__________________________________________________________________________________________________
s_z_mean (Dense)                (None, 10)           15690       flatten_1[0][0]                  
__________________________________________________________________________________________________
s_z_log_var (Dense)             (None, 10)           15690       flatten_1[0][0]                  
__________________________________________________________________________________________________
flatten_2 (Flatten)             (None, 512)          0           max_pooling2d_4[0][0]            
__________________________________________________________________________________________________
s_z (Lambda)                    (None, 10)           0           s_z_mean[0][0]                   
                                                                 s_z_log_var[0][0]                
__________________________________________________________________________________________________
t_z_mean (Dense)                (None, 10)           5130        flatten_2[0][0]                  
__________________________________________________________________________________________________WARNING:tensorflow:From /home/mrahman/anaconda3/lib/python3.7/site-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.

WARNING:tensorflow:From /home/mrahman/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:3376: The name tf.log is deprecated. Please use tf.math.log instead.

WARNING:tensorflow:From /home/mrahman/.local/lib/python3.7/site-packages/tensorflow/python/ops/nn_impl.py:180: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use tf.where in 2.0, which has the same broadcast rule as np.where
2020-04-26 00:09:22.968347: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2000204999 Hz
2020-04-26 00:09:22.970973: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55aae2daf180 executing computations on platform Host. Devices:
2020-04-26 00:09:22.971050: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>
2020-04-26 00:09:22.973358: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcuda.so.1
2020-04-26 00:09:23.273377: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 0 with properties: 
name: GeForce GTX TITAN X major: 5 minor: 2 memoryClockRate(GHz): 1.076
pciBusID: 0000:05:00.0
2020-04-26 00:09:23.274753: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 1 with properties: 
name: Tesla K40c major: 3 minor: 5 memoryClockRate(GHz): 0.745
pciBusID: 0000:84:00.0
2020-04-26 00:09:23.276036: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 2 with properties: 
name: Tesla K40c major: 3 minor: 5 memoryClockRate(GHz): 0.745
pciBusID: 0000:88:00.0
2020-04-26 00:09:23.276551: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0
2020-04-26 00:09:23.278538: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0
2020-04-26 00:09:23.280014: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcufft.so.10.0
2020-04-26 00:09:23.280504: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcurand.so.10.0
2020-04-26 00:09:23.282681: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusolver.so.10.0
2020-04-26 00:09:23.284429: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusparse.so.10.0
2020-04-26 00:09:23.289884: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7
2020-04-26 00:09:23.297618: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1763] Adding visible gpu devices: 0, 1, 2
2020-04-26 00:09:23.297708: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0
2020-04-26 00:09:23.302817: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1181] Device interconnect StreamExecutor with strength 1 edge matrix:
2020-04-26 00:09:23.302856: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1187]      0 1 2 
2020-04-26 00:09:23.302876: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1200] 0:   N N N 
2020-04-26 00:09:23.302892: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1200] 1:   N N Y 
2020-04-26 00:09:23.302907: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1200] 2:   N Y N 
2020-04-26 00:09:23.309383: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1326] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 11497 MB memory) -> physical GPU (device: 0, name: GeForce GTX TITAN X, pci bus id: 0000:05:00.0, compute capability: 5.2)
2020-04-26 00:09:23.312451: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1326] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:1 with 11525 MB memory) -> physical GPU (device: 1, name: Tesla K40c, pci bus id: 0000:84:00.0, compute capability: 3.5)
2020-04-26 00:09:23.315308: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1326] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:2 with 11525 MB memory) -> physical GPU (device: 2, name: Tesla K40c, pci bus id: 0000:88:00.0, compute capability: 3.5)
2020-04-26 00:09:23.318333: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55aae534ee50 executing computations on platform CUDA. Devices:
2020-04-26 00:09:23.318371: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): GeForce GTX TITAN X, Compute Capability 5.2
2020-04-26 00:09:23.318410: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (1): Tesla K40c, Compute Capability 3.5
2020-04-26 00:09:23.318429: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (2): Tesla K40c, Compute Capability 3.5
2020-04-26 00:09:26.635646: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0
2020-04-26 00:09:26.982612: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7

t_z_log_var (Dense)             (None, 10)           5130        flatten_2[0][0]                  
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 10)           110         s_z[0][0]                        
__________________________________________________________________________________________________
z (Lambda)                      (None, 10)           0           t_z_mean[0][0]                   
                                                                 t_z_log_var[0][0]                
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 20)           0           dense_2[0][0]                    
                                                                 z[0][0]                          
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 1568)         17248       s_z[0][0]                        
__________________________________________________________________________________________________
dense_3 (Dense)                 (None, 512)          10752       concatenate_1[0][0]              
__________________________________________________________________________________________________
reshape_1 (Reshape)             (None, 7, 7, 32)     0           dense_1[0][0]                    
__________________________________________________________________________________________________
reshape_2 (Reshape)             (None, 4, 4, 32)     0           dense_3[0][0]                    
__________________________________________________________________________________________________
conv2d_3 (Conv2D)               (None, 7, 7, 32)     4128        reshape_1[0][0]                  
__________________________________________________________________________________________________
conv2d_7 (Conv2D)               (None, 4, 4, 32)     4128        reshape_2[0][0]                  
__________________________________________________________________________________________________
up_sampling2d_1 (UpSampling2D)  (None, 14, 14, 32)   0           conv2d_3[0][0]                   
__________________________________________________________________________________________________
up_sampling2d_3 (UpSampling2D)  (None, 8, 8, 32)     0           conv2d_7[0][0]                   
__________________________________________________________________________________________________
conv2d_4 (Conv2D)               (None, 14, 14, 16)   4624        up_sampling2d_1[0][0]            
__________________________________________________________________________________________________
conv2d_8 (Conv2D)               (None, 8, 8, 16)     4624        up_sampling2d_3[0][0]            
__________________________________________________________________________________________________
up_sampling2d_2 (UpSampling2D)  (None, 28, 28, 16)   0           conv2d_4[0][0]                   
__________________________________________________________________________________________________
up_sampling2d_4 (UpSampling2D)  (None, 16, 16, 16)   0           conv2d_8[0][0]                   
__________________________________________________________________________________________________
s_output (Conv2D)               (None, 28, 28, 1)    145         up_sampling2d_2[0][0]            
__________________________________________________________________________________________________
t_output (Conv2D)               (None, 16, 16, 1)    145         up_sampling2d_4[0][0]            
==================================================================================================
Total params: 92,024
Trainable params: 92,024
Non-trainable params: 0
__________________________________________________________________________________________________
Train on 60000 samples, validate on 10000 samples
Epoch 1/10

  128/60000 [..............................] - ETA: 43:25 - loss: 1187.0381 - s_output_loss: 343.9162 - t_output_loss: 843.1218
  384/60000 [..............................] - ETA: 14:37 - loss: 873.2409 - s_output_loss: 304.3764 - t_output_loss: 568.8645 
  640/60000 [..............................] - ETA: 8:48 - loss: 716.1772 - s_output_loss: 299.4297 - t_output_loss: 416.7475 
  896/60000 [..............................] - ETA: 6:19 - loss: 631.5237 - s_output_loss: 292.4816 - t_output_loss: 339.0421
 1152/60000 [..............................] - ETA: 4:56 - loss: 581.5117 - s_output_loss: 286.4772 - t_output_loss: 295.0345
 1408/60000 [..............................] - ETA: 4:03 - loss: 549.2914 - s_output_loss: 280.9864 - t_output_loss: 268.3049
 1664/60000 [..............................] - ETA: 3:27 - loss: 525.9639 - s_output_loss: 275.6563 - t_output_loss: 250.3076
 1920/60000 [..............................] - ETA: 3:00 - loss: 506.9727 - s_output_loss: 269.7199 - t_output_loss: 237.2528
 2176/60000 [>.............................] - ETA: 2:39 - loss: 492.0557 - s_output_loss: 264.7174 - t_output_loss: 227.3382
 2432/60000 [>.............................] - ETA: 2:23 - loss: 479.5579 - s_output_loss: 260.1998 - t_output_loss: 219.3581
 2688/60000 [>.............................] - ETA: 2:10 - loss: 468.8754 - s_output_loss: 256.4399 - t_output_loss: 212.4355
 2944/60000 [>.............................] - ETA: 1:59 - loss: 459.7995 - s_output_loss: 253.2149 - t_output_loss: 206.5846
 3200/60000 [>.............................] - ETA: 1:50 - loss: 452.2500 - s_output_loss: 250.7999 - t_output_loss: 201.4501
 3456/60000 [>.............................] - ETA: 1:42 - loss: 445.4712 - s_output_loss: 248.4591 - t_output_loss: 197.0121
 3712/60000 [>.............................] - ETA: 1:35 - loss: 439.4095 - s_output_loss: 246.1537 - t_output_loss: 193.2559
 3968/60000 [>.............................] - ETA: 1:30 - loss: 434.1759 - s_output_loss: 244.1826 - t_output_loss: 189.9933
 4224/60000 [=>............................] - ETA: 1:24 - loss: 429.5786 - s_output_loss: 242.4301 - t_output_loss: 187.1485
 4608/60000 [=>............................] - ETA: 1:18 - loss: 423.6161 - s_output_loss: 240.3783 - t_output_loss: 183.2378
 4864/60000 [=>............................] - ETA: 1:14 - loss: 420.2136 - s_output_loss: 239.2371 - t_output_loss: 180.9765
 5120/60000 [=>............................] - ETA: 1:10 - loss: 417.1734 - s_output_loss: 238.0750 - t_output_loss: 179.0984
 5376/60000 [=>............................] - ETA: 1:07 - loss: 413.9751 - s_output_loss: 236.8633 - t_output_loss: 177.1118
 5632/60000 [=>............................] - ETA: 1:04 - loss: 410.9419 - s_output_loss: 235.6137 - t_output_loss: 175.3282
 5888/60000 [=>............................] - ETA: 1:02 - loss: 408.2727 - s_output_loss: 234.5898 - t_output_loss: 173.6829
 6272/60000 [==>...........................] - ETA: 58s - loss: 404.6430 - s_output_loss: 233.2965 - t_output_loss: 171.3465 
 6528/60000 [==>...........................] - ETA: 56s - loss: 402.1178 - s_output_loss: 232.3008 - t_output_loss: 169.8170
 6784/60000 [==>...........................] - ETA: 54s - loss: 399.7432 - s_output_loss: 231.2596 - t_output_loss: 168.4836
 7040/60000 [==>...........................] - ETA: 52s - loss: 397.5426 - s_output_loss: 230.3404 - t_output_loss: 167.2022
 7296/60000 [==>...........................] - ETA: 51s - loss: 395.6787 - s_output_loss: 229.6699 - t_output_loss: 166.0088
 7680/60000 [==>...........................] - ETA: 48s - loss: 392.8096 - s_output_loss: 228.4679 - t_output_loss: 164.3417
 7936/60000 [==>...........................] - ETA: 47s - loss: 391.1118 - s_output_loss: 227.8394 - t_output_loss: 163.2723
 8192/60000 [===>..........................] - ETA: 45s - loss: 389.3091 - s_output_loss: 227.1129 - t_output_loss: 162.1962
 8448/60000 [===>..........................] - ETA: 44s - loss: 387.7197 - s_output_loss: 226.4756 - t_output_loss: 161.2441
 8704/60000 [===>..........................] - ETA: 43s - loss: 386.2166 - s_output_loss: 225.8685 - t_output_loss: 160.3481
 8960/60000 [===>..........................] - ETA: 42s - loss: 384.7636 - s_output_loss: 225.2850 - t_output_loss: 159.4787
 9216/60000 [===>..........................] - ETA: 41s - loss: 383.0052 - s_output_loss: 224.4644 - t_output_loss: 158.5408
 9472/60000 [===>..........................] - ETA: 40s - loss: 381.4791 - s_output_loss: 223.8297 - t_output_loss: 157.6494
 9728/60000 [===>..........................] - ETA: 39s - loss: 379.8070 - s_output_loss: 223.0937 - t_output_loss: 156.7133
 9984/60000 [===>..........................] - ETA: 38s - loss: 378.4638 - s_output_loss: 222.5139 - t_output_loss: 155.9498
10240/60000 [====>.........................] - ETA: 37s - loss: 376.8927 - s_output_loss: 221.8086 - t_output_loss: 155.0841
10496/60000 [====>.........................] - ETA: 36s - loss: 375.5909 - s_output_loss: 221.2281 - t_output_loss: 154.3627
10752/60000 [====>.........................] - ETA: 35s - loss: 374.2262 - s_output_loss: 220.5631 - t_output_loss: 153.6631
11008/60000 [====>.........................] - ETA: 34s - loss: 372.9205 - s_output_loss: 220.0046 - t_output_loss: 152.9159
11264/60000 [====>.........................] - ETA: 34s - loss: 371.6860 - s_output_loss: 219.4403 - t_output_loss: 152.2456
11520/60000 [====>.........................] - ETA: 33s - loss: 370.3894 - s_output_loss: 218.8193 - t_output_loss: 151.5701
11776/60000 [====>.........................] - ETA: 32s - loss: 369.0670 - s_output_loss: 218.1734 - t_output_loss: 150.8936
12032/60000 [=====>........................] - ETA: 32s - loss: 367.9768 - s_output_loss: 217.6702 - t_output_loss: 150.3066
12288/60000 [=====>........................] - ETA: 31s - loss: 366.8842 - s_output_loss: 217.1764 - t_output_loss: 149.7078
12544/60000 [=====>........................] - ETA: 30s - loss: 365.6196 - s_output_loss: 216.5373 - t_output_loss: 149.0823
12800/60000 [=====>........................] - ETA: 30s - loss: 364.5037 - s_output_loss: 215.9974 - t_output_loss: 148.5063
13056/60000 [=====>........................] - ETA: 29s - loss: 363.2968 - s_output_loss: 215.3916 - t_output_loss: 147.9051
13312/60000 [=====>........................] - ETA: 29s - loss: 362.1749 - s_output_loss: 214.8080 - t_output_loss: 147.3669
13568/60000 [=====>........................] - ETA: 28s - loss: 361.1261 - s_output_loss: 214.3122 - t_output_loss: 146.8139
13824/60000 [=====>........................] - ETA: 28s - loss: 359.9876 - s_output_loss: 213.7368 - t_output_loss: 146.2508
14080/60000 [======>.......................] - ETA: 27s - loss: 358.7885 - s_output_loss: 213.1306 - t_output_loss: 145.6579
14336/60000 [======>.......................] - ETA: 27s - loss: 357.6586 - s_output_loss: 212.5027 - t_output_loss: 145.1558
14592/60000 [======>.......................] - ETA: 26s - loss: 356.7195 - s_output_loss: 212.0247 - t_output_loss: 144.6948
14848/60000 [======>.......................] - ETA: 26s - loss: 355.7817 - s_output_loss: 211.5546 - t_output_loss: 144.2271
15104/60000 [======>.......................] - ETA: 25s - loss: 354.7125 - s_output_loss: 210.9983 - t_output_loss: 143.7141
15360/60000 [======>.......................] - ETA: 25s - loss: 353.6550 - s_output_loss: 210.4587 - t_output_loss: 143.1963
15616/60000 [======>.......................] - ETA: 25s - loss: 352.7298 - s_output_loss: 210.0013 - t_output_loss: 142.7285
15872/60000 [======>.......................] - ETA: 24s - loss: 351.7807 - s_output_loss: 209.5415 - t_output_loss: 142.2392
16128/60000 [=======>......................] - ETA: 24s - loss: 350.7154 - s_output_loss: 208.9750 - t_output_loss: 141.7404
16512/60000 [=======>......................] - ETA: 23s - loss: 349.2296 - s_output_loss: 208.1830 - t_output_loss: 141.0466
16896/60000 [=======>......................] - ETA: 23s - loss: 347.7892 - s_output_loss: 207.4746 - t_output_loss: 140.3145
17152/60000 [=======>......................] - ETA: 22s - loss: 346.7089 - s_output_loss: 206.8854 - t_output_loss: 139.8234
17408/60000 [=======>......................] - ETA: 22s - loss: 345.7869 - s_output_loss: 206.4127 - t_output_loss: 139.3741
17664/60000 [=======>......................] - ETA: 22s - loss: 344.8559 - s_output_loss: 205.9370 - t_output_loss: 138.9189
17920/60000 [=======>......................] - ETA: 21s - loss: 343.9646 - s_output_loss: 205.4843 - t_output_loss: 138.4802
18176/60000 [========>.....................] - ETA: 21s - loss: 343.0865 - s_output_loss: 205.0551 - t_output_loss: 138.0314
18432/60000 [========>.....................] - ETA: 21s - loss: 342.1453 - s_output_loss: 204.5493 - t_output_loss: 137.5960
18688/60000 [========>.....................] - ETA: 20s - loss: 341.2704 - s_output_loss: 204.1166 - t_output_loss: 137.1538
18944/60000 [========>.....................] - ETA: 20s - loss: 340.4164 - s_output_loss: 203.6890 - t_output_loss: 136.7274
19200/60000 [========>.....................] - ETA: 20s - loss: 339.6257 - s_output_loss: 203.3470 - t_output_loss: 136.2787
19456/60000 [========>.....................] - ETA: 20s - loss: 338.8377 - s_output_loss: 202.9616 - t_output_loss: 135.8761
19712/60000 [========>.....................] - ETA: 19s - loss: 337.9999 - s_output_loss: 202.5330 - t_output_loss: 135.4670
19968/60000 [========>.....................] - ETA: 19s - loss: 337.2158 - s_output_loss: 202.1618 - t_output_loss: 135.0540
20224/60000 [=========>....................] - ETA: 19s - loss: 336.4034 - s_output_loss: 201.7493 - t_output_loss: 134.6540
20480/60000 [=========>....................] - ETA: 19s - loss: 335.6388 - s_output_loss: 201.4055 - t_output_loss: 134.2332
20864/60000 [=========>....................] - ETA: 18s - loss: 334.4151 - s_output_loss: 200.7784 - t_output_loss: 133.6367
21120/60000 [=========>....................] - ETA: 18s - loss: 333.6613 - s_output_loss: 200.4380 - t_output_loss: 133.2234
21376/60000 [=========>....................] - ETA: 18s - loss: 332.8826 - s_output_loss: 200.0248 - t_output_loss: 132.8578
21632/60000 [=========>....................] - ETA: 17s - loss: 332.0729 - s_output_loss: 199.6127 - t_output_loss: 132.4602
21888/60000 [=========>....................] - ETA: 17s - loss: 331.2526 - s_output_loss: 199.1892 - t_output_loss: 132.0634
22144/60000 [==========>...................] - ETA: 17s - loss: 330.5116 - s_output_loss: 198.8245 - t_output_loss: 131.6871
22400/60000 [==========>...................] - ETA: 17s - loss: 329.7295 - s_output_loss: 198.4295 - t_output_loss: 131.3000
22656/60000 [==========>...................] - ETA: 17s - loss: 328.9710 - s_output_loss: 198.0427 - t_output_loss: 130.9283
22912/60000 [==========>...................] - ETA: 16s - loss: 328.1493 - s_output_loss: 197.6238 - t_output_loss: 130.5255
23168/60000 [==========>...................] - ETA: 16s - loss: 327.4055 - s_output_loss: 197.2578 - t_output_loss: 130.1476
23424/60000 [==========>...................] - ETA: 16s - loss: 326.6453 - s_output_loss: 196.8655 - t_output_loss: 129.7798
23680/60000 [==========>...................] - ETA: 16s - loss: 325.9247 - s_output_loss: 196.4921 - t_output_loss: 129.4326
23936/60000 [==========>...................] - ETA: 15s - loss: 325.2683 - s_output_loss: 196.1752 - t_output_loss: 129.0931
24192/60000 [===========>..................] - ETA: 15s - loss: 324.5538 - s_output_loss: 195.8142 - t_output_loss: 128.7396
24448/60000 [===========>..................] - ETA: 15s - loss: 323.8721 - s_output_loss: 195.4716 - t_output_loss: 128.4005
24704/60000 [===========>..................] - ETA: 15s - loss: 323.1837 - s_output_loss: 195.1166 - t_output_loss: 128.0671
24960/60000 [===========>..................] - ETA: 15s - loss: 322.4332 - s_output_loss: 194.7119 - t_output_loss: 127.7214
25216/60000 [===========>..................] - ETA: 15s - loss: 321.6206 - s_output_loss: 194.2780 - t_output_loss: 127.3427
25472/60000 [===========>..................] - ETA: 14s - loss: 321.0460 - s_output_loss: 193.9876 - t_output_loss: 127.0583
25728/60000 [===========>..................] - ETA: 14s - loss: 320.3853 - s_output_loss: 193.6566 - t_output_loss: 126.7287
25984/60000 [===========>..................] - ETA: 14s - loss: 319.8542 - s_output_loss: 193.4454 - t_output_loss: 126.4088
26240/60000 [============>.................] - ETA: 14s - loss: 319.1774 - s_output_loss: 193.1030 - t_output_loss: 126.0743
26496/60000 [============>.................] - ETA: 14s - loss: 318.6363 - s_output_loss: 192.8841 - t_output_loss: 125.7522
26752/60000 [============>.................] - ETA: 13s - loss: 317.9743 - s_output_loss: 192.5638 - t_output_loss: 125.4105
27008/60000 [============>.................] - ETA: 13s - loss: 317.3331 - s_output_loss: 192.2434 - t_output_loss: 125.0897
27264/60000 [============>.................] - ETA: 13s - loss: 316.7309 - s_output_loss: 191.9734 - t_output_loss: 124.7575
27520/60000 [============>.................] - ETA: 13s - loss: 316.1967 - s_output_loss: 191.7171 - t_output_loss: 124.4796
27776/60000 [============>.................] - ETA: 13s - loss: 315.5464 - s_output_loss: 191.3958 - t_output_loss: 124.1506
28032/60000 [=============>................] - ETA: 13s - loss: 314.9448 - s_output_loss: 191.1056 - t_output_loss: 123.8392
28288/60000 [=============>................] - ETA: 12s - loss: 314.3434 - s_output_loss: 190.7946 - t_output_loss: 123.5488
28544/60000 [=============>................] - ETA: 12s - loss: 313.7610 - s_output_loss: 190.5118 - t_output_loss: 123.2492
28800/60000 [=============>................] - ETA: 12s - loss: 313.1881 - s_output_loss: 190.2281 - t_output_loss: 122.9600
29056/60000 [=============>................] - ETA: 12s - loss: 312.6573 - s_output_loss: 189.9571 - t_output_loss: 122.7002
29312/60000 [=============>................] - ETA: 12s - loss: 312.1194 - s_output_loss: 189.6816 - t_output_loss: 122.4379
29568/60000 [=============>................] - ETA: 12s - loss: 311.4986 - s_output_loss: 189.3408 - t_output_loss: 122.1578
29824/60000 [=============>................] - ETA: 12s - loss: 310.9755 - s_output_loss: 189.0752 - t_output_loss: 121.9003
30080/60000 [==============>...............] - ETA: 11s - loss: 310.3774 - s_output_loss: 188.7615 - t_output_loss: 121.6159
30336/60000 [==============>...............] - ETA: 11s - loss: 309.8209 - s_output_loss: 188.4731 - t_output_loss: 121.3478
30592/60000 [==============>...............] - ETA: 11s - loss: 309.3615 - s_output_loss: 188.2211 - t_output_loss: 121.1404
30848/60000 [==============>...............] - ETA: 11s - loss: 308.8224 - s_output_loss: 187.9085 - t_output_loss: 120.9139
31104/60000 [==============>...............] - ETA: 11s - loss: 308.3118 - s_output_loss: 187.6425 - t_output_loss: 120.6693
31488/60000 [==============>...............] - ETA: 11s - loss: 307.5745 - s_output_loss: 187.2667 - t_output_loss: 120.3078
31744/60000 [==============>...............] - ETA: 10s - loss: 307.0763 - s_output_loss: 187.0213 - t_output_loss: 120.0550
32000/60000 [===============>..............] - ETA: 10s - loss: 306.5221 - s_output_loss: 186.7142 - t_output_loss: 119.8080
32256/60000 [===============>..............] - ETA: 10s - loss: 305.9882 - s_output_loss: 186.4309 - t_output_loss: 119.5573
32512/60000 [===============>..............] - ETA: 10s - loss: 305.4677 - s_output_loss: 186.1535 - t_output_loss: 119.3142
32768/60000 [===============>..............] - ETA: 10s - loss: 304.9869 - s_output_loss: 185.9126 - t_output_loss: 119.0743
33024/60000 [===============>..............] - ETA: 10s - loss: 304.4115 - s_output_loss: 185.6092 - t_output_loss: 118.8023
33280/60000 [===============>..............] - ETA: 10s - loss: 303.9645 - s_output_loss: 185.3954 - t_output_loss: 118.5690
33536/60000 [===============>..............] - ETA: 10s - loss: 303.4248 - s_output_loss: 185.1084 - t_output_loss: 118.3164
33792/60000 [===============>..............] - ETA: 9s - loss: 302.9065 - s_output_loss: 184.8209 - t_output_loss: 118.0856 
34176/60000 [================>.............] - ETA: 9s - loss: 302.1701 - s_output_loss: 184.4330 - t_output_loss: 117.7371
34432/60000 [================>.............] - ETA: 9s - loss: 301.7101 - s_output_loss: 184.2064 - t_output_loss: 117.5037
34688/60000 [================>.............] - ETA: 9s - loss: 301.2284 - s_output_loss: 183.9466 - t_output_loss: 117.2817
34944/60000 [================>.............] - ETA: 9s - loss: 300.7654 - s_output_loss: 183.7135 - t_output_loss: 117.0519
35200/60000 [================>.............] - ETA: 9s - loss: 300.2908 - s_output_loss: 183.4629 - t_output_loss: 116.8279
35456/60000 [================>.............] - ETA: 9s - loss: 299.8650 - s_output_loss: 183.2637 - t_output_loss: 116.6013
35712/60000 [================>.............] - ETA: 8s - loss: 299.3740 - s_output_loss: 182.9951 - t_output_loss: 116.3789
35968/60000 [================>.............] - ETA: 8s - loss: 298.9062 - s_output_loss: 182.7693 - t_output_loss: 116.1369
36352/60000 [=================>............] - ETA: 8s - loss: 298.2251 - s_output_loss: 182.4009 - t_output_loss: 115.8242
36608/60000 [=================>............] - ETA: 8s - loss: 297.8005 - s_output_loss: 182.1880 - t_output_loss: 115.6125
36864/60000 [=================>............] - ETA: 8s - loss: 297.4018 - s_output_loss: 181.9996 - t_output_loss: 115.4021
37120/60000 [=================>............] - ETA: 8s - loss: 297.0160 - s_output_loss: 181.8073 - t_output_loss: 115.2087
37376/60000 [=================>............] - ETA: 8s - loss: 296.6378 - s_output_loss: 181.6420 - t_output_loss: 114.9957
37632/60000 [=================>............] - ETA: 8s - loss: 296.1995 - s_output_loss: 181.4322 - t_output_loss: 114.7673
37888/60000 [=================>............] - ETA: 7s - loss: 295.7708 - s_output_loss: 181.2144 - t_output_loss: 114.5565
38144/60000 [==================>...........] - ETA: 7s - loss: 295.3333 - s_output_loss: 181.0006 - t_output_loss: 114.3327
38400/60000 [==================>...........] - ETA: 7s - loss: 294.9598 - s_output_loss: 180.7999 - t_output_loss: 114.1599
38656/60000 [==================>...........] - ETA: 7s - loss: 294.6165 - s_output_loss: 180.6037 - t_output_loss: 114.0128
38912/60000 [==================>...........] - ETA: 7s - loss: 294.2207 - s_output_loss: 180.3844 - t_output_loss: 113.8364
39168/60000 [==================>...........] - ETA: 7s - loss: 293.8029 - s_output_loss: 180.1776 - t_output_loss: 113.6253
39424/60000 [==================>...........] - ETA: 7s - loss: 293.4118 - s_output_loss: 179.9827 - t_output_loss: 113.4291
39680/60000 [==================>...........] - ETA: 7s - loss: 292.9835 - s_output_loss: 179.7587 - t_output_loss: 113.2248
39936/60000 [==================>...........] - ETA: 7s - loss: 292.6071 - s_output_loss: 179.5704 - t_output_loss: 113.0367
40192/60000 [===================>..........] - ETA: 6s - loss: 292.2270 - s_output_loss: 179.3902 - t_output_loss: 112.8368
40448/60000 [===================>..........] - ETA: 6s - loss: 291.8621 - s_output_loss: 179.2274 - t_output_loss: 112.6347
40704/60000 [===================>..........] - ETA: 6s - loss: 291.5033 - s_output_loss: 179.0478 - t_output_loss: 112.4555
40960/60000 [===================>..........] - ETA: 6s - loss: 291.0790 - s_output_loss: 178.8361 - t_output_loss: 112.2429
41216/60000 [===================>..........] - ETA: 6s - loss: 290.7149 - s_output_loss: 178.6491 - t_output_loss: 112.0659
41472/60000 [===================>..........] - ETA: 6s - loss: 290.3579 - s_output_loss: 178.4670 - t_output_loss: 111.8909
41728/60000 [===================>..........] - ETA: 6s - loss: 290.0437 - s_output_loss: 178.3207 - t_output_loss: 111.7230
41984/60000 [===================>..........] - ETA: 6s - loss: 289.6780 - s_output_loss: 178.1253 - t_output_loss: 111.5527
42240/60000 [====================>.........] - ETA: 6s - loss: 289.3544 - s_output_loss: 177.9711 - t_output_loss: 111.3833
42496/60000 [====================>.........] - ETA: 6s - loss: 289.0086 - s_output_loss: 177.8048 - t_output_loss: 111.2038
42752/60000 [====================>.........] - ETA: 5s - loss: 288.6505 - s_output_loss: 177.6071 - t_output_loss: 111.0433
43136/60000 [====================>.........] - ETA: 5s - loss: 288.1125 - s_output_loss: 177.3180 - t_output_loss: 110.7944
43392/60000 [====================>.........] - ETA: 5s - loss: 287.7710 - s_output_loss: 177.1412 - t_output_loss: 110.6299
43648/60000 [====================>.........] - ETA: 5s - loss: 287.3772 - s_output_loss: 176.9313 - t_output_loss: 110.4460
43904/60000 [====================>.........] - ETA: 5s - loss: 287.0227 - s_output_loss: 176.7500 - t_output_loss: 110.2727
44160/60000 [=====================>........] - ETA: 5s - loss: 286.6372 - s_output_loss: 176.5467 - t_output_loss: 110.0905
44416/60000 [=====================>........] - ETA: 5s - loss: 286.2475 - s_output_loss: 176.3403 - t_output_loss: 109.9073
44672/60000 [=====================>........] - ETA: 5s - loss: 285.8995 - s_output_loss: 176.1450 - t_output_loss: 109.7546
44928/60000 [=====================>........] - ETA: 5s - loss: 285.5681 - s_output_loss: 175.9787 - t_output_loss: 109.5894
45184/60000 [=====================>........] - ETA: 4s - loss: 285.2350 - s_output_loss: 175.8097 - t_output_loss: 109.4253
45440/60000 [=====================>........] - ETA: 4s - loss: 284.9011 - s_output_loss: 175.6419 - t_output_loss: 109.2592
45696/60000 [=====================>........] - ETA: 4s - loss: 284.5635 - s_output_loss: 175.4588 - t_output_loss: 109.1047
45952/60000 [=====================>........] - ETA: 4s - loss: 284.2444 - s_output_loss: 175.2876 - t_output_loss: 108.9568
46208/60000 [======================>.......] - ETA: 4s - loss: 283.9125 - s_output_loss: 175.1096 - t_output_loss: 108.8028
46464/60000 [======================>.......] - ETA: 4s - loss: 283.5898 - s_output_loss: 174.9470 - t_output_loss: 108.6428
46720/60000 [======================>.......] - ETA: 4s - loss: 283.2579 - s_output_loss: 174.7839 - t_output_loss: 108.4741
46976/60000 [======================>.......] - ETA: 4s - loss: 282.9254 - s_output_loss: 174.5999 - t_output_loss: 108.3255
47232/60000 [======================>.......] - ETA: 4s - loss: 282.6642 - s_output_loss: 174.4342 - t_output_loss: 108.2301
47616/60000 [======================>.......] - ETA: 4s - loss: 282.3017 - s_output_loss: 174.1921 - t_output_loss: 108.1096
47872/60000 [======================>.......] - ETA: 4s - loss: 282.0401 - s_output_loss: 174.0138 - t_output_loss: 108.0262
48128/60000 [=======================>......] - ETA: 3s - loss: 281.7383 - s_output_loss: 173.8335 - t_output_loss: 107.9049
48384/60000 [=======================>......] - ETA: 3s - loss: 281.4636 - s_output_loss: 173.6612 - t_output_loss: 107.8024
48640/60000 [=======================>......] - ETA: 3s - loss: 281.1876 - s_output_loss: 173.5051 - t_output_loss: 107.6824
48896/60000 [=======================>......] - ETA: 3s - loss: 280.9542 - s_output_loss: 173.3694 - t_output_loss: 107.5848
49152/60000 [=======================>......] - ETA: 3s - loss: 280.6922 - s_output_loss: 173.2190 - t_output_loss: 107.4731
49408/60000 [=======================>......] - ETA: 3s - loss: 280.4094 - s_output_loss: 173.0493 - t_output_loss: 107.3600
49664/60000 [=======================>......] - ETA: 3s - loss: 280.1314 - s_output_loss: 172.8910 - t_output_loss: 107.2403
49920/60000 [=======================>......] - ETA: 3s - loss: 279.8713 - s_output_loss: 172.7467 - t_output_loss: 107.1246
50176/60000 [========================>.....] - ETA: 3s - loss: 279.6295 - s_output_loss: 172.6162 - t_output_loss: 107.0132
50432/60000 [========================>.....] - ETA: 3s - loss: 279.3406 - s_output_loss: 172.4457 - t_output_loss: 106.8948
50688/60000 [========================>.....] - ETA: 3s - loss: 279.1008 - s_output_loss: 172.3070 - t_output_loss: 106.7939
50944/60000 [========================>.....] - ETA: 2s - loss: 278.8420 - s_output_loss: 172.1439 - t_output_loss: 106.6980
51328/60000 [========================>.....] - ETA: 2s - loss: 278.4435 - s_output_loss: 171.9095 - t_output_loss: 106.5339
51584/60000 [========================>.....] - ETA: 2s - loss: 278.1575 - s_output_loss: 171.7383 - t_output_loss: 106.4193
51840/60000 [========================>.....] - ETA: 2s - loss: 277.9128 - s_output_loss: 171.6067 - t_output_loss: 106.3061
52096/60000 [=========================>....] - ETA: 2s - loss: 277.6563 - s_output_loss: 171.4634 - t_output_loss: 106.1929
52352/60000 [=========================>....] - ETA: 2s - loss: 277.4509 - s_output_loss: 171.3597 - t_output_loss: 106.0913
52608/60000 [=========================>....] - ETA: 2s - loss: 277.2470 - s_output_loss: 171.2644 - t_output_loss: 105.9826
52864/60000 [=========================>....] - ETA: 2s - loss: 277.0780 - s_output_loss: 171.2158 - t_output_loss: 105.8622
53120/60000 [=========================>....] - ETA: 2s - loss: 276.9204 - s_output_loss: 171.1741 - t_output_loss: 105.7463
53376/60000 [=========================>....] - ETA: 2s - loss: 276.7690 - s_output_loss: 171.1390 - t_output_loss: 105.6301
53632/60000 [=========================>....] - ETA: 2s - loss: 276.6172 - s_output_loss: 171.0943 - t_output_loss: 105.5228
53888/60000 [=========================>....] - ETA: 1s - loss: 276.4117 - s_output_loss: 170.9980 - t_output_loss: 105.4138
54144/60000 [==========================>...] - ETA: 1s - loss: 276.2039 - s_output_loss: 170.9138 - t_output_loss: 105.2900
54400/60000 [==========================>...] - ETA: 1s - loss: 275.9984 - s_output_loss: 170.8302 - t_output_loss: 105.1682
54656/60000 [==========================>...] - ETA: 1s - loss: 275.7562 - s_output_loss: 170.7157 - t_output_loss: 105.0405
54912/60000 [==========================>...] - ETA: 1s - loss: 275.5761 - s_output_loss: 170.6437 - t_output_loss: 104.9324
55168/60000 [==========================>...] - ETA: 1s - loss: 275.3158 - s_output_loss: 170.5132 - t_output_loss: 104.8026
55424/60000 [==========================>...] - ETA: 1s - loss: 275.0936 - s_output_loss: 170.4148 - t_output_loss: 104.6788
55680/60000 [==========================>...] - ETA: 1s - loss: 274.8910 - s_output_loss: 170.3349 - t_output_loss: 104.5561
55936/60000 [==========================>...] - ETA: 1s - loss: 274.6933 - s_output_loss: 170.2543 - t_output_loss: 104.4390
56192/60000 [===========================>..] - ETA: 1s - loss: 274.5049 - s_output_loss: 170.1879 - t_output_loss: 104.3171
56448/60000 [===========================>..] - ETA: 1s - loss: 274.3324 - s_output_loss: 170.1243 - t_output_loss: 104.2082
56704/60000 [===========================>..] - ETA: 1s - loss: 274.1435 - s_output_loss: 170.0434 - t_output_loss: 104.1001
56960/60000 [===========================>..] - ETA: 0s - loss: 273.9269 - s_output_loss: 169.9449 - t_output_loss: 103.9821
57216/60000 [===========================>..] - ETA: 0s - loss: 273.6639 - s_output_loss: 169.8204 - t_output_loss: 103.8435
57472/60000 [===========================>..] - ETA: 0s - loss: 273.4417 - s_output_loss: 169.7226 - t_output_loss: 103.7191
57728/60000 [===========================>..] - ETA: 0s - loss: 273.2073 - s_output_loss: 169.6091 - t_output_loss: 103.5983
57984/60000 [===========================>..] - ETA: 0s - loss: 273.0050 - s_output_loss: 169.5100 - t_output_loss: 103.4950
58240/60000 [============================>.] - ETA: 0s - loss: 272.8926 - s_output_loss: 169.4281 - t_output_loss: 103.4646
58496/60000 [============================>.] - ETA: 0s - loss: 273.0177 - s_output_loss: 169.3207 - t_output_loss: 103.6970
58752/60000 [============================>.] - ETA: 0s - loss: 273.0736 - s_output_loss: 169.2140 - t_output_loss: 103.8596
59136/60000 [============================>.] - ETA: 0s - loss: 273.0108 - s_output_loss: 169.0567 - t_output_loss: 103.9541
59392/60000 [============================>.] - ETA: 0s - loss: 273.0120 - s_output_loss: 168.9472 - t_output_loss: 104.0649
59648/60000 [============================>.] - ETA: 0s - loss: 272.9502 - s_output_loss: 168.8162 - t_output_loss: 104.1340
59904/60000 [============================>.] - ETA: 0s - loss: 272.8839 - s_output_loss: 168.7064 - t_output_loss: 104.1775
60000/60000 [==============================] - 19s 322us/step - loss: 272.8683 - s_output_loss: 168.6697 - t_output_loss: 104.1987 - val_loss: 275.9994 - val_s_output_loss: 153.9337 - val_t_output_loss: 122.0656
Epoch 2/10

  128/60000 [..............................] - ETA: 14s - loss: 278.8966 - s_output_loss: 159.2333 - t_output_loss: 119.6633
  384/60000 [..............................] - ETA: 13s - loss: 296.6904 - s_output_loss: 178.8244 - t_output_loss: 117.8660
  640/60000 [..............................] - ETA: 13s - loss: 292.9931 - s_output_loss: 176.5705 - t_output_loss: 116.4226
  896/60000 [..............................] - ETA: 13s - loss: 286.7862 - s_output_loss: 171.6147 - t_output_loss: 115.1715
 1152/60000 [..............................] - ETA: 13s - loss: 286.3870 - s_output_loss: 171.3634 - t_output_loss: 115.0236
 1408/60000 [..............................] - ETA: 13s - loss: 285.4894 - s_output_loss: 170.7259 - t_output_loss: 114.7635
 1664/60000 [..............................] - ETA: 13s - loss: 283.3646 - s_output_loss: 169.1763 - t_output_loss: 114.1883
 1920/60000 [..............................] - ETA: 13s - loss: 281.1722 - s_output_loss: 167.9475 - t_output_loss: 113.2246
 2176/60000 [>.............................] - ETA: 13s - loss: 279.0668 - s_output_loss: 166.7882 - t_output_loss: 112.2786
 2432/60000 [>.............................] - ETA: 13s - loss: 277.5421 - s_output_loss: 166.0007 - t_output_loss: 111.5414
 2688/60000 [>.............................] - ETA: 13s - loss: 275.9468 - s_output_loss: 165.1072 - t_output_loss: 110.8396
 2944/60000 [>.............................] - ETA: 13s - loss: 274.4448 - s_output_loss: 164.1609 - t_output_loss: 110.2839
 3200/60000 [>.............................] - ETA: 13s - loss: 272.9591 - s_output_loss: 163.2361 - t_output_loss: 109.7230
 3456/60000 [>.............................] - ETA: 13s - loss: 270.9442 - s_output_loss: 162.0333 - t_output_loss: 108.9108
 3712/60000 [>.............................] - ETA: 12s - loss: 269.0638 - s_output_loss: 160.9399 - t_output_loss: 108.1239
 3968/60000 [>.............................] - ETA: 12s - loss: 267.2339 - s_output_loss: 159.8896 - t_output_loss: 107.3443
 4224/60000 [=>............................] - ETA: 12s - loss: 265.8824 - s_output_loss: 159.1748 - t_output_loss: 106.7077
 4480/60000 [=>............................] - ETA: 12s - loss: 264.2321 - s_output_loss: 158.2619 - t_output_loss: 105.9703
 4736/60000 [=>............................] - ETA: 12s - loss: 263.1394 - s_output_loss: 157.7203 - t_output_loss: 105.4191
 4992/60000 [=>............................] - ETA: 12s - loss: 261.8175 - s_output_loss: 156.8597 - t_output_loss: 104.9578
 5248/60000 [=>............................] - ETA: 12s - loss: 260.7091 - s_output_loss: 156.2338 - t_output_loss: 104.4752
 5504/60000 [=>............................] - ETA: 12s - loss: 259.5907 - s_output_loss: 155.5549 - t_output_loss: 104.0359
 5888/60000 [=>............................] - ETA: 11s - loss: 258.2329 - s_output_loss: 154.9127 - t_output_loss: 103.3202
 6144/60000 [==>...........................] - ETA: 11s - loss: 257.4801 - s_output_loss: 154.6197 - t_output_loss: 102.8604
 6400/60000 [==>...........................] - ETA: 11s - loss: 256.5798 - s_output_loss: 154.2311 - t_output_loss: 102.3487
 6656/60000 [==>...........................] - ETA: 11s - loss: 255.7613 - s_output_loss: 153.7760 - t_output_loss: 101.9853
 7040/60000 [==>...........................] - ETA: 11s - loss: 254.8903 - s_output_loss: 153.3851 - t_output_loss: 101.5053
 7296/60000 [==>...........................] - ETA: 11s - loss: 254.1507 - s_output_loss: 153.0672 - t_output_loss: 101.0835
 7552/60000 [==>...........................] - ETA: 11s - loss: 253.6315 - s_output_loss: 152.7981 - t_output_loss: 100.8334
 7808/60000 [==>...........................] - ETA: 11s - loss: 252.8554 - s_output_loss: 152.4426 - t_output_loss: 100.4127
 8064/60000 [===>..........................] - ETA: 11s - loss: 252.2631 - s_output_loss: 152.1398 - t_output_loss: 100.1233
 8320/60000 [===>..........................] - ETA: 11s - loss: 251.6117 - s_output_loss: 151.8133 - t_output_loss: 99.7984 
 8576/60000 [===>..........................] - ETA: 11s - loss: 251.0535 - s_output_loss: 151.5254 - t_output_loss: 99.5281
 8832/60000 [===>..........................] - ETA: 11s - loss: 250.2311 - s_output_loss: 151.0473 - t_output_loss: 99.1837
 9088/60000 [===>..........................] - ETA: 10s - loss: 249.5984 - s_output_loss: 150.7549 - t_output_loss: 98.8434
 9344/60000 [===>..........................] - ETA: 10s - loss: 248.8138 - s_output_loss: 150.3401 - t_output_loss: 98.4736
 9600/60000 [===>..........................] - ETA: 10s - loss: 248.2511 - s_output_loss: 150.0525 - t_output_loss: 98.1986
 9856/60000 [===>..........................] - ETA: 10s - loss: 247.7563 - s_output_loss: 149.8141 - t_output_loss: 97.9422
10240/60000 [====>.........................] - ETA: 10s - loss: 246.8924 - s_output_loss: 149.3648 - t_output_loss: 97.5276
10624/60000 [====>.........................] - ETA: 10s - loss: 246.1931 - s_output_loss: 149.0772 - t_output_loss: 97.1158
10880/60000 [====>.........................] - ETA: 10s - loss: 245.7259 - s_output_loss: 148.8736 - t_output_loss: 96.8524
11136/60000 [====>.........................] - ETA: 10s - loss: 245.3385 - s_output_loss: 148.7913 - t_output_loss: 96.5473
11392/60000 [====>.........................] - ETA: 10s - loss: 245.0413 - s_output_loss: 148.7243 - t_output_loss: 96.3170
11776/60000 [====>.........................] - ETA: 10s - loss: 244.7425 - s_output_loss: 148.7874 - t_output_loss: 95.9550
12032/60000 [=====>........................] - ETA: 10s - loss: 244.4547 - s_output_loss: 148.6764 - t_output_loss: 95.7783
12416/60000 [=====>........................] - ETA: 10s - loss: 243.8393 - s_output_loss: 148.3714 - t_output_loss: 95.4679
12800/60000 [=====>........................] - ETA: 9s - loss: 243.4326 - s_output_loss: 148.2432 - t_output_loss: 95.1894 
13056/60000 [=====>........................] - ETA: 9s - loss: 243.2248 - s_output_loss: 148.1849 - t_output_loss: 95.0398
13312/60000 [=====>........................] - ETA: 9s - loss: 242.8070 - s_output_loss: 148.0143 - t_output_loss: 94.7928
13568/60000 [=====>........................] - ETA: 9s - loss: 242.5885 - s_output_loss: 147.9839 - t_output_loss: 94.6047
13824/60000 [=====>........................] - ETA: 9s - loss: 242.3845 - s_output_loss: 147.9757 - t_output_loss: 94.4088
14080/60000 [======>.......................] - ETA: 9s - loss: 242.2750 - s_output_loss: 148.0674 - t_output_loss: 94.2077
14336/60000 [======>.......................] - ETA: 9s - loss: 242.0310 - s_output_loss: 148.0083 - t_output_loss: 94.0228
14720/60000 [======>.......................] - ETA: 9s - loss: 241.7298 - s_output_loss: 147.9835 - t_output_loss: 93.7463
14976/60000 [======>.......................] - ETA: 9s - loss: 241.4948 - s_output_loss: 147.9417 - t_output_loss: 93.5531
15232/60000 [======>.......................] - ETA: 9s - loss: 241.3050 - s_output_loss: 147.8690 - t_output_loss: 93.4360
15488/60000 [======>.......................] - ETA: 9s - loss: 240.9788 - s_output_loss: 147.7546 - t_output_loss: 93.2243
15744/60000 [======>.......................] - ETA: 9s - loss: 240.7037 - s_output_loss: 147.6519 - t_output_loss: 93.0518
16000/60000 [=======>......................] - ETA: 9s - loss: 240.4274 - s_output_loss: 147.5819 - t_output_loss: 92.8455
16256/60000 [=======>......................] - ETA: 9s - loss: 240.1968 - s_output_loss: 147.5252 - t_output_loss: 92.6716
16512/60000 [=======>......................] - ETA: 9s - loss: 240.0325 - s_output_loss: 147.5027 - t_output_loss: 92.5299
16768/60000 [=======>......................] - ETA: 9s - loss: 239.7390 - s_output_loss: 147.3993 - t_output_loss: 92.3397
17024/60000 [=======>......................] - ETA: 9s - loss: 239.5041 - s_output_loss: 147.2869 - t_output_loss: 92.2172
17280/60000 [=======>......................] - ETA: 8s - loss: 239.1457 - s_output_loss: 147.1317 - t_output_loss: 92.0140
17536/60000 [=======>......................] - ETA: 8s - loss: 238.9065 - s_output_loss: 147.0851 - t_output_loss: 91.8214
17792/60000 [=======>......................] - ETA: 8s - loss: 238.7471 - s_output_loss: 147.0512 - t_output_loss: 91.6959
18048/60000 [========>.....................] - ETA: 8s - loss: 238.5531 - s_output_loss: 146.9676 - t_output_loss: 91.5855
18304/60000 [========>.....................] - ETA: 8s - loss: 238.3870 - s_output_loss: 146.9271 - t_output_loss: 91.4598
18688/60000 [========>.....................] - ETA: 8s - loss: 238.0626 - s_output_loss: 146.8011 - t_output_loss: 91.2615
18944/60000 [========>.....................] - ETA: 8s - loss: 237.8130 - s_output_loss: 146.7103 - t_output_loss: 91.1026
19200/60000 [========>.....................] - ETA: 8s - loss: 237.5672 - s_output_loss: 146.6120 - t_output_loss: 90.9551
19584/60000 [========>.....................] - ETA: 8s - loss: 237.2519 - s_output_loss: 146.4793 - t_output_loss: 90.7726
19968/60000 [========>.....................] - ETA: 8s - loss: 236.9665 - s_output_loss: 146.3699 - t_output_loss: 90.5965
20224/60000 [=========>....................] - ETA: 8s - loss: 236.7895 - s_output_loss: 146.2964 - t_output_loss: 90.4931
20480/60000 [=========>....................] - ETA: 8s - loss: 236.5097 - s_output_loss: 146.1680 - t_output_loss: 90.3417
20736/60000 [=========>....................] - ETA: 8s - loss: 236.2375 - s_output_loss: 146.0364 - t_output_loss: 90.2011
21120/60000 [=========>....................] - ETA: 8s - loss: 236.0072 - s_output_loss: 145.9051 - t_output_loss: 90.1021
21376/60000 [=========>....................] - ETA: 8s - loss: 235.9082 - s_output_loss: 145.8655 - t_output_loss: 90.0427
21632/60000 [=========>....................] - ETA: 8s - loss: 236.0750 - s_output_loss: 146.1287 - t_output_loss: 89.9463
21888/60000 [=========>....................] - ETA: 8s - loss: 236.2532 - s_output_loss: 146.3873 - t_output_loss: 89.8658
22272/60000 [==========>...................] - ETA: 7s - loss: 236.1456 - s_output_loss: 146.4009 - t_output_loss: 89.7447
22528/60000 [==========>...................] - ETA: 7s - loss: 236.0864 - s_output_loss: 146.4763 - t_output_loss: 89.6101
22912/60000 [==========>...................] - ETA: 7s - loss: 236.1278 - s_output_loss: 146.6344 - t_output_loss: 89.4934
23168/60000 [==========>...................] - ETA: 7s - loss: 235.9843 - s_output_loss: 146.6026 - t_output_loss: 89.3817
23424/60000 [==========>...................] - ETA: 7s - loss: 235.9683 - s_output_loss: 146.6288 - t_output_loss: 89.3395
23680/60000 [==========>...................] - ETA: 7s - loss: 235.9160 - s_output_loss: 146.6638 - t_output_loss: 89.2522
23936/60000 [==========>...................] - ETA: 7s - loss: 235.8494 - s_output_loss: 146.6619 - t_output_loss: 89.1876
24192/60000 [===========>..................] - ETA: 7s - loss: 235.7138 - s_output_loss: 146.6162 - t_output_loss: 89.0976
24448/60000 [===========>..................] - ETA: 7s - loss: 235.5694 - s_output_loss: 146.5661 - t_output_loss: 89.0033
24704/60000 [===========>..................] - ETA: 7s - loss: 235.4777 - s_output_loss: 146.5636 - t_output_loss: 88.9141
24960/60000 [===========>..................] - ETA: 7s - loss: 235.3103 - s_output_loss: 146.4841 - t_output_loss: 88.8261
25216/60000 [===========>..................] - ETA: 7s - loss: 235.2014 - s_output_loss: 146.4258 - t_output_loss: 88.7756
25472/60000 [===========>..................] - ETA: 7s - loss: 235.2268 - s_output_loss: 146.3850 - t_output_loss: 88.8417
25728/60000 [===========>..................] - ETA: 7s - loss: 237.0740 - s_output_loss: 146.3124 - t_output_loss: 90.7616
25984/60000 [===========>..................] - ETA: 7s - loss: 238.8435 - s_output_loss: 146.2114 - t_output_loss: 92.6321
26240/60000 [============>.................] - ETA: 7s - loss: 240.0689 - s_output_loss: 146.1841 - t_output_loss: 93.8848
26496/60000 [============>.................] - ETA: 7s - loss: 241.4210 - s_output_loss: 146.1014 - t_output_loss: 95.3196
26752/60000 [============>.................] - ETA: 6s - loss: 242.1931 - s_output_loss: 146.0269 - t_output_loss: 96.1662
27008/60000 [============>.................] - ETA: 6s - loss: 242.7458 - s_output_loss: 145.9691 - t_output_loss: 96.7767
27264/60000 [============>.................] - ETA: 6s - loss: 243.2449 - s_output_loss: 145.9112 - t_output_loss: 97.3337
27520/60000 [============>.................] - ETA: 6s - loss: 243.6531 - s_output_loss: 145.8448 - t_output_loss: 97.8083
27776/60000 [============>.................] - ETA: 6s - loss: 243.9999 - s_output_loss: 145.7510 - t_output_loss: 98.2489
28032/60000 [=============>................] - ETA: 6s - loss: 244.1637 - s_output_loss: 145.6339 - t_output_loss: 98.5298
28288/60000 [=============>................] - ETA: 6s - loss: 244.2372 - s_output_loss: 145.5307 - t_output_loss: 98.7065
28672/60000 [=============>................] - ETA: 6s - loss: 244.3873 - s_output_loss: 145.4342 - t_output_loss: 98.9530
28928/60000 [=============>................] - ETA: 6s - loss: 244.5308 - s_output_loss: 145.4293 - t_output_loss: 99.1016
29312/60000 [=============>................] - ETA: 6s - loss: 244.7476 - s_output_loss: 145.4574 - t_output_loss: 99.2902
29568/60000 [=============>................] - ETA: 6s - loss: 245.0427 - s_output_loss: 145.5789 - t_output_loss: 99.4637
29824/60000 [=============>................] - ETA: 6s - loss: 245.2310 - s_output_loss: 145.6480 - t_output_loss: 99.5830
30080/60000 [==============>...............] - ETA: 6s - loss: 245.3566 - s_output_loss: 145.6561 - t_output_loss: 99.7005
30336/60000 [==============>...............] - ETA: 6s - loss: 245.4811 - s_output_loss: 145.6726 - t_output_loss: 99.8084
30720/60000 [==============>...............] - ETA: 6s - loss: 245.6212 - s_output_loss: 145.6873 - t_output_loss: 99.9339
30976/60000 [==============>...............] - ETA: 6s - loss: 245.6515 - s_output_loss: 145.6581 - t_output_loss: 99.9934
31360/60000 [==============>...............] - ETA: 5s - loss: 245.7414 - s_output_loss: 145.6273 - t_output_loss: 100.1141
31744/60000 [==============>...............] - ETA: 5s - loss: 245.8723 - s_output_loss: 145.6262 - t_output_loss: 100.2461
32000/60000 [===============>..............] - ETA: 5s - loss: 245.8998 - s_output_loss: 145.6102 - t_output_loss: 100.2896
32256/60000 [===============>..............] - ETA: 5s - loss: 245.8752 - s_output_loss: 145.5524 - t_output_loss: 100.3229
32640/60000 [===============>..............] - ETA: 5s - loss: 245.8898 - s_output_loss: 145.5303 - t_output_loss: 100.3595
32896/60000 [===============>..............] - ETA: 5s - loss: 245.8990 - s_output_loss: 145.5286 - t_output_loss: 100.3704
33280/60000 [===============>..............] - ETA: 5s - loss: 245.8660 - s_output_loss: 145.4869 - t_output_loss: 100.3792
33664/60000 [===============>..............] - ETA: 5s - loss: 245.9282 - s_output_loss: 145.5042 - t_output_loss: 100.4240
33920/60000 [===============>..............] - ETA: 5s - loss: 245.9208 - s_output_loss: 145.5028 - t_output_loss: 100.4180
34176/60000 [================>.............] - ETA: 5s - loss: 245.8443 - s_output_loss: 145.4580 - t_output_loss: 100.3863
34432/60000 [================>.............] - ETA: 5s - loss: 245.7530 - s_output_loss: 145.3980 - t_output_loss: 100.3550
34816/60000 [================>.............] - ETA: 5s - loss: 245.6592 - s_output_loss: 145.3287 - t_output_loss: 100.3305
35072/60000 [================>.............] - ETA: 5s - loss: 245.5961 - s_output_loss: 145.2949 - t_output_loss: 100.3013
35328/60000 [================>.............] - ETA: 5s - loss: 245.5504 - s_output_loss: 145.2745 - t_output_loss: 100.2759
35584/60000 [================>.............] - ETA: 5s - loss: 245.4640 - s_output_loss: 145.2227 - t_output_loss: 100.2413
35840/60000 [================>.............] - ETA: 5s - loss: 245.3449 - s_output_loss: 145.1627 - t_output_loss: 100.1822
36096/60000 [=================>............] - ETA: 4s - loss: 245.2530 - s_output_loss: 145.1257 - t_output_loss: 100.1273
36480/60000 [=================>............] - ETA: 4s - loss: 245.0071 - s_output_loss: 144.9804 - t_output_loss: 100.0267
36864/60000 [=================>............] - ETA: 4s - loss: 244.8857 - s_output_loss: 144.9285 - t_output_loss: 99.9572 
37248/60000 [=================>............] - ETA: 4s - loss: 244.7612 - s_output_loss: 144.8631 - t_output_loss: 99.8981
37632/60000 [=================>............] - ETA: 4s - loss: 244.6404 - s_output_loss: 144.8110 - t_output_loss: 99.8294
37888/60000 [=================>............] - ETA: 4s - loss: 244.5105 - s_output_loss: 144.7547 - t_output_loss: 99.7558
38272/60000 [==================>...........] - ETA: 4s - loss: 244.3322 - s_output_loss: 144.6741 - t_output_loss: 99.6582
38656/60000 [==================>...........] - ETA: 4s - loss: 244.0683 - s_output_loss: 144.5302 - t_output_loss: 99.5380
38912/60000 [==================>...........] - ETA: 4s - loss: 243.9073 - s_output_loss: 144.4388 - t_output_loss: 99.4685
39168/60000 [==================>...........] - ETA: 4s - loss: 243.7683 - s_output_loss: 144.3730 - t_output_loss: 99.3953
39424/60000 [==================>...........] - ETA: 4s - loss: 243.6610 - s_output_loss: 144.3278 - t_output_loss: 99.3332
39680/60000 [==================>...........] - ETA: 4s - loss: 243.5452 - s_output_loss: 144.2683 - t_output_loss: 99.2768
39936/60000 [==================>...........] - ETA: 4s - loss: 243.4301 - s_output_loss: 144.2056 - t_output_loss: 99.2245
40192/60000 [===================>..........] - ETA: 4s - loss: 243.3138 - s_output_loss: 144.1290 - t_output_loss: 99.1848
40448/60000 [===================>..........] - ETA: 4s - loss: 243.2021 - s_output_loss: 144.0627 - t_output_loss: 99.1394
40704/60000 [===================>..........] - ETA: 3s - loss: 243.1048 - s_output_loss: 144.0088 - t_output_loss: 99.0960
40960/60000 [===================>..........] - ETA: 3s - loss: 242.9866 - s_output_loss: 143.9472 - t_output_loss: 99.0394
41344/60000 [===================>..........] - ETA: 3s - loss: 242.7911 - s_output_loss: 143.8532 - t_output_loss: 98.9379
41728/60000 [===================>..........] - ETA: 3s - loss: 242.6287 - s_output_loss: 143.7816 - t_output_loss: 98.8471
41984/60000 [===================>..........] - ETA: 3s - loss: 242.5334 - s_output_loss: 143.7538 - t_output_loss: 98.7797
42240/60000 [====================>.........] - ETA: 3s - loss: 242.7671 - s_output_loss: 144.0466 - t_output_loss: 98.7205
42624/60000 [====================>.........] - ETA: 3s - loss: 243.0496 - s_output_loss: 144.4230 - t_output_loss: 98.6267
43008/60000 [====================>.........] - ETA: 3s - loss: 243.1897 - s_output_loss: 144.6385 - t_output_loss: 98.5511
43264/60000 [====================>.........] - ETA: 3s - loss: 243.2525 - s_output_loss: 144.7717 - t_output_loss: 98.4808
43520/60000 [====================>.........] - ETA: 3s - loss: 243.3452 - s_output_loss: 144.9112 - t_output_loss: 98.4340
43776/60000 [====================>.........] - ETA: 3s - loss: 243.4045 - s_output_loss: 145.0262 - t_output_loss: 98.3782
44160/60000 [=====================>........] - ETA: 3s - loss: 243.4809 - s_output_loss: 145.1894 - t_output_loss: 98.2916
44416/60000 [=====================>........] - ETA: 3s - loss: 243.5309 - s_output_loss: 145.2921 - t_output_loss: 98.2388
44672/60000 [=====================>........] - ETA: 3s - loss: 243.5133 - s_output_loss: 145.3627 - t_output_loss: 98.1505
45056/60000 [=====================>........] - ETA: 3s - loss: 243.5409 - s_output_loss: 145.4707 - t_output_loss: 98.0702
45312/60000 [=====================>........] - ETA: 3s - loss: 243.5462 - s_output_loss: 145.5110 - t_output_loss: 98.0352
45696/60000 [=====================>........] - ETA: 2s - loss: 243.5795 - s_output_loss: 145.5546 - t_output_loss: 98.0250
45952/60000 [=====================>........] - ETA: 2s - loss: 243.6043 - s_output_loss: 145.5753 - t_output_loss: 98.0290
46336/60000 [======================>.......] - ETA: 2s - loss: 243.5751 - s_output_loss: 145.5660 - t_output_loss: 98.0091
46720/60000 [======================>.......] - ETA: 2s - loss: 243.5183 - s_output_loss: 145.5436 - t_output_loss: 97.9747
46976/60000 [======================>.......] - ETA: 2s - loss: 243.4577 - s_output_loss: 145.5148 - t_output_loss: 97.9429
47232/60000 [======================>.......] - ETA: 2s - loss: 243.4172 - s_output_loss: 145.4980 - t_output_loss: 97.9192
47488/60000 [======================>.......] - ETA: 2s - loss: 243.3720 - s_output_loss: 145.4932 - t_output_loss: 97.8788
47744/60000 [======================>.......] - ETA: 2s - loss: 243.2984 - s_output_loss: 145.4670 - t_output_loss: 97.8315
48000/60000 [=======================>......] - ETA: 2s - loss: 243.2425 - s_output_loss: 145.4442 - t_output_loss: 97.7983
48256/60000 [=======================>......] - ETA: 2s - loss: 243.1618 - s_output_loss: 145.4086 - t_output_loss: 97.7532
48512/60000 [=======================>......] - ETA: 2s - loss: 243.0928 - s_output_loss: 145.3927 - t_output_loss: 97.7001
48768/60000 [=======================>......] - ETA: 2s - loss: 243.0253 - s_output_loss: 145.3672 - t_output_loss: 97.6581
49024/60000 [=======================>......] - ETA: 2s - loss: 242.9807 - s_output_loss: 145.3530 - t_output_loss: 97.6277
49408/60000 [=======================>......] - ETA: 2s - loss: 242.8508 - s_output_loss: 145.2915 - t_output_loss: 97.5592
49664/60000 [=======================>......] - ETA: 2s - loss: 242.7671 - s_output_loss: 145.2563 - t_output_loss: 97.5108
49920/60000 [=======================>......] - ETA: 2s - loss: 242.7084 - s_output_loss: 145.2362 - t_output_loss: 97.4722
50176/60000 [========================>.....] - ETA: 2s - loss: 242.6962 - s_output_loss: 145.1897 - t_output_loss: 97.5065
50432/60000 [========================>.....] - ETA: 1s - loss: 242.8321 - s_output_loss: 145.1316 - t_output_loss: 97.7005
50688/60000 [========================>.....] - ETA: 1s - loss: 243.0005 - s_output_loss: 145.1061 - t_output_loss: 97.8944
50944/60000 [========================>.....] - ETA: 1s - loss: 243.1040 - s_output_loss: 145.0889 - t_output_loss: 98.0152
51200/60000 [========================>.....] - ETA: 1s - loss: 243.1155 - s_output_loss: 145.0319 - t_output_loss: 98.0836
51456/60000 [========================>.....] - ETA: 1s - loss: 243.1732 - s_output_loss: 144.9859 - t_output_loss: 98.1873
51712/60000 [========================>.....] - ETA: 1s - loss: 243.1921 - s_output_loss: 144.9201 - t_output_loss: 98.2720
51968/60000 [========================>.....] - ETA: 1s - loss: 243.2515 - s_output_loss: 144.8877 - t_output_loss: 98.3637
52352/60000 [=========================>....] - ETA: 1s - loss: 243.2891 - s_output_loss: 144.8177 - t_output_loss: 98.4714
52608/60000 [=========================>....] - ETA: 1s - loss: 243.2976 - s_output_loss: 144.7575 - t_output_loss: 98.5400
52864/60000 [=========================>....] - ETA: 1s - loss: 243.3496 - s_output_loss: 144.7496 - t_output_loss: 98.6000
53120/60000 [=========================>....] - ETA: 1s - loss: 243.5426 - s_output_loss: 144.8849 - t_output_loss: 98.6576
53376/60000 [=========================>....] - ETA: 1s - loss: 243.7393 - s_output_loss: 145.0240 - t_output_loss: 98.7152
53632/60000 [=========================>....] - ETA: 1s - loss: 243.9087 - s_output_loss: 145.1334 - t_output_loss: 98.7753
53888/60000 [=========================>....] - ETA: 1s - loss: 244.0515 - s_output_loss: 145.2245 - t_output_loss: 98.8270
54144/60000 [==========================>...] - ETA: 1s - loss: 244.1768 - s_output_loss: 145.3050 - t_output_loss: 98.8718
54400/60000 [==========================>...] - ETA: 1s - loss: 244.2776 - s_output_loss: 145.3741 - t_output_loss: 98.9035
54656/60000 [==========================>...] - ETA: 1s - loss: 244.3756 - s_output_loss: 145.4374 - t_output_loss: 98.9383
54912/60000 [==========================>...] - ETA: 1s - loss: 244.4517 - s_output_loss: 145.4835 - t_output_loss: 98.9683
55168/60000 [==========================>...] - ETA: 0s - loss: 244.5409 - s_output_loss: 145.5433 - t_output_loss: 98.9976
55424/60000 [==========================>...] - ETA: 0s - loss: 244.6096 - s_output_loss: 145.5811 - t_output_loss: 99.0286
55680/60000 [==========================>...] - ETA: 0s - loss: 244.6110 - s_output_loss: 145.5822 - t_output_loss: 99.0288
55936/60000 [==========================>...] - ETA: 0s - loss: 244.6631 - s_output_loss: 145.6164 - t_output_loss: 99.0467
56192/60000 [===========================>..] - ETA: 0s - loss: 244.6812 - s_output_loss: 145.6237 - t_output_loss: 99.0575
56448/60000 [===========================>..] - ETA: 0s - loss: 244.7169 - s_output_loss: 145.6445 - t_output_loss: 99.0723
56704/60000 [===========================>..] - ETA: 0s - loss: 244.6831 - s_output_loss: 145.6315 - t_output_loss: 99.0516
56960/60000 [===========================>..] - ETA: 0s - loss: 244.6682 - s_output_loss: 145.6232 - t_output_loss: 99.0450
57216/60000 [===========================>..] - ETA: 0s - loss: 244.6328 - s_output_loss: 145.6002 - t_output_loss: 99.0326
57472/60000 [===========================>..] - ETA: 0s - loss: 244.5951 - s_output_loss: 145.5839 - t_output_loss: 99.0112
57856/60000 [===========================>..] - ETA: 0s - loss: 244.5819 - s_output_loss: 145.5769 - t_output_loss: 99.0050
58112/60000 [============================>.] - ETA: 0s - loss: 244.5559 - s_output_loss: 145.5634 - t_output_loss: 98.9925
58368/60000 [============================>.] - ETA: 0s - loss: 244.5671 - s_output_loss: 145.5753 - t_output_loss: 98.9918
58624/60000 [============================>.] - ETA: 0s - loss: 244.5522 - s_output_loss: 145.5738 - t_output_loss: 98.9784
58880/60000 [============================>.] - ETA: 0s - loss: 244.5205 - s_output_loss: 145.5658 - t_output_loss: 98.9547
59136/60000 [============================>.] - ETA: 0s - loss: 244.4805 - s_output_loss: 145.5472 - t_output_loss: 98.9333
59392/60000 [============================>.] - ETA: 0s - loss: 244.4351 - s_output_loss: 145.5214 - t_output_loss: 98.9137
59648/60000 [============================>.] - ETA: 0s - loss: 244.3799 - s_output_loss: 145.4895 - t_output_loss: 98.8905
59904/60000 [============================>.] - ETA: 0s - loss: 244.3089 - s_output_loss: 145.4514 - t_output_loss: 98.8575
60000/60000 [==============================] - 13s 216us/step - loss: 244.2891 - s_output_loss: 145.4448 - t_output_loss: 98.8443 - val_loss: 232.6345 - val_s_output_loss: 136.3855 - val_t_output_loss: 96.2490
Epoch 3/10

  128/60000 [..............................] - ETA: 17s - loss: 227.1533 - s_output_loss: 135.6558 - t_output_loss: 91.4975
  384/60000 [..............................] - ETA: 15s - loss: 225.6170 - s_output_loss: 135.3224 - t_output_loss: 90.2946
  640/60000 [..............................] - ETA: 14s - loss: 229.5787 - s_output_loss: 137.7312 - t_output_loss: 91.8475
  896/60000 [..............................] - ETA: 14s - loss: 229.1063 - s_output_loss: 136.9327 - t_output_loss: 92.1735
 1152/60000 [..............................] - ETA: 14s - loss: 228.1724 - s_output_loss: 136.3912 - t_output_loss: 91.7812
 1408/60000 [..............................] - ETA: 13s - loss: 227.1574 - s_output_loss: 136.1038 - t_output_loss: 91.0536
 1664/60000 [..............................] - ETA: 13s - loss: 227.1821 - s_output_loss: 136.2299 - t_output_loss: 90.9521
 1920/60000 [..............................] - ETA: 13s - loss: 227.3022 - s_output_loss: 136.1737 - t_output_loss: 91.1285
 2176/60000 [>.............................] - ETA: 12s - loss: 226.6738 - s_output_loss: 135.7602 - t_output_loss: 90.9136
 2432/60000 [>.............................] - ETA: 12s - loss: 226.0455 - s_output_loss: 135.4357 - t_output_loss: 90.6098
 2688/60000 [>.............................] - ETA: 12s - loss: 225.6618 - s_output_loss: 135.1251 - t_output_loss: 90.5367
 2944/60000 [>.............................] - ETA: 12s - loss: 225.2111 - s_output_loss: 135.0159 - t_output_loss: 90.1952
 3200/60000 [>.............................] - ETA: 12s - loss: 225.6383 - s_output_loss: 135.3987 - t_output_loss: 90.2396
 3456/60000 [>.............................] - ETA: 12s - loss: 224.9457 - s_output_loss: 135.0753 - t_output_loss: 89.8704
 3712/60000 [>.............................] - ETA: 12s - loss: 224.7204 - s_output_loss: 135.0702 - t_output_loss: 89.6502
 4096/60000 [=>............................] - ETA: 11s - loss: 224.9034 - s_output_loss: 135.2202 - t_output_loss: 89.6832
 4352/60000 [=>............................] - ETA: 11s - loss: 224.8224 - s_output_loss: 135.2087 - t_output_loss: 89.6136
 4608/60000 [=>............................] - ETA: 11s - loss: 224.8857 - s_output_loss: 135.2328 - t_output_loss: 89.6529
 4864/60000 [=>............................] - ETA: 11s - loss: 224.7099 - s_output_loss: 135.1993 - t_output_loss: 89.5107
 5120/60000 [=>............................] - ETA: 11s - loss: 225.6835 - s_output_loss: 136.3011 - t_output_loss: 89.3824
 5376/60000 [=>............................] - ETA: 11s - loss: 230.0177 - s_output_loss: 140.6090 - t_output_loss: 89.4086
 5632/60000 [=>............................] - ETA: 11s - loss: 232.1383 - s_output_loss: 142.9320 - t_output_loss: 89.2063
 5888/60000 [=>............................] - ETA: 11s - loss: 232.5135 - s_output_loss: 143.4723 - t_output_loss: 89.0412
 6144/60000 [==>...........................] - ETA: 11s - loss: 232.8792 - s_output_loss: 143.9365 - t_output_loss: 88.9427
 6400/60000 [==>...........................] - ETA: 11s - loss: 233.7523 - s_output_loss: 144.9407 - t_output_loss: 88.8116
 6656/60000 [==>...........................] - ETA: 11s - loss: 234.4926 - s_output_loss: 145.8553 - t_output_loss: 88.6373
 6912/60000 [==>...........................] - ETA: 11s - loss: 235.0782 - s_output_loss: 146.5277 - t_output_loss: 88.5505
 7168/60000 [==>...........................] - ETA: 11s - loss: 235.3503 - s_output_loss: 146.8693 - t_output_loss: 88.4810
 7424/60000 [==>...........................] - ETA: 11s - loss: 235.3775 - s_output_loss: 147.1184 - t_output_loss: 88.2591
 7680/60000 [==>...........................] - ETA: 10s - loss: 235.9036 - s_output_loss: 147.6232 - t_output_loss: 88.2804
 7936/60000 [==>...........................] - ETA: 10s - loss: 236.3159 - s_output_loss: 148.0913 - t_output_loss: 88.2246
 8192/60000 [===>..........................] - ETA: 10s - loss: 236.7647 - s_output_loss: 148.4802 - t_output_loss: 88.2845
 8448/60000 [===>..........................] - ETA: 10s - loss: 236.9573 - s_output_loss: 148.6718 - t_output_loss: 88.2854
 8832/60000 [===>..........................] - ETA: 10s - loss: 237.2547 - s_output_loss: 148.7959 - t_output_loss: 88.4589
 9088/60000 [===>..........................] - ETA: 10s - loss: 237.2891 - s_output_loss: 148.7056 - t_output_loss: 88.5834
 9344/60000 [===>..........................] - ETA: 10s - loss: 237.3150 - s_output_loss: 148.5719 - t_output_loss: 88.7431
 9600/60000 [===>..........................] - ETA: 10s - loss: 237.3902 - s_output_loss: 148.4856 - t_output_loss: 88.9046
 9856/60000 [===>..........................] - ETA: 10s - loss: 237.2404 - s_output_loss: 148.2933 - t_output_loss: 88.9471
10112/60000 [====>.........................] - ETA: 10s - loss: 237.1641 - s_output_loss: 148.1105 - t_output_loss: 89.0536
10368/60000 [====>.........................] - ETA: 10s - loss: 236.9713 - s_output_loss: 147.8329 - t_output_loss: 89.1384
10624/60000 [====>.........................] - ETA: 10s - loss: 236.9345 - s_output_loss: 147.6696 - t_output_loss: 89.2649
10880/60000 [====>.........................] - ETA: 10s - loss: 237.0591 - s_output_loss: 147.6641 - t_output_loss: 89.3950
11136/60000 [====>.........................] - ETA: 10s - loss: 237.0362 - s_output_loss: 147.5746 - t_output_loss: 89.4616
11520/60000 [====>.........................] - ETA: 10s - loss: 236.8073 - s_output_loss: 147.3032 - t_output_loss: 89.5041
11776/60000 [====>.........................] - ETA: 10s - loss: 236.6467 - s_output_loss: 147.1317 - t_output_loss: 89.5150
12032/60000 [=====>........................] - ETA: 9s - loss: 236.6077 - s_output_loss: 147.0302 - t_output_loss: 89.5775 
12288/60000 [=====>........................] - ETA: 9s - loss: 236.5061 - s_output_loss: 146.8954 - t_output_loss: 89.6107
12544/60000 [=====>........................] - ETA: 9s - loss: 236.3759 - s_output_loss: 146.7453 - t_output_loss: 89.6306
12800/60000 [=====>........................] - ETA: 9s - loss: 236.1111 - s_output_loss: 146.5375 - t_output_loss: 89.5736
13056/60000 [=====>........................] - ETA: 9s - loss: 235.9806 - s_output_loss: 146.4416 - t_output_loss: 89.5389
13312/60000 [=====>........................] - ETA: 9s - loss: 235.9571 - s_output_loss: 146.3815 - t_output_loss: 89.5756
13568/60000 [=====>........................] - ETA: 9s - loss: 235.7530 - s_output_loss: 146.2262 - t_output_loss: 89.5267
13824/60000 [=====>........................] - ETA: 9s - loss: 235.5529 - s_output_loss: 146.0322 - t_output_loss: 89.5207
14208/60000 [======>.......................] - ETA: 9s - loss: 235.1471 - s_output_loss: 145.7230 - t_output_loss: 89.4241
14464/60000 [======>.......................] - ETA: 9s - loss: 235.0255 - s_output_loss: 145.5991 - t_output_loss: 89.4264
14720/60000 [======>.......................] - ETA: 9s - loss: 234.7968 - s_output_loss: 145.4051 - t_output_loss: 89.3917
14976/60000 [======>.......................] - ETA: 9s - loss: 234.6032 - s_output_loss: 145.2666 - t_output_loss: 89.3366
15232/60000 [======>.......................] - ETA: 9s - loss: 234.4124 - s_output_loss: 145.1138 - t_output_loss: 89.2986
15488/60000 [======>.......................] - ETA: 9s - loss: 234.2050 - s_output_loss: 144.9617 - t_output_loss: 89.2433
15744/60000 [======>.......................] - ETA: 9s - loss: 233.9823 - s_output_loss: 144.7992 - t_output_loss: 89.1831
16000/60000 [=======>......................] - ETA: 9s - loss: 233.7127 - s_output_loss: 144.6021 - t_output_loss: 89.1106
16384/60000 [=======>......................] - ETA: 9s - loss: 233.4302 - s_output_loss: 144.4243 - t_output_loss: 89.0059
16768/60000 [=======>......................] - ETA: 8s - loss: 233.2230 - s_output_loss: 144.2778 - t_output_loss: 88.9452
17024/60000 [=======>......................] - ETA: 8s - loss: 232.9752 - s_output_loss: 144.1046 - t_output_loss: 88.8706
17280/60000 [=======>......................] - ETA: 8s - loss: 232.7248 - s_output_loss: 143.9397 - t_output_loss: 88.7850
17536/60000 [=======>......................] - ETA: 8s - loss: 232.5179 - s_output_loss: 143.8141 - t_output_loss: 88.7038
17920/60000 [=======>......................] - ETA: 8s - loss: 232.1972 - s_output_loss: 143.5984 - t_output_loss: 88.5988
18176/60000 [========>.....................] - ETA: 8s - loss: 231.9780 - s_output_loss: 143.4555 - t_output_loss: 88.5225
18432/60000 [========>.....................] - ETA: 8s - loss: 231.7692 - s_output_loss: 143.3179 - t_output_loss: 88.4513
18816/60000 [========>.....................] - ETA: 8s - loss: 231.5314 - s_output_loss: 143.1747 - t_output_loss: 88.3566
19072/60000 [========>.....................] - ETA: 8s - loss: 231.2847 - s_output_loss: 142.9964 - t_output_loss: 88.2883
19456/60000 [========>.....................] - ETA: 8s - loss: 231.0288 - s_output_loss: 142.8593 - t_output_loss: 88.1695
19712/60000 [========>.....................] - ETA: 8s - loss: 230.9000 - s_output_loss: 142.7985 - t_output_loss: 88.1014
20096/60000 [=========>....................] - ETA: 8s - loss: 230.6096 - s_output_loss: 142.6134 - t_output_loss: 87.9962
20352/60000 [=========>....................] - ETA: 8s - loss: 230.3852 - s_output_loss: 142.4672 - t_output_loss: 87.9181
20608/60000 [=========>....................] - ETA: 8s - loss: 230.2620 - s_output_loss: 142.4025 - t_output_loss: 87.8595
20864/60000 [=========>....................] - ETA: 8s - loss: 230.0266 - s_output_loss: 142.2537 - t_output_loss: 87.7729
21120/60000 [=========>....................] - ETA: 7s - loss: 229.8638 - s_output_loss: 142.1566 - t_output_loss: 87.7072
21376/60000 [=========>....................] - ETA: 7s - loss: 229.6852 - s_output_loss: 142.0497 - t_output_loss: 87.6356
21760/60000 [=========>....................] - ETA: 7s - loss: 229.4960 - s_output_loss: 141.9487 - t_output_loss: 87.5474
22016/60000 [==========>...................] - ETA: 7s - loss: 229.3291 - s_output_loss: 141.8488 - t_output_loss: 87.4803
22272/60000 [==========>...................] - ETA: 7s - loss: 229.1574 - s_output_loss: 141.7382 - t_output_loss: 87.4192
22528/60000 [==========>...................] - ETA: 7s - loss: 229.0115 - s_output_loss: 141.6586 - t_output_loss: 87.3530
22784/60000 [==========>...................] - ETA: 7s - loss: 228.9126 - s_output_loss: 141.6063 - t_output_loss: 87.3063
23168/60000 [==========>...................] - ETA: 7s - loss: 228.9251 - s_output_loss: 141.6576 - t_output_loss: 87.2675
23424/60000 [==========>...................] - ETA: 7s - loss: 228.9021 - s_output_loss: 141.6867 - t_output_loss: 87.2154
23680/60000 [==========>...................] - ETA: 7s - loss: 228.8782 - s_output_loss: 141.7269 - t_output_loss: 87.1513
24064/60000 [===========>..................] - ETA: 7s - loss: 228.8931 - s_output_loss: 141.8217 - t_output_loss: 87.0714
24320/60000 [===========>..................] - ETA: 7s - loss: 228.9523 - s_output_loss: 141.8915 - t_output_loss: 87.0609
24576/60000 [===========>..................] - ETA: 7s - loss: 228.8932 - s_output_loss: 141.8823 - t_output_loss: 87.0109
24960/60000 [===========>..................] - ETA: 7s - loss: 228.7614 - s_output_loss: 141.8352 - t_output_loss: 86.9262
25216/60000 [===========>..................] - ETA: 7s - loss: 228.7174 - s_output_loss: 141.8364 - t_output_loss: 86.8810
25472/60000 [===========>..................] - ETA: 7s - loss: 228.6052 - s_output_loss: 141.7823 - t_output_loss: 86.8229
25856/60000 [===========>..................] - ETA: 6s - loss: 228.4113 - s_output_loss: 141.6916 - t_output_loss: 86.7197
26112/60000 [============>.................] - ETA: 6s - loss: 228.2980 - s_output_loss: 141.6303 - t_output_loss: 86.6677
26496/60000 [============>.................] - ETA: 6s - loss: 228.1245 - s_output_loss: 141.5201 - t_output_loss: 86.6045
26880/60000 [============>.................] - ETA: 6s - loss: 227.9425 - s_output_loss: 141.4193 - t_output_loss: 86.5231
27136/60000 [============>.................] - ETA: 6s - loss: 227.7546 - s_output_loss: 141.3204 - t_output_loss: 86.4342
27392/60000 [============>.................] - ETA: 6s - loss: 227.6500 - s_output_loss: 141.2719 - t_output_loss: 86.3782
27648/60000 [============>.................] - ETA: 6s - loss: 227.5911 - s_output_loss: 141.2290 - t_output_loss: 86.3621
27904/60000 [============>.................] - ETA: 6s - loss: 227.4448 - s_output_loss: 141.1442 - t_output_loss: 86.3006
28160/60000 [=============>................] - ETA: 6s - loss: 227.3020 - s_output_loss: 141.0660 - t_output_loss: 86.2360
28416/60000 [=============>................] - ETA: 6s - loss: 227.1522 - s_output_loss: 140.9775 - t_output_loss: 86.1747
28672/60000 [=============>................] - ETA: 6s - loss: 227.0250 - s_output_loss: 140.9182 - t_output_loss: 86.1068
28928/60000 [=============>................] - ETA: 6s - loss: 226.9632 - s_output_loss: 140.8991 - t_output_loss: 86.0642
29184/60000 [=============>................] - ETA: 6s - loss: 226.8773 - s_output_loss: 140.8550 - t_output_loss: 86.0224
29568/60000 [=============>................] - ETA: 6s - loss: 226.7184 - s_output_loss: 140.7666 - t_output_loss: 85.9519
29824/60000 [=============>................] - ETA: 6s - loss: 226.6179 - s_output_loss: 140.7187 - t_output_loss: 85.8991
30080/60000 [==============>...............] - ETA: 6s - loss: 226.5257 - s_output_loss: 140.6628 - t_output_loss: 85.8628
30336/60000 [==============>...............] - ETA: 6s - loss: 226.4439 - s_output_loss: 140.6112 - t_output_loss: 85.8327
30592/60000 [==============>...............] - ETA: 5s - loss: 226.3105 - s_output_loss: 140.5330 - t_output_loss: 85.7775
30976/60000 [==============>...............] - ETA: 5s - loss: 226.0974 - s_output_loss: 140.4043 - t_output_loss: 85.6930
31232/60000 [==============>...............] - ETA: 5s - loss: 225.9606 - s_output_loss: 140.3234 - t_output_loss: 85.6372
31488/60000 [==============>...............] - ETA: 5s - loss: 225.9019 - s_output_loss: 140.2944 - t_output_loss: 85.6074
31744/60000 [==============>...............] - ETA: 5s - loss: 225.8436 - s_output_loss: 140.2753 - t_output_loss: 85.5683
32000/60000 [===============>..............] - ETA: 5s - loss: 225.7395 - s_output_loss: 140.2225 - t_output_loss: 85.5170
32256/60000 [===============>..............] - ETA: 5s - loss: 225.6352 - s_output_loss: 140.1643 - t_output_loss: 85.4709
32640/60000 [===============>..............] - ETA: 5s - loss: 225.5055 - s_output_loss: 140.0819 - t_output_loss: 85.4236
33024/60000 [===============>..............] - ETA: 5s - loss: 225.3950 - s_output_loss: 140.0206 - t_output_loss: 85.3744
33408/60000 [===============>..............] - ETA: 5s - loss: 225.2041 - s_output_loss: 139.9199 - t_output_loss: 85.2842
33664/60000 [===============>..............] - ETA: 5s - loss: 225.1110 - s_output_loss: 139.8803 - t_output_loss: 85.2307
34048/60000 [================>.............] - ETA: 5s - loss: 224.9326 - s_output_loss: 139.7795 - t_output_loss: 85.1531
34304/60000 [================>.............] - ETA: 5s - loss: 224.8599 - s_output_loss: 139.7547 - t_output_loss: 85.1052
34560/60000 [================>.............] - ETA: 5s - loss: 224.7931 - s_output_loss: 139.7171 - t_output_loss: 85.0760
34816/60000 [================>.............] - ETA: 5s - loss: 224.7520 - s_output_loss: 139.7179 - t_output_loss: 85.0341
35200/60000 [================>.............] - ETA: 5s - loss: 224.6310 - s_output_loss: 139.6463 - t_output_loss: 84.9847
35456/60000 [================>.............] - ETA: 4s - loss: 224.5036 - s_output_loss: 139.5712 - t_output_loss: 84.9324
35712/60000 [================>.............] - ETA: 4s - loss: 224.3983 - s_output_loss: 139.5147 - t_output_loss: 84.8836
35968/60000 [================>.............] - ETA: 4s - loss: 224.3205 - s_output_loss: 139.4729 - t_output_loss: 84.8477
36352/60000 [=================>............] - ETA: 4s - loss: 224.1748 - s_output_loss: 139.4039 - t_output_loss: 84.7708
36608/60000 [=================>............] - ETA: 4s - loss: 224.0782 - s_output_loss: 139.3461 - t_output_loss: 84.7321
36992/60000 [=================>............] - ETA: 4s - loss: 223.9398 - s_output_loss: 139.2783 - t_output_loss: 84.6615
37376/60000 [=================>............] - ETA: 4s - loss: 223.8291 - s_output_loss: 139.2194 - t_output_loss: 84.6097
37632/60000 [=================>............] - ETA: 4s - loss: 223.7514 - s_output_loss: 139.1840 - t_output_loss: 84.5674
38016/60000 [==================>...........] - ETA: 4s - loss: 223.6120 - s_output_loss: 139.1078 - t_output_loss: 84.5042
38400/60000 [==================>...........] - ETA: 4s - loss: 223.4493 - s_output_loss: 139.0034 - t_output_loss: 84.4459
38656/60000 [==================>...........] - ETA: 4s - loss: 223.3141 - s_output_loss: 138.9158 - t_output_loss: 84.3982
38912/60000 [==================>...........] - ETA: 4s - loss: 223.2140 - s_output_loss: 138.8527 - t_output_loss: 84.3613
39168/60000 [==================>...........] - ETA: 4s - loss: 223.1150 - s_output_loss: 138.7958 - t_output_loss: 84.3191
39552/60000 [==================>...........] - ETA: 4s - loss: 223.1000 - s_output_loss: 138.7462 - t_output_loss: 84.3538
39808/60000 [==================>...........] - ETA: 4s - loss: 223.2235 - s_output_loss: 138.6858 - t_output_loss: 84.5377
40064/60000 [===================>..........] - ETA: 4s - loss: 223.4138 - s_output_loss: 138.6294 - t_output_loss: 84.7844
40448/60000 [===================>..........] - ETA: 3s - loss: 223.5212 - s_output_loss: 138.5293 - t_output_loss: 84.9920
40704/60000 [===================>..........] - ETA: 3s - loss: 223.5406 - s_output_loss: 138.4664 - t_output_loss: 85.0742
40960/60000 [===================>..........] - ETA: 3s - loss: 223.6485 - s_output_loss: 138.4279 - t_output_loss: 85.2206
41216/60000 [===================>..........] - ETA: 3s - loss: 223.7679 - s_output_loss: 138.3711 - t_output_loss: 85.3968
41472/60000 [===================>..........] - ETA: 3s - loss: 223.9638 - s_output_loss: 138.3358 - t_output_loss: 85.6280
41728/60000 [===================>..........] - ETA: 3s - loss: 224.1301 - s_output_loss: 138.3032 - t_output_loss: 85.8269
42112/60000 [====================>.........] - ETA: 3s - loss: 224.2660 - s_output_loss: 138.2283 - t_output_loss: 86.0377
42368/60000 [====================>.........] - ETA: 3s - loss: 224.3390 - s_output_loss: 138.1920 - t_output_loss: 86.1470
42624/60000 [====================>.........] - ETA: 3s - loss: 224.4669 - s_output_loss: 138.2233 - t_output_loss: 86.2436
42880/60000 [====================>.........] - ETA: 3s - loss: 224.5172 - s_output_loss: 138.1973 - t_output_loss: 86.3199
43136/60000 [====================>.........] - ETA: 3s - loss: 224.6053 - s_output_loss: 138.1942 - t_output_loss: 86.4111
43392/60000 [====================>.........] - ETA: 3s - loss: 224.7134 - s_output_loss: 138.2158 - t_output_loss: 86.4976
43776/60000 [====================>.........] - ETA: 3s - loss: 224.8418 - s_output_loss: 138.2446 - t_output_loss: 86.5972
44032/60000 [=====================>........] - ETA: 3s - loss: 224.8771 - s_output_loss: 138.2269 - t_output_loss: 86.6502
44416/60000 [=====================>........] - ETA: 3s - loss: 224.9104 - s_output_loss: 138.1974 - t_output_loss: 86.7129
44672/60000 [=====================>........] - ETA: 3s - loss: 224.9979 - s_output_loss: 138.2320 - t_output_loss: 86.7659
45056/60000 [=====================>........] - ETA: 3s - loss: 225.1254 - s_output_loss: 138.3050 - t_output_loss: 86.8204
45312/60000 [=====================>........] - ETA: 2s - loss: 225.2144 - s_output_loss: 138.3520 - t_output_loss: 86.8624
45568/60000 [=====================>........] - ETA: 2s - loss: 225.2855 - s_output_loss: 138.3837 - t_output_loss: 86.9019
45824/60000 [=====================>........] - ETA: 2s - loss: 225.3303 - s_output_loss: 138.4103 - t_output_loss: 86.9200
46208/60000 [======================>.......] - ETA: 2s - loss: 225.3790 - s_output_loss: 138.4315 - t_output_loss: 86.9475
46464/60000 [======================>.......] - ETA: 2s - loss: 225.3946 - s_output_loss: 138.4371 - t_output_loss: 86.9576
46720/60000 [======================>.......] - ETA: 2s - loss: 225.4426 - s_output_loss: 138.4660 - t_output_loss: 86.9766
47104/60000 [======================>.......] - ETA: 2s - loss: 225.5017 - s_output_loss: 138.5277 - t_output_loss: 86.9740
47360/60000 [======================>.......] - ETA: 2s - loss: 225.5437 - s_output_loss: 138.5518 - t_output_loss: 86.9919
47616/60000 [======================>.......] - ETA: 2s - loss: 225.5469 - s_output_loss: 138.5514 - t_output_loss: 86.9954
47872/60000 [======================>.......] - ETA: 2s - loss: 225.5295 - s_output_loss: 138.5418 - t_output_loss: 86.9877
48128/60000 [=======================>......] - ETA: 2s - loss: 225.5232 - s_output_loss: 138.5319 - t_output_loss: 86.9913
48384/60000 [=======================>......] - ETA: 2s - loss: 225.4853 - s_output_loss: 138.4988 - t_output_loss: 86.9865
48640/60000 [=======================>......] - ETA: 2s - loss: 225.4946 - s_output_loss: 138.5009 - t_output_loss: 86.9937
48896/60000 [=======================>......] - ETA: 2s - loss: 225.4653 - s_output_loss: 138.4850 - t_output_loss: 86.9803
49152/60000 [=======================>......] - ETA: 2s - loss: 225.4569 - s_output_loss: 138.4717 - t_output_loss: 86.9852
49408/60000 [=======================>......] - ETA: 2s - loss: 225.4285 - s_output_loss: 138.4544 - t_output_loss: 86.9741
49664/60000 [=======================>......] - ETA: 2s - loss: 225.3646 - s_output_loss: 138.4166 - t_output_loss: 86.9481
49920/60000 [=======================>......] - ETA: 2s - loss: 225.3536 - s_output_loss: 138.4042 - t_output_loss: 86.9494
50176/60000 [========================>.....] - ETA: 1s - loss: 225.2850 - s_output_loss: 138.3623 - t_output_loss: 86.9226
50432/60000 [========================>.....] - ETA: 1s - loss: 225.2689 - s_output_loss: 138.3457 - t_output_loss: 86.9232
50688/60000 [========================>.....] - ETA: 1s - loss: 225.1982 - s_output_loss: 138.3051 - t_output_loss: 86.8931
50944/60000 [========================>.....] - ETA: 1s - loss: 225.1678 - s_output_loss: 138.2859 - t_output_loss: 86.8818
51200/60000 [========================>.....] - ETA: 1s - loss: 225.1256 - s_output_loss: 138.2461 - t_output_loss: 86.8796
51456/60000 [========================>.....] - ETA: 1s - loss: 225.0942 - s_output_loss: 138.2188 - t_output_loss: 86.8754
51712/60000 [========================>.....] - ETA: 1s - loss: 225.0749 - s_output_loss: 138.1985 - t_output_loss: 86.8764
51968/60000 [========================>.....] - ETA: 1s - loss: 225.0262 - s_output_loss: 138.1636 - t_output_loss: 86.8626
52224/60000 [=========================>....] - ETA: 1s - loss: 224.9650 - s_output_loss: 138.1220 - t_output_loss: 86.8430
52608/60000 [=========================>....] - ETA: 1s - loss: 224.8640 - s_output_loss: 138.0542 - t_output_loss: 86.8098
52864/60000 [=========================>....] - ETA: 1s - loss: 224.8124 - s_output_loss: 138.0248 - t_output_loss: 86.7876
53120/60000 [=========================>....] - ETA: 1s - loss: 224.7477 - s_output_loss: 137.9909 - t_output_loss: 86.7568
53376/60000 [=========================>....] - ETA: 1s - loss: 224.7541 - s_output_loss: 138.0077 - t_output_loss: 86.7464
53632/60000 [=========================>....] - ETA: 1s - loss: 224.7653 - s_output_loss: 138.0364 - t_output_loss: 86.7289
53888/60000 [=========================>....] - ETA: 1s - loss: 224.7834 - s_output_loss: 138.0567 - t_output_loss: 86.7268
54144/60000 [==========================>...] - ETA: 1s - loss: 224.7439 - s_output_loss: 138.0506 - t_output_loss: 86.6933
54400/60000 [==========================>...] - ETA: 1s - loss: 224.7046 - s_output_loss: 138.0374 - t_output_loss: 86.6672
54656/60000 [==========================>...] - ETA: 1s - loss: 224.7091 - s_output_loss: 138.0537 - t_output_loss: 86.6554
55040/60000 [==========================>...] - ETA: 1s - loss: 224.6271 - s_output_loss: 138.0105 - t_output_loss: 86.6166
55296/60000 [==========================>...] - ETA: 0s - loss: 224.5739 - s_output_loss: 137.9769 - t_output_loss: 86.5970
55552/60000 [==========================>...] - ETA: 0s - loss: 224.5466 - s_output_loss: 137.9638 - t_output_loss: 86.5828
55808/60000 [==========================>...] - ETA: 0s - loss: 224.4634 - s_output_loss: 137.9249 - t_output_loss: 86.5385
56192/60000 [===========================>..] - ETA: 0s - loss: 224.4261 - s_output_loss: 137.9053 - t_output_loss: 86.5208
56448/60000 [===========================>..] - ETA: 0s - loss: 224.3670 - s_output_loss: 137.8751 - t_output_loss: 86.4920
56832/60000 [===========================>..] - ETA: 0s - loss: 224.2817 - s_output_loss: 137.8266 - t_output_loss: 86.4551
57088/60000 [===========================>..] - ETA: 0s - loss: 224.2148 - s_output_loss: 137.7862 - t_output_loss: 86.4286
57472/60000 [===========================>..] - ETA: 0s - loss: 224.1307 - s_output_loss: 137.7485 - t_output_loss: 86.3822
57728/60000 [===========================>..] - ETA: 0s - loss: 224.0750 - s_output_loss: 137.7249 - t_output_loss: 86.3500
57984/60000 [===========================>..] - ETA: 0s - loss: 224.0327 - s_output_loss: 137.7136 - t_output_loss: 86.3191
58240/60000 [============================>.] - ETA: 0s - loss: 224.0006 - s_output_loss: 137.7027 - t_output_loss: 86.2979
58496/60000 [============================>.] - ETA: 0s - loss: 223.9460 - s_output_loss: 137.6715 - t_output_loss: 86.2745
58752/60000 [============================>.] - ETA: 0s - loss: 223.8698 - s_output_loss: 137.6324 - t_output_loss: 86.2373
59136/60000 [============================>.] - ETA: 0s - loss: 223.7784 - s_output_loss: 137.5848 - t_output_loss: 86.1935
59520/60000 [============================>.] - ETA: 0s - loss: 223.6751 - s_output_loss: 137.5243 - t_output_loss: 86.1508
59904/60000 [============================>.] - ETA: 0s - loss: 223.6066 - s_output_loss: 137.4925 - t_output_loss: 86.1141
60000/60000 [==============================] - 13s 213us/step - loss: 223.5861 - s_output_loss: 137.4811 - t_output_loss: 86.1050 - val_loss: 214.2859 - val_s_output_loss: 130.2696 - val_t_output_loss: 84.0163
Epoch 4/10

  128/60000 [..............................] - ETA: 15s - loss: 210.1464 - s_output_loss: 129.6275 - t_output_loss: 80.5189
  384/60000 [..............................] - ETA: 13s - loss: 213.2689 - s_output_loss: 132.9715 - t_output_loss: 80.2974
  768/60000 [..............................] - ETA: 12s - loss: 213.4857 - s_output_loss: 132.2415 - t_output_loss: 81.2442
 1024/60000 [..............................] - ETA: 12s - loss: 211.6064 - s_output_loss: 131.0396 - t_output_loss: 80.5667
 1280/60000 [..............................] - ETA: 12s - loss: 210.4207 - s_output_loss: 130.4881 - t_output_loss: 79.9326
 1536/60000 [..............................] - ETA: 12s - loss: 210.1011 - s_output_loss: 130.0587 - t_output_loss: 80.0424
 1792/60000 [..............................] - ETA: 12s - loss: 211.1148 - s_output_loss: 130.5150 - t_output_loss: 80.5997
 2048/60000 [>.............................] - ETA: 12s - loss: 211.0783 - s_output_loss: 130.5943 - t_output_loss: 80.4840
 2304/60000 [>.............................] - ETA: 11s - loss: 210.8168 - s_output_loss: 130.4066 - t_output_loss: 80.4101
 2560/60000 [>.............................] - ETA: 12s - loss: 209.9523 - s_output_loss: 129.9351 - t_output_loss: 80.0172
 2816/60000 [>.............................] - ETA: 11s - loss: 209.7866 - s_output_loss: 129.8584 - t_output_loss: 79.9282
 3072/60000 [>.............................] - ETA: 11s - loss: 209.2543 - s_output_loss: 129.4987 - t_output_loss: 79.7556
 3328/60000 [>.............................] - ETA: 11s - loss: 209.0227 - s_output_loss: 129.2328 - t_output_loss: 79.7899
 3584/60000 [>.............................] - ETA: 11s - loss: 208.8299 - s_output_loss: 129.1393 - t_output_loss: 79.6907
 3840/60000 [>.............................] - ETA: 11s - loss: 208.6196 - s_output_loss: 129.0805 - t_output_loss: 79.5391
 4096/60000 [=>............................] - ETA: 11s - loss: 209.0001 - s_output_loss: 129.5022 - t_output_loss: 79.4980
 4480/60000 [=>............................] - ETA: 11s - loss: 209.5965 - s_output_loss: 129.9407 - t_output_loss: 79.6558
 4736/60000 [=>............................] - ETA: 11s - loss: 209.7258 - s_output_loss: 130.1031 - t_output_loss: 79.6227
 4992/60000 [=>............................] - ETA: 11s - loss: 209.4061 - s_output_loss: 129.9727 - t_output_loss: 79.4333
 5376/60000 [=>............................] - ETA: 11s - loss: 209.8078 - s_output_loss: 130.2569 - t_output_loss: 79.5509
 5760/60000 [=>............................] - ETA: 11s - loss: 209.8340 - s_output_loss: 130.2830 - t_output_loss: 79.5509
 6144/60000 [==>...........................] - ETA: 11s - loss: 209.7453 - s_output_loss: 130.2254 - t_output_loss: 79.5199
 6400/60000 [==>...........................] - ETA: 11s - loss: 209.7043 - s_output_loss: 130.1997 - t_output_loss: 79.5046
 6784/60000 [==>...........................] - ETA: 10s - loss: 209.8810 - s_output_loss: 130.3998 - t_output_loss: 79.4813
 7040/60000 [==>...........................] - ETA: 10s - loss: 210.2570 - s_output_loss: 130.6843 - t_output_loss: 79.5727
 7296/60000 [==>...........................] - ETA: 10s - loss: 209.9331 - s_output_loss: 130.5435 - t_output_loss: 79.3896
 7552/60000 [==>...........................] - ETA: 10s - loss: 210.1438 - s_output_loss: 130.7042 - t_output_loss: 79.4396
 7808/60000 [==>...........................] - ETA: 10s - loss: 210.2074 - s_output_loss: 130.7763 - t_output_loss: 79.4311
 8192/60000 [===>..........................] - ETA: 10s - loss: 210.2287 - s_output_loss: 130.7866 - t_output_loss: 79.4420
 8576/60000 [===>..........................] - ETA: 10s - loss: 210.2595 - s_output_loss: 130.7391 - t_output_loss: 79.5205
 8832/60000 [===>..........................] - ETA: 10s - loss: 210.2969 - s_output_loss: 130.7690 - t_output_loss: 79.5278
 9088/60000 [===>..........................] - ETA: 10s - loss: 210.0791 - s_output_loss: 130.6798 - t_output_loss: 79.3993
 9344/60000 [===>..........................] - ETA: 10s - loss: 210.0656 - s_output_loss: 130.7140 - t_output_loss: 79.3516
 9600/60000 [===>..........................] - ETA: 10s - loss: 209.9911 - s_output_loss: 130.6756 - t_output_loss: 79.3154
 9984/60000 [===>..........................] - ETA: 10s - loss: 209.9542 - s_output_loss: 130.6486 - t_output_loss: 79.3056
10240/60000 [====>.........................] - ETA: 10s - loss: 209.9411 - s_output_loss: 130.6547 - t_output_loss: 79.2864
10624/60000 [====>.........................] - ETA: 10s - loss: 209.9053 - s_output_loss: 130.6603 - t_output_loss: 79.2450
10880/60000 [====>.........................] - ETA: 10s - loss: 209.8691 - s_output_loss: 130.6553 - t_output_loss: 79.2138
11136/60000 [====>.........................] - ETA: 9s - loss: 209.6748 - s_output_loss: 130.5511 - t_output_loss: 79.1237 
11392/60000 [====>.........................] - ETA: 9s - loss: 209.5089 - s_output_loss: 130.4375 - t_output_loss: 79.0713
11648/60000 [====>.........................] - ETA: 9s - loss: 209.3909 - s_output_loss: 130.3769 - t_output_loss: 79.0140
11904/60000 [====>.........................] - ETA: 9s - loss: 209.2428 - s_output_loss: 130.2655 - t_output_loss: 78.9773
12160/60000 [=====>........................] - ETA: 9s - loss: 209.2144 - s_output_loss: 130.2016 - t_output_loss: 79.0128
12544/60000 [=====>........................] - ETA: 9s - loss: 209.6478 - s_output_loss: 130.1965 - t_output_loss: 79.4513
12800/60000 [=====>........................] - ETA: 9s - loss: 209.9824 - s_output_loss: 130.2061 - t_output_loss: 79.7763
13056/60000 [=====>........................] - ETA: 9s - loss: 210.1877 - s_output_loss: 130.1224 - t_output_loss: 80.0653
13312/60000 [=====>........................] - ETA: 9s - loss: 210.3841 - s_output_loss: 130.0346 - t_output_loss: 80.3496
13568/60000 [=====>........................] - ETA: 9s - loss: 210.8539 - s_output_loss: 130.1686 - t_output_loss: 80.6853
13824/60000 [=====>........................] - ETA: 9s - loss: 212.1320 - s_output_loss: 131.1861 - t_output_loss: 80.9459
14080/60000 [======>.......................] - ETA: 9s - loss: 213.5995 - s_output_loss: 132.4668 - t_output_loss: 81.1327
14336/60000 [======>.......................] - ETA: 9s - loss: 214.6777 - s_output_loss: 133.3071 - t_output_loss: 81.3706
14720/60000 [======>.......................] - ETA: 9s - loss: 215.5029 - s_output_loss: 133.9109 - t_output_loss: 81.5920
14976/60000 [======>.......................] - ETA: 9s - loss: 215.9971 - s_output_loss: 134.2955 - t_output_loss: 81.7016
15232/60000 [======>.......................] - ETA: 9s - loss: 216.4264 - s_output_loss: 134.6823 - t_output_loss: 81.7441
15488/60000 [======>.......................] - ETA: 9s - loss: 216.8758 - s_output_loss: 135.0288 - t_output_loss: 81.8470
15744/60000 [======>.......................] - ETA: 9s - loss: 217.2780 - s_output_loss: 135.2973 - t_output_loss: 81.9807
16000/60000 [=======>......................] - ETA: 9s - loss: 217.5498 - s_output_loss: 135.5113 - t_output_loss: 82.0386
16256/60000 [=======>......................] - ETA: 8s - loss: 217.7335 - s_output_loss: 135.6497 - t_output_loss: 82.0838
16512/60000 [=======>......................] - ETA: 8s - loss: 217.9216 - s_output_loss: 135.7743 - t_output_loss: 82.1473
16768/60000 [=======>......................] - ETA: 8s - loss: 218.0731 - s_output_loss: 135.8794 - t_output_loss: 82.1937
17024/60000 [=======>......................] - ETA: 8s - loss: 218.2578 - s_output_loss: 136.0104 - t_output_loss: 82.2474
17408/60000 [=======>......................] - ETA: 8s - loss: 218.2784 - s_output_loss: 136.0086 - t_output_loss: 82.2698
17664/60000 [=======>......................] - ETA: 8s - loss: 218.3165 - s_output_loss: 136.0146 - t_output_loss: 82.3019
17920/60000 [=======>......................] - ETA: 8s - loss: 218.3500 - s_output_loss: 136.0344 - t_output_loss: 82.3156
18304/60000 [========>.....................] - ETA: 8s - loss: 218.3913 - s_output_loss: 136.0240 - t_output_loss: 82.3674
18560/60000 [========>.....................] - ETA: 8s - loss: 218.4096 - s_output_loss: 135.9977 - t_output_loss: 82.4118
18816/60000 [========>.....................] - ETA: 8s - loss: 218.3043 - s_output_loss: 135.9069 - t_output_loss: 82.3973
19200/60000 [========>.....................] - ETA: 8s - loss: 218.1480 - s_output_loss: 135.7832 - t_output_loss: 82.3647
19456/60000 [========>.....................] - ETA: 8s - loss: 218.0874 - s_output_loss: 135.7425 - t_output_loss: 82.3449
19712/60000 [========>.....................] - ETA: 8s - loss: 217.9598 - s_output_loss: 135.6691 - t_output_loss: 82.2906
19968/60000 [========>.....................] - ETA: 8s - loss: 217.9426 - s_output_loss: 135.6459 - t_output_loss: 82.2966
20352/60000 [=========>....................] - ETA: 8s - loss: 217.7993 - s_output_loss: 135.5543 - t_output_loss: 82.2450
20608/60000 [=========>....................] - ETA: 8s - loss: 217.7514 - s_output_loss: 135.4948 - t_output_loss: 82.2566
20864/60000 [=========>....................] - ETA: 7s - loss: 217.7445 - s_output_loss: 135.4651 - t_output_loss: 82.2794
21120/60000 [=========>....................] - ETA: 7s - loss: 217.6776 - s_output_loss: 135.3752 - t_output_loss: 82.3024
21376/60000 [=========>....................] - ETA: 7s - loss: 217.7116 - s_output_loss: 135.3667 - t_output_loss: 82.3449
21632/60000 [=========>....................] - ETA: 7s - loss: 217.5918 - s_output_loss: 135.2580 - t_output_loss: 82.3338
21888/60000 [=========>....................] - ETA: 7s - loss: 217.5957 - s_output_loss: 135.2242 - t_output_loss: 82.3714
22144/60000 [==========>...................] - ETA: 7s - loss: 217.5209 - s_output_loss: 135.1473 - t_output_loss: 82.3736
22400/60000 [==========>...................] - ETA: 7s - loss: 217.4981 - s_output_loss: 135.1163 - t_output_loss: 82.3818
22784/60000 [==========>...................] - ETA: 7s - loss: 217.2529 - s_output_loss: 134.9264 - t_output_loss: 82.3265
23040/60000 [==========>...................] - ETA: 7s - loss: 217.1273 - s_output_loss: 134.8287 - t_output_loss: 82.2987
23296/60000 [==========>...................] - ETA: 7s - loss: 217.0084 - s_output_loss: 134.7241 - t_output_loss: 82.2843
23552/60000 [==========>...................] - ETA: 7s - loss: 217.0299 - s_output_loss: 134.7575 - t_output_loss: 82.2723
23808/60000 [==========>...................] - ETA: 7s - loss: 217.0599 - s_output_loss: 134.7956 - t_output_loss: 82.2643
24064/60000 [===========>..................] - ETA: 7s - loss: 217.0080 - s_output_loss: 134.7754 - t_output_loss: 82.2326
24320/60000 [===========>..................] - ETA: 7s - loss: 216.9489 - s_output_loss: 134.7324 - t_output_loss: 82.2165
24576/60000 [===========>..................] - ETA: 7s - loss: 217.0684 - s_output_loss: 134.7550 - t_output_loss: 82.3135
24832/60000 [===========>..................] - ETA: 7s - loss: 217.1644 - s_output_loss: 134.6678 - t_output_loss: 82.4966
25088/60000 [===========>..................] - ETA: 7s - loss: 217.4546 - s_output_loss: 134.6545 - t_output_loss: 82.8001
25344/60000 [===========>..................] - ETA: 7s - loss: 217.6438 - s_output_loss: 134.6019 - t_output_loss: 83.0419
25600/60000 [===========>..................] - ETA: 7s - loss: 217.8527 - s_output_loss: 134.5475 - t_output_loss: 83.3052
25856/60000 [===========>..................] - ETA: 6s - loss: 217.9975 - s_output_loss: 134.5221 - t_output_loss: 83.4755
26240/60000 [============>.................] - ETA: 6s - loss: 218.2188 - s_output_loss: 134.5184 - t_output_loss: 83.7004
26496/60000 [============>.................] - ETA: 6s - loss: 218.2037 - s_output_loss: 134.4402 - t_output_loss: 83.7636
26752/60000 [============>.................] - ETA: 6s - loss: 218.1774 - s_output_loss: 134.3574 - t_output_loss: 83.8200
27136/60000 [============>.................] - ETA: 6s - loss: 218.2443 - s_output_loss: 134.3320 - t_output_loss: 83.9123
27392/60000 [============>.................] - ETA: 6s - loss: 218.2642 - s_output_loss: 134.3013 - t_output_loss: 83.9629
27648/60000 [============>.................] - ETA: 6s - loss: 218.2853 - s_output_loss: 134.2573 - t_output_loss: 84.0280
27904/60000 [============>.................] - ETA: 6s - loss: 218.2939 - s_output_loss: 134.2112 - t_output_loss: 84.0826
28160/60000 [=============>................] - ETA: 6s - loss: 218.2268 - s_output_loss: 134.1172 - t_output_loss: 84.1096
28416/60000 [=============>................] - ETA: 6s - loss: 218.2642 - s_output_loss: 134.0947 - t_output_loss: 84.1696
28672/60000 [=============>................] - ETA: 6s - loss: 218.1992 - s_output_loss: 134.0129 - t_output_loss: 84.1863
29056/60000 [=============>................] - ETA: 6s - loss: 218.1862 - s_output_loss: 133.9606 - t_output_loss: 84.2256
29440/60000 [=============>................] - ETA: 6s - loss: 218.0761 - s_output_loss: 133.8611 - t_output_loss: 84.2150
29696/60000 [=============>................] - ETA: 6s - loss: 217.9841 - s_output_loss: 133.7781 - t_output_loss: 84.2060
30080/60000 [==============>...............] - ETA: 6s - loss: 217.9188 - s_output_loss: 133.7334 - t_output_loss: 84.1854
30464/60000 [==============>...............] - ETA: 6s - loss: 217.8080 - s_output_loss: 133.6479 - t_output_loss: 84.1600
30720/60000 [==============>...............] - ETA: 5s - loss: 217.7248 - s_output_loss: 133.5907 - t_output_loss: 84.1341
30976/60000 [==============>...............] - ETA: 5s - loss: 217.6030 - s_output_loss: 133.5063 - t_output_loss: 84.0967
31232/60000 [==============>...............] - ETA: 5s - loss: 217.4997 - s_output_loss: 133.4262 - t_output_loss: 84.0735
31616/60000 [==============>...............] - ETA: 5s - loss: 217.4161 - s_output_loss: 133.3373 - t_output_loss: 84.0789
31872/60000 [==============>...............] - ETA: 5s - loss: 217.3400 - s_output_loss: 133.2687 - t_output_loss: 84.0713
32256/60000 [===============>..............] - ETA: 5s - loss: 217.2382 - s_output_loss: 133.1960 - t_output_loss: 84.0422
32640/60000 [===============>..............] - ETA: 5s - loss: 217.1600 - s_output_loss: 133.1366 - t_output_loss: 84.0234
33024/60000 [===============>..............] - ETA: 5s - loss: 216.9856 - s_output_loss: 133.0337 - t_output_loss: 83.9519
33280/60000 [===============>..............] - ETA: 5s - loss: 216.9484 - s_output_loss: 133.0170 - t_output_loss: 83.9314
33536/60000 [===============>..............] - ETA: 5s - loss: 216.9000 - s_output_loss: 132.9776 - t_output_loss: 83.9224
33792/60000 [===============>..............] - ETA: 5s - loss: 216.8405 - s_output_loss: 132.9396 - t_output_loss: 83.9010
34048/60000 [================>.............] - ETA: 5s - loss: 216.7700 - s_output_loss: 132.8943 - t_output_loss: 83.8757
34432/60000 [================>.............] - ETA: 5s - loss: 216.6885 - s_output_loss: 132.8386 - t_output_loss: 83.8499
34688/60000 [================>.............] - ETA: 5s - loss: 216.5969 - s_output_loss: 132.7828 - t_output_loss: 83.8140
34944/60000 [================>.............] - ETA: 5s - loss: 216.5282 - s_output_loss: 132.7355 - t_output_loss: 83.7928
35328/60000 [================>.............] - ETA: 5s - loss: 216.4059 - s_output_loss: 132.6622 - t_output_loss: 83.7437
35584/60000 [================>.............] - ETA: 4s - loss: 216.3060 - s_output_loss: 132.6013 - t_output_loss: 83.7046
35840/60000 [================>.............] - ETA: 4s - loss: 216.2608 - s_output_loss: 132.5753 - t_output_loss: 83.6855
36096/60000 [=================>............] - ETA: 4s - loss: 216.1917 - s_output_loss: 132.5409 - t_output_loss: 83.6508
36352/60000 [=================>............] - ETA: 4s - loss: 216.0861 - s_output_loss: 132.4960 - t_output_loss: 83.5901
36736/60000 [=================>............] - ETA: 4s - loss: 215.9541 - s_output_loss: 132.4095 - t_output_loss: 83.5446
37120/60000 [=================>............] - ETA: 4s - loss: 215.8339 - s_output_loss: 132.3416 - t_output_loss: 83.4923
37504/60000 [=================>............] - ETA: 4s - loss: 215.7679 - s_output_loss: 132.2961 - t_output_loss: 83.4718
37760/60000 [=================>............] - ETA: 4s - loss: 215.7003 - s_output_loss: 132.2432 - t_output_loss: 83.4571
38016/60000 [==================>...........] - ETA: 4s - loss: 215.5940 - s_output_loss: 132.1857 - t_output_loss: 83.4083
38272/60000 [==================>...........] - ETA: 4s - loss: 215.4898 - s_output_loss: 132.1215 - t_output_loss: 83.3683
38528/60000 [==================>...........] - ETA: 4s - loss: 215.4540 - s_output_loss: 132.0853 - t_output_loss: 83.3687
38912/60000 [==================>...........] - ETA: 4s - loss: 215.3364 - s_output_loss: 132.0216 - t_output_loss: 83.3147
39296/60000 [==================>...........] - ETA: 4s - loss: 215.2146 - s_output_loss: 131.9535 - t_output_loss: 83.2611
39552/60000 [==================>...........] - ETA: 4s - loss: 215.1494 - s_output_loss: 131.9126 - t_output_loss: 83.2368
39808/60000 [==================>...........] - ETA: 4s - loss: 215.1322 - s_output_loss: 131.9041 - t_output_loss: 83.2281
40064/60000 [===================>..........] - ETA: 4s - loss: 215.0630 - s_output_loss: 131.8702 - t_output_loss: 83.1928
40320/60000 [===================>..........] - ETA: 4s - loss: 214.9811 - s_output_loss: 131.8261 - t_output_loss: 83.1550
40576/60000 [===================>..........] - ETA: 3s - loss: 214.9486 - s_output_loss: 131.8116 - t_output_loss: 83.1369
40832/60000 [===================>..........] - ETA: 3s - loss: 214.8367 - s_output_loss: 131.7476 - t_output_loss: 83.0891
41088/60000 [===================>..........] - ETA: 3s - loss: 214.7738 - s_output_loss: 131.7187 - t_output_loss: 83.0551
41472/60000 [===================>..........] - ETA: 3s - loss: 214.6715 - s_output_loss: 131.6811 - t_output_loss: 82.9904
41728/60000 [===================>..........] - ETA: 3s - loss: 214.6360 - s_output_loss: 131.6773 - t_output_loss: 82.9587
42112/60000 [====================>.........] - ETA: 3s - loss: 214.5587 - s_output_loss: 131.6440 - t_output_loss: 82.9147
42496/60000 [====================>.........] - ETA: 3s - loss: 214.4601 - s_output_loss: 131.5914 - t_output_loss: 82.8686
42752/60000 [====================>.........] - ETA: 3s - loss: 214.4002 - s_output_loss: 131.5541 - t_output_loss: 82.8461
43008/60000 [====================>.........] - ETA: 3s - loss: 214.3574 - s_output_loss: 131.5323 - t_output_loss: 82.8252
43264/60000 [====================>.........] - ETA: 3s - loss: 214.2720 - s_output_loss: 131.4877 - t_output_loss: 82.7843
43520/60000 [====================>.........] - ETA: 3s - loss: 214.1943 - s_output_loss: 131.4484 - t_output_loss: 82.7458
43776/60000 [====================>.........] - ETA: 3s - loss: 214.1440 - s_output_loss: 131.4259 - t_output_loss: 82.7181
44160/60000 [=====================>........] - ETA: 3s - loss: 214.0810 - s_output_loss: 131.4091 - t_output_loss: 82.6719
44416/60000 [=====================>........] - ETA: 3s - loss: 214.0368 - s_output_loss: 131.3947 - t_output_loss: 82.6421
44800/60000 [=====================>........] - ETA: 3s - loss: 213.9283 - s_output_loss: 131.3364 - t_output_loss: 82.5919
45056/60000 [=====================>........] - ETA: 3s - loss: 213.8909 - s_output_loss: 131.3231 - t_output_loss: 82.5679
45312/60000 [=====================>........] - ETA: 2s - loss: 213.8393 - s_output_loss: 131.3016 - t_output_loss: 82.5376
45568/60000 [=====================>........] - ETA: 2s - loss: 213.7701 - s_output_loss: 131.2657 - t_output_loss: 82.5045
45952/60000 [=====================>........] - ETA: 2s - loss: 213.6470 - s_output_loss: 131.2055 - t_output_loss: 82.4415
46336/60000 [======================>.......] - ETA: 2s - loss: 213.5150 - s_output_loss: 131.1323 - t_output_loss: 82.3827
46592/60000 [======================>.......] - ETA: 2s - loss: 213.4536 - s_output_loss: 131.1068 - t_output_loss: 82.3468
46848/60000 [======================>.......] - ETA: 2s - loss: 213.3997 - s_output_loss: 131.0880 - t_output_loss: 82.3116
47104/60000 [======================>.......] - ETA: 2s - loss: 213.3696 - s_output_loss: 131.0824 - t_output_loss: 82.2872
47360/60000 [======================>.......] - ETA: 2s - loss: 213.3188 - s_output_loss: 131.0572 - t_output_loss: 82.2617
47744/60000 [======================>.......] - ETA: 2s - loss: 213.2110 - s_output_loss: 130.9972 - t_output_loss: 82.2138
48000/60000 [=======================>......] - ETA: 2s - loss: 213.1610 - s_output_loss: 130.9632 - t_output_loss: 82.1978
48256/60000 [=======================>......] - ETA: 2s - loss: 213.0661 - s_output_loss: 130.8976 - t_output_loss: 82.1685
48512/60000 [=======================>......] - ETA: 2s - loss: 212.9960 - s_output_loss: 130.8559 - t_output_loss: 82.1401
48768/60000 [=======================>......] - ETA: 2s - loss: 212.9246 - s_output_loss: 130.8172 - t_output_loss: 82.1074
49024/60000 [=======================>......] - ETA: 2s - loss: 212.8600 - s_output_loss: 130.7900 - t_output_loss: 82.0700
49280/60000 [=======================>......] - ETA: 2s - loss: 212.8063 - s_output_loss: 130.7508 - t_output_loss: 82.0555
49536/60000 [=======================>......] - ETA: 2s - loss: 212.7532 - s_output_loss: 130.7210 - t_output_loss: 82.0322
49920/60000 [=======================>......] - ETA: 2s - loss: 212.7032 - s_output_loss: 130.6999 - t_output_loss: 82.0032
50304/60000 [========================>.....] - ETA: 1s - loss: 212.5891 - s_output_loss: 130.6360 - t_output_loss: 81.9532
50560/60000 [========================>.....] - ETA: 1s - loss: 212.5478 - s_output_loss: 130.6171 - t_output_loss: 81.9307
50944/60000 [========================>.....] - ETA: 1s - loss: 212.4910 - s_output_loss: 130.5866 - t_output_loss: 81.9043
51200/60000 [========================>.....] - ETA: 1s - loss: 212.4220 - s_output_loss: 130.5424 - t_output_loss: 81.8795
51456/60000 [========================>.....] - ETA: 1s - loss: 212.3500 - s_output_loss: 130.5079 - t_output_loss: 81.8422
51712/60000 [========================>.....] - ETA: 1s - loss: 212.2966 - s_output_loss: 130.4906 - t_output_loss: 81.8061
51968/60000 [========================>.....] - ETA: 1s - loss: 212.3303 - s_output_loss: 130.5431 - t_output_loss: 81.7872
52224/60000 [=========================>....] - ETA: 1s - loss: 212.4476 - s_output_loss: 130.6735 - t_output_loss: 81.7741
52608/60000 [=========================>....] - ETA: 1s - loss: 212.5628 - s_output_loss: 130.8146 - t_output_loss: 81.7482
52864/60000 [=========================>....] - ETA: 1s - loss: 212.5776 - s_output_loss: 130.8510 - t_output_loss: 81.7266
53248/60000 [=========================>....] - ETA: 1s - loss: 212.5858 - s_output_loss: 130.9057 - t_output_loss: 81.6801
53504/60000 [=========================>....] - ETA: 1s - loss: 212.6227 - s_output_loss: 130.9675 - t_output_loss: 81.6552
53760/60000 [=========================>....] - ETA: 1s - loss: 212.6354 - s_output_loss: 131.0056 - t_output_loss: 81.6299
54016/60000 [==========================>...] - ETA: 1s - loss: 212.6410 - s_output_loss: 131.0394 - t_output_loss: 81.6015
54272/60000 [==========================>...] - ETA: 1s - loss: 212.6500 - s_output_loss: 131.0735 - t_output_loss: 81.5765
54528/60000 [==========================>...] - ETA: 1s - loss: 212.6526 - s_output_loss: 131.1020 - t_output_loss: 81.5506
54784/60000 [==========================>...] - ETA: 1s - loss: 212.6060 - s_output_loss: 131.0909 - t_output_loss: 81.5151
55040/60000 [==========================>...] - ETA: 1s - loss: 212.6002 - s_output_loss: 131.1055 - t_output_loss: 81.4947
55424/60000 [==========================>...] - ETA: 0s - loss: 212.5506 - s_output_loss: 131.1012 - t_output_loss: 81.4494
55808/60000 [==========================>...] - ETA: 0s - loss: 212.4875 - s_output_loss: 131.0794 - t_output_loss: 81.4082
56064/60000 [===========================>..] - ETA: 0s - loss: 212.4592 - s_output_loss: 131.0667 - t_output_loss: 81.3926
56320/60000 [===========================>..] - ETA: 0s - loss: 212.4215 - s_output_loss: 131.0456 - t_output_loss: 81.3759
56576/60000 [===========================>..] - ETA: 0s - loss: 212.3922 - s_output_loss: 131.0370 - t_output_loss: 81.3552
56960/60000 [===========================>..] - ETA: 0s - loss: 212.3342 - s_output_loss: 131.0123 - t_output_loss: 81.3219
57344/60000 [===========================>..] - ETA: 0s - loss: 212.3157 - s_output_loss: 131.0022 - t_output_loss: 81.3136
57600/60000 [===========================>..] - ETA: 0s - loss: 212.3350 - s_output_loss: 130.9880 - t_output_loss: 81.3470
57856/60000 [===========================>..] - ETA: 0s - loss: 212.3952 - s_output_loss: 130.9958 - t_output_loss: 81.3993
58112/60000 [============================>.] - ETA: 0s - loss: 212.4526 - s_output_loss: 131.0043 - t_output_loss: 81.4482
58496/60000 [============================>.] - ETA: 0s - loss: 212.5026 - s_output_loss: 131.0050 - t_output_loss: 81.4976
58752/60000 [============================>.] - ETA: 0s - loss: 212.5223 - s_output_loss: 130.9897 - t_output_loss: 81.5326
59008/60000 [============================>.] - ETA: 0s - loss: 212.5602 - s_output_loss: 130.9958 - t_output_loss: 81.5644
59392/60000 [============================>.] - ETA: 0s - loss: 212.5916 - s_output_loss: 130.9780 - t_output_loss: 81.6136
59648/60000 [============================>.] - ETA: 0s - loss: 212.6052 - s_output_loss: 130.9758 - t_output_loss: 81.6293
59904/60000 [============================>.] - ETA: 0s - loss: 212.5836 - s_output_loss: 130.9439 - t_output_loss: 81.6397
60000/60000 [==============================] - 13s 213us/step - loss: 212.5992 - s_output_loss: 130.9502 - t_output_loss: 81.6490 - val_loss: 213.1175 - val_s_output_loss: 125.9386 - val_t_output_loss: 87.1789
Epoch 5/10

  128/60000 [..............................] - ETA: 14s - loss: 222.6175 - s_output_loss: 133.2480 - t_output_loss: 89.3695
  384/60000 [..............................] - ETA: 13s - loss: 213.2469 - s_output_loss: 129.7150 - t_output_loss: 83.5320
  640/60000 [..............................] - ETA: 12s - loss: 211.5675 - s_output_loss: 128.8640 - t_output_loss: 82.7036
  896/60000 [..............................] - ETA: 12s - loss: 212.3689 - s_output_loss: 128.9455 - t_output_loss: 83.4233
 1152/60000 [..............................] - ETA: 12s - loss: 212.3842 - s_output_loss: 128.7055 - t_output_loss: 83.6787
 1408/60000 [..............................] - ETA: 12s - loss: 211.2408 - s_output_loss: 128.0625 - t_output_loss: 83.1783
 1664/60000 [..............................] - ETA: 12s - loss: 210.4187 - s_output_loss: 127.7128 - t_output_loss: 82.7060
 2048/60000 [>.............................] - ETA: 12s - loss: 209.8750 - s_output_loss: 127.6415 - t_output_loss: 82.2334
 2432/60000 [>.............................] - ETA: 11s - loss: 210.2945 - s_output_loss: 128.3973 - t_output_loss: 81.8972
 2688/60000 [>.............................] - ETA: 11s - loss: 210.3791 - s_output_loss: 128.6430 - t_output_loss: 81.7361
 2944/60000 [>.............................] - ETA: 11s - loss: 209.4875 - s_output_loss: 128.3727 - t_output_loss: 81.1148
 3200/60000 [>.............................] - ETA: 11s - loss: 209.2340 - s_output_loss: 128.4210 - t_output_loss: 80.8130
 3456/60000 [>.............................] - ETA: 11s - loss: 209.2662 - s_output_loss: 128.6135 - t_output_loss: 80.6526
 3712/60000 [>.............................] - ETA: 11s - loss: 208.9343 - s_output_loss: 128.5487 - t_output_loss: 80.3857
 4096/60000 [=>............................] - ETA: 11s - loss: 208.6822 - s_output_loss: 128.5238 - t_output_loss: 80.1583
 4480/60000 [=>............................] - ETA: 11s - loss: 208.2001 - s_output_loss: 128.3738 - t_output_loss: 79.8263
 4736/60000 [=>............................] - ETA: 11s - loss: 208.3307 - s_output_loss: 128.4529 - t_output_loss: 79.8778
 4992/60000 [=>............................] - ETA: 11s - loss: 208.3042 - s_output_loss: 128.5111 - t_output_loss: 79.7932
 5248/60000 [=>............................] - ETA: 11s - loss: 207.8950 - s_output_loss: 128.2936 - t_output_loss: 79.6014
 5504/60000 [=>............................] - ETA: 11s - loss: 207.7763 - s_output_loss: 128.2647 - t_output_loss: 79.5116
 5760/60000 [=>............................] - ETA: 11s - loss: 207.6739 - s_output_loss: 128.2347 - t_output_loss: 79.4392
 6016/60000 [==>...........................] - ETA: 11s - loss: 207.4405 - s_output_loss: 128.1060 - t_output_loss: 79.3345
 6272/60000 [==>...........................] - ETA: 10s - loss: 207.1143 - s_output_loss: 127.8878 - t_output_loss: 79.2265
 6528/60000 [==>...........................] - ETA: 10s - loss: 206.9330 - s_output_loss: 127.8571 - t_output_loss: 79.0759
 6784/60000 [==>...........................] - ETA: 10s - loss: 206.6423 - s_output_loss: 127.7671 - t_output_loss: 78.8752
 7040/60000 [==>...........................] - ETA: 10s - loss: 206.5895 - s_output_loss: 127.7357 - t_output_loss: 78.8539
 7424/60000 [==>...........................] - ETA: 10s - loss: 206.2563 - s_output_loss: 127.5365 - t_output_loss: 78.7198
 7680/60000 [==>...........................] - ETA: 10s - loss: 206.1809 - s_output_loss: 127.4611 - t_output_loss: 78.7198
 8064/60000 [===>..........................] - ETA: 10s - loss: 205.9661 - s_output_loss: 127.3628 - t_output_loss: 78.6033
 8320/60000 [===>..........................] - ETA: 10s - loss: 205.7104 - s_output_loss: 127.2684 - t_output_loss: 78.4419
 8576/60000 [===>..........................] - ETA: 10s - loss: 205.9357 - s_output_loss: 127.4574 - t_output_loss: 78.4782
 8832/60000 [===>..........................] - ETA: 10s - loss: 206.8530 - s_output_loss: 128.5094 - t_output_loss: 78.3437
 9088/60000 [===>..........................] - ETA: 10s - loss: 208.8068 - s_output_loss: 130.4918 - t_output_loss: 78.3150
 9344/60000 [===>..........................] - ETA: 10s - loss: 210.3304 - s_output_loss: 132.1139 - t_output_loss: 78.2165
 9600/60000 [===>..........................] - ETA: 10s - loss: 211.3932 - s_output_loss: 133.2201 - t_output_loss: 78.1730
 9856/60000 [===>..........................] - ETA: 10s - loss: 211.9682 - s_output_loss: 133.9347 - t_output_loss: 78.0334
10112/60000 [====>.........................] - ETA: 10s - loss: 212.5998 - s_output_loss: 134.5473 - t_output_loss: 78.0525
10368/60000 [====>.........................] - ETA: 10s - loss: 213.7161 - s_output_loss: 135.1945 - t_output_loss: 78.5216
10624/60000 [====>.........................] - ETA: 10s - loss: 214.8793 - s_output_loss: 135.8221 - t_output_loss: 79.0572
10880/60000 [====>.........................] - ETA: 10s - loss: 215.8902 - s_output_loss: 136.2851 - t_output_loss: 79.6051
11264/60000 [====>.........................] - ETA: 9s - loss: 217.0213 - s_output_loss: 136.7342 - t_output_loss: 80.2871 
11520/60000 [====>.........................] - ETA: 9s - loss: 217.6164 - s_output_loss: 136.9310 - t_output_loss: 80.6855
11904/60000 [====>.........................] - ETA: 9s - loss: 218.5493 - s_output_loss: 137.3909 - t_output_loss: 81.1583
12160/60000 [=====>........................] - ETA: 9s - loss: 218.8735 - s_output_loss: 137.5034 - t_output_loss: 81.3701
12416/60000 [=====>........................] - ETA: 9s - loss: 219.1062 - s_output_loss: 137.6050 - t_output_loss: 81.5013
12800/60000 [=====>........................] - ETA: 9s - loss: 219.2329 - s_output_loss: 137.6317 - t_output_loss: 81.6013
13056/60000 [=====>........................] - ETA: 9s - loss: 219.4121 - s_output_loss: 137.6705 - t_output_loss: 81.7416
13312/60000 [=====>........................] - ETA: 9s - loss: 219.4619 - s_output_loss: 137.6188 - t_output_loss: 81.8431
13696/60000 [=====>........................] - ETA: 9s - loss: 219.3765 - s_output_loss: 137.5295 - t_output_loss: 81.8471
13952/60000 [=====>........................] - ETA: 9s - loss: 219.3946 - s_output_loss: 137.5248 - t_output_loss: 81.8699
14336/60000 [======>.......................] - ETA: 9s - loss: 219.3411 - s_output_loss: 137.4546 - t_output_loss: 81.8864
14592/60000 [======>.......................] - ETA: 9s - loss: 219.2066 - s_output_loss: 137.3542 - t_output_loss: 81.8524
14848/60000 [======>.......................] - ETA: 9s - loss: 219.0703 - s_output_loss: 137.2324 - t_output_loss: 81.8379
15104/60000 [======>.......................] - ETA: 9s - loss: 219.0078 - s_output_loss: 137.1908 - t_output_loss: 81.8170
15488/60000 [======>.......................] - ETA: 9s - loss: 218.6832 - s_output_loss: 136.9701 - t_output_loss: 81.7132
15872/60000 [======>.......................] - ETA: 8s - loss: 218.4200 - s_output_loss: 136.7992 - t_output_loss: 81.6208
16256/60000 [=======>......................] - ETA: 8s - loss: 218.1416 - s_output_loss: 136.5980 - t_output_loss: 81.5436
16512/60000 [=======>......................] - ETA: 8s - loss: 218.0799 - s_output_loss: 136.5514 - t_output_loss: 81.5285
16768/60000 [=======>......................] - ETA: 8s - loss: 217.9007 - s_output_loss: 136.4226 - t_output_loss: 81.4781
17152/60000 [=======>......................] - ETA: 8s - loss: 217.7264 - s_output_loss: 136.3172 - t_output_loss: 81.4092
17408/60000 [=======>......................] - ETA: 8s - loss: 217.6925 - s_output_loss: 136.3041 - t_output_loss: 81.3883
17792/60000 [=======>......................] - ETA: 8s - loss: 217.4724 - s_output_loss: 136.1586 - t_output_loss: 81.3137
18048/60000 [========>.....................] - ETA: 8s - loss: 217.2530 - s_output_loss: 136.0186 - t_output_loss: 81.2345
18304/60000 [========>.....................] - ETA: 8s - loss: 217.1327 - s_output_loss: 135.9316 - t_output_loss: 81.2010
18688/60000 [========>.....................] - ETA: 8s - loss: 216.9512 - s_output_loss: 135.7887 - t_output_loss: 81.1625
18944/60000 [========>.....................] - ETA: 8s - loss: 216.8145 - s_output_loss: 135.6897 - t_output_loss: 81.1248
19200/60000 [========>.....................] - ETA: 8s - loss: 216.6785 - s_output_loss: 135.6037 - t_output_loss: 81.0748
19584/60000 [========>.....................] - ETA: 8s - loss: 216.5143 - s_output_loss: 135.5142 - t_output_loss: 81.0001
19968/60000 [========>.....................] - ETA: 8s - loss: 216.3507 - s_output_loss: 135.4044 - t_output_loss: 80.9463
20224/60000 [=========>....................] - ETA: 8s - loss: 216.1588 - s_output_loss: 135.2711 - t_output_loss: 80.8876
20608/60000 [=========>....................] - ETA: 7s - loss: 215.9388 - s_output_loss: 135.1310 - t_output_loss: 80.8078
20864/60000 [=========>....................] - ETA: 7s - loss: 215.8707 - s_output_loss: 135.0719 - t_output_loss: 80.7988
21120/60000 [=========>....................] - ETA: 7s - loss: 215.7176 - s_output_loss: 134.9771 - t_output_loss: 80.7405
21376/60000 [=========>....................] - ETA: 7s - loss: 215.5668 - s_output_loss: 134.8890 - t_output_loss: 80.6778
21760/60000 [=========>....................] - ETA: 7s - loss: 215.4484 - s_output_loss: 134.8255 - t_output_loss: 80.6229
22016/60000 [==========>...................] - ETA: 7s - loss: 215.3882 - s_output_loss: 134.7994 - t_output_loss: 80.5887
22272/60000 [==========>...................] - ETA: 7s - loss: 215.3999 - s_output_loss: 134.8349 - t_output_loss: 80.5649
22656/60000 [==========>...................] - ETA: 7s - loss: 216.1976 - s_output_loss: 135.6436 - t_output_loss: 80.5540
22912/60000 [==========>...................] - ETA: 7s - loss: 218.6612 - s_output_loss: 138.1016 - t_output_loss: 80.5596
23168/60000 [==========>...................] - ETA: 7s - loss: 221.1835 - s_output_loss: 140.6556 - t_output_loss: 80.5278
23552/60000 [==========>...................] - ETA: 7s - loss: 223.1907 - s_output_loss: 142.7004 - t_output_loss: 80.4904
23808/60000 [==========>...................] - ETA: 7s - loss: 224.1856 - s_output_loss: 143.6946 - t_output_loss: 80.4911
24064/60000 [===========>..................] - ETA: 7s - loss: 225.0579 - s_output_loss: 144.5729 - t_output_loss: 80.4850
24320/60000 [===========>..................] - ETA: 7s - loss: 225.9082 - s_output_loss: 145.4350 - t_output_loss: 80.4731
24576/60000 [===========>..................] - ETA: 7s - loss: 226.7415 - s_output_loss: 146.2785 - t_output_loss: 80.4630
24960/60000 [===========>..................] - ETA: 7s - loss: 227.8309 - s_output_loss: 147.4012 - t_output_loss: 80.4298
25216/60000 [===========>..................] - ETA: 7s - loss: 228.4457 - s_output_loss: 148.0271 - t_output_loss: 80.4185
25472/60000 [===========>..................] - ETA: 7s - loss: 229.0386 - s_output_loss: 148.6387 - t_output_loss: 80.3999
25728/60000 [===========>..................] - ETA: 6s - loss: 229.5731 - s_output_loss: 149.1999 - t_output_loss: 80.3732
25984/60000 [===========>..................] - ETA: 6s - loss: 230.1044 - s_output_loss: 149.7495 - t_output_loss: 80.3549
26240/60000 [============>.................] - ETA: 6s - loss: 230.5551 - s_output_loss: 150.2333 - t_output_loss: 80.3218
26496/60000 [============>.................] - ETA: 6s - loss: 230.9338 - s_output_loss: 150.6388 - t_output_loss: 80.2950
26752/60000 [============>.................] - ETA: 6s - loss: 231.3492 - s_output_loss: 151.0633 - t_output_loss: 80.2859
27008/60000 [============>.................] - ETA: 6s - loss: 231.8098 - s_output_loss: 151.4960 - t_output_loss: 80.3138
27264/60000 [============>.................] - ETA: 6s - loss: 232.1759 - s_output_loss: 151.8722 - t_output_loss: 80.3037
27520/60000 [============>.................] - ETA: 6s - loss: 232.4893 - s_output_loss: 152.2009 - t_output_loss: 80.2884
27776/60000 [============>.................] - ETA: 6s - loss: 232.7326 - s_output_loss: 152.4873 - t_output_loss: 80.2453
28032/60000 [=============>................] - ETA: 6s - loss: 233.0171 - s_output_loss: 152.7831 - t_output_loss: 80.2340
28288/60000 [=============>................] - ETA: 6s - loss: 233.3032 - s_output_loss: 153.0769 - t_output_loss: 80.2263
28544/60000 [=============>................] - ETA: 6s - loss: 233.6093 - s_output_loss: 153.3632 - t_output_loss: 80.2462
28800/60000 [=============>................] - ETA: 6s - loss: 234.0401 - s_output_loss: 153.5787 - t_output_loss: 80.4614
29056/60000 [=============>................] - ETA: 6s - loss: 234.3039 - s_output_loss: 153.7723 - t_output_loss: 80.5315
29312/60000 [=============>................] - ETA: 6s - loss: 234.6380 - s_output_loss: 153.9710 - t_output_loss: 80.6670
29568/60000 [=============>................] - ETA: 6s - loss: 235.0133 - s_output_loss: 154.1144 - t_output_loss: 80.8990
29824/60000 [=============>................] - ETA: 6s - loss: 235.5205 - s_output_loss: 154.2828 - t_output_loss: 81.2378
30080/60000 [==============>...............] - ETA: 6s - loss: 235.8888 - s_output_loss: 154.3601 - t_output_loss: 81.5287
30336/60000 [==============>...............] - ETA: 6s - loss: 236.2337 - s_output_loss: 154.4748 - t_output_loss: 81.7588
30592/60000 [==============>...............] - ETA: 6s - loss: 236.5244 - s_output_loss: 154.5782 - t_output_loss: 81.9462
30848/60000 [==============>...............] - ETA: 5s - loss: 236.7653 - s_output_loss: 154.6494 - t_output_loss: 82.1159
31104/60000 [==============>...............] - ETA: 5s - loss: 236.9623 - s_output_loss: 154.6982 - t_output_loss: 82.2641
31360/60000 [==============>...............] - ETA: 5s - loss: 237.2279 - s_output_loss: 154.7833 - t_output_loss: 82.4445
31616/60000 [==============>...............] - ETA: 5s - loss: 237.4229 - s_output_loss: 154.8176 - t_output_loss: 82.6053
31872/60000 [==============>...............] - ETA: 5s - loss: 237.6045 - s_output_loss: 154.8467 - t_output_loss: 82.7578
32128/60000 [===============>..............] - ETA: 5s - loss: 237.8121 - s_output_loss: 154.9029 - t_output_loss: 82.9093
32512/60000 [===============>..............] - ETA: 5s - loss: 237.9898 - s_output_loss: 154.8927 - t_output_loss: 83.0972
32896/60000 [===============>..............] - ETA: 5s - loss: 238.1608 - s_output_loss: 154.9192 - t_output_loss: 83.2416
33152/60000 [===============>..............] - ETA: 5s - loss: 238.1781 - s_output_loss: 154.8823 - t_output_loss: 83.2958
33408/60000 [===============>..............] - ETA: 5s - loss: 238.1976 - s_output_loss: 154.8512 - t_output_loss: 83.3463
33664/60000 [===============>..............] - ETA: 5s - loss: 238.2721 - s_output_loss: 154.8416 - t_output_loss: 83.4304
34048/60000 [================>.............] - ETA: 5s - loss: 238.3855 - s_output_loss: 154.8420 - t_output_loss: 83.5435
34304/60000 [================>.............] - ETA: 5s - loss: 238.4740 - s_output_loss: 154.8590 - t_output_loss: 83.6150
34560/60000 [================>.............] - ETA: 5s - loss: 238.5190 - s_output_loss: 154.8577 - t_output_loss: 83.6613
34816/60000 [================>.............] - ETA: 5s - loss: 238.5280 - s_output_loss: 154.8227 - t_output_loss: 83.7053
35072/60000 [================>.............] - ETA: 5s - loss: 238.5590 - s_output_loss: 154.8111 - t_output_loss: 83.7480
35328/60000 [================>.............] - ETA: 5s - loss: 238.5274 - s_output_loss: 154.7663 - t_output_loss: 83.7611
35584/60000 [================>.............] - ETA: 5s - loss: 238.5010 - s_output_loss: 154.7146 - t_output_loss: 83.7864
35840/60000 [================>.............] - ETA: 4s - loss: 238.5213 - s_output_loss: 154.7026 - t_output_loss: 83.8187
36096/60000 [=================>............] - ETA: 4s - loss: 238.5308 - s_output_loss: 154.6808 - t_output_loss: 83.8500
36352/60000 [=================>............] - ETA: 4s - loss: 238.5140 - s_output_loss: 154.6408 - t_output_loss: 83.8732
36608/60000 [=================>............] - ETA: 4s - loss: 238.4296 - s_output_loss: 154.5585 - t_output_loss: 83.8711
36864/60000 [=================>............] - ETA: 4s - loss: 238.3726 - s_output_loss: 154.4913 - t_output_loss: 83.8812
37120/60000 [=================>............] - ETA: 4s - loss: 238.3169 - s_output_loss: 154.4232 - t_output_loss: 83.8937
37376/60000 [=================>............] - ETA: 4s - loss: 238.2885 - s_output_loss: 154.3926 - t_output_loss: 83.8959
37632/60000 [=================>............] - ETA: 4s - loss: 238.2808 - s_output_loss: 154.3686 - t_output_loss: 83.9122
37888/60000 [=================>............] - ETA: 4s - loss: 238.2225 - s_output_loss: 154.3037 - t_output_loss: 83.9188
38144/60000 [==================>...........] - ETA: 4s - loss: 238.1725 - s_output_loss: 154.2441 - t_output_loss: 83.9284
38400/60000 [==================>...........] - ETA: 4s - loss: 238.1065 - s_output_loss: 154.1742 - t_output_loss: 83.9323
38656/60000 [==================>...........] - ETA: 4s - loss: 238.0155 - s_output_loss: 154.0933 - t_output_loss: 83.9222
38912/60000 [==================>...........] - ETA: 4s - loss: 237.9057 - s_output_loss: 153.9966 - t_output_loss: 83.9091
39296/60000 [==================>...........] - ETA: 4s - loss: 237.8329 - s_output_loss: 153.9122 - t_output_loss: 83.9206
39552/60000 [==================>...........] - ETA: 4s - loss: 237.7804 - s_output_loss: 153.8571 - t_output_loss: 83.9234
39808/60000 [==================>...........] - ETA: 4s - loss: 237.6654 - s_output_loss: 153.7622 - t_output_loss: 83.9032
40064/60000 [===================>..........] - ETA: 4s - loss: 237.5805 - s_output_loss: 153.6876 - t_output_loss: 83.8928
40320/60000 [===================>..........] - ETA: 4s - loss: 237.4985 - s_output_loss: 153.6073 - t_output_loss: 83.8912
40576/60000 [===================>..........] - ETA: 4s - loss: 237.4127 - s_output_loss: 153.5308 - t_output_loss: 83.8819
40832/60000 [===================>..........] - ETA: 3s - loss: 237.2919 - s_output_loss: 153.4227 - t_output_loss: 83.8692
41216/60000 [===================>..........] - ETA: 3s - loss: 237.1259 - s_output_loss: 153.2796 - t_output_loss: 83.8463
41600/60000 [===================>..........] - ETA: 3s - loss: 237.0301 - s_output_loss: 153.1690 - t_output_loss: 83.8611
41856/60000 [===================>..........] - ETA: 3s - loss: 236.9334 - s_output_loss: 153.0783 - t_output_loss: 83.8551
42112/60000 [====================>.........] - ETA: 3s - loss: 236.8905 - s_output_loss: 153.0334 - t_output_loss: 83.8571
42368/60000 [====================>.........] - ETA: 3s - loss: 236.7815 - s_output_loss: 152.9345 - t_output_loss: 83.8471
42624/60000 [====================>.........] - ETA: 3s - loss: 236.6904 - s_output_loss: 152.8518 - t_output_loss: 83.8385
43008/60000 [====================>.........] - ETA: 3s - loss: 236.5550 - s_output_loss: 152.7416 - t_output_loss: 83.8133
43392/60000 [====================>.........] - ETA: 3s - loss: 236.4383 - s_output_loss: 152.6376 - t_output_loss: 83.8008
43648/60000 [====================>.........] - ETA: 3s - loss: 236.3816 - s_output_loss: 152.5900 - t_output_loss: 83.7916
44032/60000 [=====================>........] - ETA: 3s - loss: 236.3288 - s_output_loss: 152.5202 - t_output_loss: 83.8087
44416/60000 [=====================>........] - ETA: 3s - loss: 236.2246 - s_output_loss: 152.4373 - t_output_loss: 83.7873
44672/60000 [=====================>........] - ETA: 3s - loss: 236.1776 - s_output_loss: 152.3963 - t_output_loss: 83.7813
45056/60000 [=====================>........] - ETA: 3s - loss: 236.0822 - s_output_loss: 152.3480 - t_output_loss: 83.7342
45312/60000 [=====================>........] - ETA: 3s - loss: 236.0603 - s_output_loss: 152.3431 - t_output_loss: 83.7172
45696/60000 [=====================>........] - ETA: 2s - loss: 236.0033 - s_output_loss: 152.3158 - t_output_loss: 83.6875
46080/60000 [======================>.......] - ETA: 2s - loss: 235.9670 - s_output_loss: 152.2766 - t_output_loss: 83.6904
46336/60000 [======================>.......] - ETA: 2s - loss: 235.8699 - s_output_loss: 152.2051 - t_output_loss: 83.6648
46592/60000 [======================>.......] - ETA: 2s - loss: 235.7575 - s_output_loss: 152.1291 - t_output_loss: 83.6284
46848/60000 [======================>.......] - ETA: 2s - loss: 235.6768 - s_output_loss: 152.0715 - t_output_loss: 83.6053
47104/60000 [======================>.......] - ETA: 2s - loss: 235.6199 - s_output_loss: 152.0294 - t_output_loss: 83.5905
47360/60000 [======================>.......] - ETA: 2s - loss: 235.5190 - s_output_loss: 151.9542 - t_output_loss: 83.5648
47744/60000 [======================>.......] - ETA: 2s - loss: 235.4167 - s_output_loss: 151.8848 - t_output_loss: 83.5318
48000/60000 [=======================>......] - ETA: 2s - loss: 235.2837 - s_output_loss: 151.7950 - t_output_loss: 83.4887
48256/60000 [=======================>......] - ETA: 2s - loss: 235.1838 - s_output_loss: 151.7175 - t_output_loss: 83.4664
48512/60000 [=======================>......] - ETA: 2s - loss: 235.0781 - s_output_loss: 151.6390 - t_output_loss: 83.4390
48768/60000 [=======================>......] - ETA: 2s - loss: 234.9769 - s_output_loss: 151.5659 - t_output_loss: 83.4109
49024/60000 [=======================>......] - ETA: 2s - loss: 234.8692 - s_output_loss: 151.4876 - t_output_loss: 83.3816
49280/60000 [=======================>......] - ETA: 2s - loss: 234.8029 - s_output_loss: 151.4324 - t_output_loss: 83.3705
49536/60000 [=======================>......] - ETA: 2s - loss: 234.7158 - s_output_loss: 151.3680 - t_output_loss: 83.3478
49792/60000 [=======================>......] - ETA: 2s - loss: 234.5940 - s_output_loss: 151.2786 - t_output_loss: 83.3154
50048/60000 [========================>.....] - ETA: 2s - loss: 234.5200 - s_output_loss: 151.2207 - t_output_loss: 83.2992
50304/60000 [========================>.....] - ETA: 1s - loss: 234.4652 - s_output_loss: 151.1880 - t_output_loss: 83.2772
50560/60000 [========================>.....] - ETA: 1s - loss: 234.4591 - s_output_loss: 151.1943 - t_output_loss: 83.2647
50816/60000 [========================>.....] - ETA: 1s - loss: 234.4577 - s_output_loss: 151.2009 - t_output_loss: 83.2567
51072/60000 [========================>.....] - ETA: 1s - loss: 234.4254 - s_output_loss: 151.1843 - t_output_loss: 83.2411
51328/60000 [========================>.....] - ETA: 1s - loss: 234.4190 - s_output_loss: 151.1864 - t_output_loss: 83.2326
51584/60000 [========================>.....] - ETA: 1s - loss: 234.3484 - s_output_loss: 151.1401 - t_output_loss: 83.2084
51968/60000 [========================>.....] - ETA: 1s - loss: 234.2714 - s_output_loss: 151.0867 - t_output_loss: 83.1847
52352/60000 [=========================>....] - ETA: 1s - loss: 234.1518 - s_output_loss: 151.0035 - t_output_loss: 83.1483
52736/60000 [=========================>....] - ETA: 1s - loss: 234.0264 - s_output_loss: 150.9199 - t_output_loss: 83.1065
52992/60000 [=========================>....] - ETA: 1s - loss: 233.9646 - s_output_loss: 150.8760 - t_output_loss: 83.0886
53248/60000 [=========================>....] - ETA: 1s - loss: 233.8765 - s_output_loss: 150.8227 - t_output_loss: 83.0538
53632/60000 [=========================>....] - ETA: 1s - loss: 233.7603 - s_output_loss: 150.7398 - t_output_loss: 83.0205
53888/60000 [=========================>....] - ETA: 1s - loss: 233.6848 - s_output_loss: 150.6904 - t_output_loss: 82.9944
54272/60000 [==========================>...] - ETA: 1s - loss: 233.6051 - s_output_loss: 150.6309 - t_output_loss: 82.9742
54528/60000 [==========================>...] - ETA: 1s - loss: 233.5022 - s_output_loss: 150.5637 - t_output_loss: 82.9385
54912/60000 [==========================>...] - ETA: 1s - loss: 233.3902 - s_output_loss: 150.4861 - t_output_loss: 82.9041
55168/60000 [==========================>...] - ETA: 0s - loss: 233.3554 - s_output_loss: 150.4479 - t_output_loss: 82.9075
55424/60000 [==========================>...] - ETA: 0s - loss: 233.3180 - s_output_loss: 150.4171 - t_output_loss: 82.9009
55808/60000 [==========================>...] - ETA: 0s - loss: 233.2384 - s_output_loss: 150.3629 - t_output_loss: 82.8755
56064/60000 [===========================>..] - ETA: 0s - loss: 233.1811 - s_output_loss: 150.3078 - t_output_loss: 82.8733
56448/60000 [===========================>..] - ETA: 0s - loss: 233.0715 - s_output_loss: 150.2256 - t_output_loss: 82.8460
56832/60000 [===========================>..] - ETA: 0s - loss: 232.9213 - s_output_loss: 150.1168 - t_output_loss: 82.8045
57088/60000 [===========================>..] - ETA: 0s - loss: 232.8344 - s_output_loss: 150.0529 - t_output_loss: 82.7814
57344/60000 [===========================>..] - ETA: 0s - loss: 232.7656 - s_output_loss: 150.0062 - t_output_loss: 82.7594
57728/60000 [===========================>..] - ETA: 0s - loss: 232.6671 - s_output_loss: 149.9337 - t_output_loss: 82.7334
57984/60000 [===========================>..] - ETA: 0s - loss: 232.5498 - s_output_loss: 149.8520 - t_output_loss: 82.6978
58240/60000 [============================>.] - ETA: 0s - loss: 232.4561 - s_output_loss: 149.7898 - t_output_loss: 82.6663
58624/60000 [============================>.] - ETA: 0s - loss: 232.3617 - s_output_loss: 149.7326 - t_output_loss: 82.6291
58880/60000 [============================>.] - ETA: 0s - loss: 232.3060 - s_output_loss: 149.6970 - t_output_loss: 82.6090
59136/60000 [============================>.] - ETA: 0s - loss: 232.2194 - s_output_loss: 149.6440 - t_output_loss: 82.5755
59392/60000 [============================>.] - ETA: 0s - loss: 232.1273 - s_output_loss: 149.5711 - t_output_loss: 82.5561
59776/60000 [============================>.] - ETA: 0s - loss: 232.0381 - s_output_loss: 149.5154 - t_output_loss: 82.5228
60000/60000 [==============================] - 13s 215us/step - loss: 231.9589 - s_output_loss: 149.4608 - t_output_loss: 82.4981 - val_loss: 216.0635 - val_s_output_loss: 135.4697 - val_t_output_loss: 80.5938
Epoch 6/10

  128/60000 [..............................] - ETA: 15s - loss: 219.8743 - s_output_loss: 140.4254 - t_output_loss: 79.4489
  384/60000 [..............................] - ETA: 14s - loss: 214.2250 - s_output_loss: 137.6051 - t_output_loss: 76.6199
  640/60000 [..............................] - ETA: 13s - loss: 212.6550 - s_output_loss: 136.3678 - t_output_loss: 76.2872
  896/60000 [..............................] - ETA: 12s - loss: 214.0831 - s_output_loss: 136.6342 - t_output_loss: 77.4489
 1152/60000 [..............................] - ETA: 12s - loss: 214.5580 - s_output_loss: 137.0035 - t_output_loss: 77.5545
 1536/60000 [..............................] - ETA: 12s - loss: 212.3981 - s_output_loss: 135.5427 - t_output_loss: 76.8554
 1920/60000 [..............................] - ETA: 12s - loss: 210.8629 - s_output_loss: 134.5781 - t_output_loss: 76.2848
 2176/60000 [>.............................] - ETA: 12s - loss: 210.5201 - s_output_loss: 134.3705 - t_output_loss: 76.1496
 2432/60000 [>.............................] - ETA: 12s - loss: 210.3911 - s_output_loss: 134.1294 - t_output_loss: 76.2617
 2816/60000 [>.............................] - ETA: 11s - loss: 210.5740 - s_output_loss: 134.3518 - t_output_loss: 76.2223
 3200/60000 [>.............................] - ETA: 11s - loss: 211.0054 - s_output_loss: 134.4605 - t_output_loss: 76.5449
 3456/60000 [>.............................] - ETA: 11s - loss: 210.9349 - s_output_loss: 134.2735 - t_output_loss: 76.6615
 3840/60000 [>.............................] - ETA: 11s - loss: 210.7885 - s_output_loss: 134.4142 - t_output_loss: 76.3743
 4224/60000 [=>............................] - ETA: 11s - loss: 210.7264 - s_output_loss: 134.4440 - t_output_loss: 76.2824
 4608/60000 [=>............................] - ETA: 11s - loss: 210.9486 - s_output_loss: 134.4945 - t_output_loss: 76.4542
 4864/60000 [=>............................] - ETA: 11s - loss: 210.7714 - s_output_loss: 134.2484 - t_output_loss: 76.5230
 5248/60000 [=>............................] - ETA: 11s - loss: 210.5144 - s_output_loss: 134.0375 - t_output_loss: 76.4768
 5504/60000 [=>............................] - ETA: 11s - loss: 210.2955 - s_output_loss: 133.7204 - t_output_loss: 76.5750
 5888/60000 [=>............................] - ETA: 10s - loss: 210.3177 - s_output_loss: 133.7366 - t_output_loss: 76.5811
 6144/60000 [==>...........................] - ETA: 10s - loss: 210.3308 - s_output_loss: 133.6823 - t_output_loss: 76.6485
 6528/60000 [==>...........................] - ETA: 10s - loss: 210.3420 - s_output_loss: 133.6907 - t_output_loss: 76.6513
 6912/60000 [==>...........................] - ETA: 10s - loss: 210.1047 - s_output_loss: 133.5497 - t_output_loss: 76.5550
 7168/60000 [==>...........................] - ETA: 10s - loss: 210.0020 - s_output_loss: 133.5105 - t_output_loss: 76.4916
 7552/60000 [==>...........................] - ETA: 10s - loss: 209.8490 - s_output_loss: 133.4037 - t_output_loss: 76.4453
 7808/60000 [==>...........................] - ETA: 10s - loss: 209.8505 - s_output_loss: 133.3582 - t_output_loss: 76.4923
 8064/60000 [===>..........................] - ETA: 10s - loss: 209.8919 - s_output_loss: 133.4094 - t_output_loss: 76.4824
 8320/60000 [===>..........................] - ETA: 10s - loss: 209.8059 - s_output_loss: 133.4060 - t_output_loss: 76.3999
 8704/60000 [===>..........................] - ETA: 10s - loss: 210.2337 - s_output_loss: 133.8425 - t_output_loss: 76.3912
 8960/60000 [===>..........................] - ETA: 10s - loss: 210.4302 - s_output_loss: 134.0282 - t_output_loss: 76.4020
 9216/60000 [===>..........................] - ETA: 10s - loss: 210.3903 - s_output_loss: 134.0411 - t_output_loss: 76.3492
 9472/60000 [===>..........................] - ETA: 10s - loss: 210.5808 - s_output_loss: 134.2287 - t_output_loss: 76.3521
 9856/60000 [===>..........................] - ETA: 10s - loss: 210.8018 - s_output_loss: 134.4005 - t_output_loss: 76.4013
10112/60000 [====>.........................] - ETA: 10s - loss: 210.8981 - s_output_loss: 134.4798 - t_output_loss: 76.4183
10368/60000 [====>.........................] - ETA: 10s - loss: 210.7674 - s_output_loss: 134.4266 - t_output_loss: 76.3408
10624/60000 [====>.........................] - ETA: 9s - loss: 210.8128 - s_output_loss: 134.4583 - t_output_loss: 76.3545 
10880/60000 [====>.........................] - ETA: 9s - loss: 210.7049 - s_output_loss: 134.4274 - t_output_loss: 76.2774
11136/60000 [====>.........................] - ETA: 9s - loss: 210.6457 - s_output_loss: 134.3714 - t_output_loss: 76.2743
11392/60000 [====>.........................] - ETA: 9s - loss: 210.5450 - s_output_loss: 134.3441 - t_output_loss: 76.2009
11776/60000 [====>.........................] - ETA: 9s - loss: 211.1982 - s_output_loss: 135.0209 - t_output_loss: 76.1774
12032/60000 [=====>........................] - ETA: 9s - loss: 212.2686 - s_output_loss: 136.0728 - t_output_loss: 76.1958
12288/60000 [=====>........................] - ETA: 9s - loss: 212.8485 - s_output_loss: 136.6746 - t_output_loss: 76.1739
12544/60000 [=====>........................] - ETA: 9s - loss: 213.2255 - s_output_loss: 137.0650 - t_output_loss: 76.1606
12800/60000 [=====>........................] - ETA: 9s - loss: 213.2900 - s_output_loss: 137.1601 - t_output_loss: 76.1300
13184/60000 [=====>........................] - ETA: 9s - loss: 213.6994 - s_output_loss: 137.5590 - t_output_loss: 76.1405
13440/60000 [=====>........................] - ETA: 9s - loss: 213.8748 - s_output_loss: 137.7600 - t_output_loss: 76.1148
13824/60000 [=====>........................] - ETA: 9s - loss: 214.0528 - s_output_loss: 138.0017 - t_output_loss: 76.0510
14080/60000 [======>.......................] - ETA: 9s - loss: 214.7271 - s_output_loss: 138.1379 - t_output_loss: 76.5892
14336/60000 [======>.......................] - ETA: 9s - loss: 216.6336 - s_output_loss: 138.1964 - t_output_loss: 78.4372
14592/60000 [======>.......................] - ETA: 9s - loss: 218.3720 - s_output_loss: 138.2388 - t_output_loss: 80.1332
14976/60000 [======>.......................] - ETA: 9s - loss: 220.7795 - s_output_loss: 138.2664 - t_output_loss: 82.5131
15360/60000 [======>.......................] - ETA: 9s - loss: 222.6855 - s_output_loss: 138.3031 - t_output_loss: 84.3824
15744/60000 [======>.......................] - ETA: 8s - loss: 223.5181 - s_output_loss: 138.3071 - t_output_loss: 85.2110
16000/60000 [=======>......................] - ETA: 8s - loss: 223.9123 - s_output_loss: 138.2413 - t_output_loss: 85.6710
16256/60000 [=======>......................] - ETA: 8s - loss: 224.2546 - s_output_loss: 138.2146 - t_output_loss: 86.0400
16640/60000 [=======>......................] - ETA: 8s - loss: 224.7771 - s_output_loss: 138.1371 - t_output_loss: 86.6400
16896/60000 [=======>......................] - ETA: 8s - loss: 225.1066 - s_output_loss: 138.0941 - t_output_loss: 87.0125
17152/60000 [=======>......................] - ETA: 8s - loss: 225.4679 - s_output_loss: 138.0986 - t_output_loss: 87.3693
17408/60000 [=======>......................] - ETA: 8s - loss: 225.7101 - s_output_loss: 138.0156 - t_output_loss: 87.6945
17664/60000 [=======>......................] - ETA: 8s - loss: 225.8601 - s_output_loss: 137.8988 - t_output_loss: 87.9613
18048/60000 [========>.....................] - ETA: 8s - loss: 226.1152 - s_output_loss: 137.8139 - t_output_loss: 88.3014
18304/60000 [========>.....................] - ETA: 8s - loss: 226.3415 - s_output_loss: 137.7976 - t_output_loss: 88.5438
18560/60000 [========>.....................] - ETA: 8s - loss: 226.4882 - s_output_loss: 137.7282 - t_output_loss: 88.7601
18944/60000 [========>.....................] - ETA: 8s - loss: 226.5966 - s_output_loss: 137.5909 - t_output_loss: 89.0057
19328/60000 [========>.....................] - ETA: 8s - loss: 226.7945 - s_output_loss: 137.5178 - t_output_loss: 89.2767
19584/60000 [========>.....................] - ETA: 8s - loss: 226.8727 - s_output_loss: 137.4550 - t_output_loss: 89.4177
19840/60000 [========>.....................] - ETA: 8s - loss: 226.8779 - s_output_loss: 137.3372 - t_output_loss: 89.5407
20096/60000 [=========>....................] - ETA: 8s - loss: 226.9163 - s_output_loss: 137.2653 - t_output_loss: 89.6510
20352/60000 [=========>....................] - ETA: 8s - loss: 226.9706 - s_output_loss: 137.2095 - t_output_loss: 89.7610
20608/60000 [=========>....................] - ETA: 7s - loss: 226.9875 - s_output_loss: 137.1467 - t_output_loss: 89.8409
20992/60000 [=========>....................] - ETA: 7s - loss: 226.9149 - s_output_loss: 136.9744 - t_output_loss: 89.9406
21376/60000 [=========>....................] - ETA: 7s - loss: 226.9415 - s_output_loss: 136.8676 - t_output_loss: 90.0740
21632/60000 [=========>....................] - ETA: 7s - loss: 226.8728 - s_output_loss: 136.7457 - t_output_loss: 90.1271
21888/60000 [=========>....................] - ETA: 7s - loss: 226.8546 - s_output_loss: 136.6728 - t_output_loss: 90.1818
22144/60000 [==========>...................] - ETA: 7s - loss: 226.8998 - s_output_loss: 136.6878 - t_output_loss: 90.2120
22400/60000 [==========>...................] - ETA: 7s - loss: 227.2200 - s_output_loss: 136.9868 - t_output_loss: 90.2331
22656/60000 [==========>...................] - ETA: 7s - loss: 227.6860 - s_output_loss: 137.4006 - t_output_loss: 90.2854
22912/60000 [==========>...................] - ETA: 7s - loss: 228.0480 - s_output_loss: 137.7467 - t_output_loss: 90.3013
23168/60000 [==========>...................] - ETA: 7s - loss: 228.3743 - s_output_loss: 138.0244 - t_output_loss: 90.3499
23424/60000 [==========>...................] - ETA: 7s - loss: 228.6216 - s_output_loss: 138.2283 - t_output_loss: 90.3932
23808/60000 [==========>...................] - ETA: 7s - loss: 228.9432 - s_output_loss: 138.4699 - t_output_loss: 90.4733
24064/60000 [===========>..................] - ETA: 7s - loss: 229.1718 - s_output_loss: 138.6431 - t_output_loss: 90.5287
24320/60000 [===========>..................] - ETA: 7s - loss: 229.3303 - s_output_loss: 138.7482 - t_output_loss: 90.5821
24576/60000 [===========>..................] - ETA: 7s - loss: 229.3692 - s_output_loss: 138.7848 - t_output_loss: 90.5844
24832/60000 [===========>..................] - ETA: 7s - loss: 229.4091 - s_output_loss: 138.8103 - t_output_loss: 90.5988
25216/60000 [===========>..................] - ETA: 7s - loss: 229.4597 - s_output_loss: 138.8445 - t_output_loss: 90.6152
25472/60000 [===========>..................] - ETA: 6s - loss: 229.5610 - s_output_loss: 138.9150 - t_output_loss: 90.6460
25728/60000 [===========>..................] - ETA: 6s - loss: 229.6520 - s_output_loss: 138.9865 - t_output_loss: 90.6655
25984/60000 [===========>..................] - ETA: 6s - loss: 229.6660 - s_output_loss: 138.9994 - t_output_loss: 90.6666
26240/60000 [============>.................] - ETA: 6s - loss: 229.6902 - s_output_loss: 139.0200 - t_output_loss: 90.6702
26624/60000 [============>.................] - ETA: 6s - loss: 229.7956 - s_output_loss: 139.0994 - t_output_loss: 90.6963
26880/60000 [============>.................] - ETA: 6s - loss: 229.8096 - s_output_loss: 139.1274 - t_output_loss: 90.6822
27264/60000 [============>.................] - ETA: 6s - loss: 229.8048 - s_output_loss: 139.1603 - t_output_loss: 90.6446
27520/60000 [============>.................] - ETA: 6s - loss: 229.7849 - s_output_loss: 139.1659 - t_output_loss: 90.6190
27776/60000 [============>.................] - ETA: 6s - loss: 229.7980 - s_output_loss: 139.1881 - t_output_loss: 90.6099
28032/60000 [=============>................] - ETA: 6s - loss: 229.7281 - s_output_loss: 139.1604 - t_output_loss: 90.5677
28288/60000 [=============>................] - ETA: 6s - loss: 229.6689 - s_output_loss: 139.1270 - t_output_loss: 90.5419
28672/60000 [=============>................] - ETA: 6s - loss: 229.7042 - s_output_loss: 139.1637 - t_output_loss: 90.5405
29056/60000 [=============>................] - ETA: 6s - loss: 229.6464 - s_output_loss: 139.1420 - t_output_loss: 90.5044
29440/60000 [=============>................] - ETA: 6s - loss: 229.4978 - s_output_loss: 139.0788 - t_output_loss: 90.4190
29696/60000 [=============>................] - ETA: 6s - loss: 229.4853 - s_output_loss: 139.0668 - t_output_loss: 90.4185
29952/60000 [=============>................] - ETA: 6s - loss: 229.4165 - s_output_loss: 139.0345 - t_output_loss: 90.3819
30208/60000 [==============>...............] - ETA: 6s - loss: 229.2759 - s_output_loss: 138.9553 - t_output_loss: 90.3206
30592/60000 [==============>...............] - ETA: 5s - loss: 229.0231 - s_output_loss: 138.8158 - t_output_loss: 90.2073
30848/60000 [==============>...............] - ETA: 5s - loss: 228.9399 - s_output_loss: 138.7671 - t_output_loss: 90.1728
31104/60000 [==============>...............] - ETA: 5s - loss: 228.8048 - s_output_loss: 138.6785 - t_output_loss: 90.1263
31360/60000 [==============>...............] - ETA: 5s - loss: 228.7536 - s_output_loss: 138.6564 - t_output_loss: 90.0972
31616/60000 [==============>...............] - ETA: 5s - loss: 228.6314 - s_output_loss: 138.5843 - t_output_loss: 90.0471
31872/60000 [==============>...............] - ETA: 5s - loss: 228.6043 - s_output_loss: 138.5819 - t_output_loss: 90.0224
32128/60000 [===============>..............] - ETA: 5s - loss: 228.5513 - s_output_loss: 138.5571 - t_output_loss: 89.9942
32384/60000 [===============>..............] - ETA: 5s - loss: 228.4726 - s_output_loss: 138.5012 - t_output_loss: 89.9714
32768/60000 [===============>..............] - ETA: 5s - loss: 228.3542 - s_output_loss: 138.4366 - t_output_loss: 89.9175
33152/60000 [===============>..............] - ETA: 5s - loss: 228.2129 - s_output_loss: 138.3300 - t_output_loss: 89.8829
33536/60000 [===============>..............] - ETA: 5s - loss: 228.0633 - s_output_loss: 138.2321 - t_output_loss: 89.8313
33920/60000 [===============>..............] - ETA: 5s - loss: 227.9116 - s_output_loss: 138.1447 - t_output_loss: 89.7669
34176/60000 [================>.............] - ETA: 5s - loss: 227.8569 - s_output_loss: 138.1050 - t_output_loss: 89.7519
34432/60000 [================>.............] - ETA: 5s - loss: 227.7807 - s_output_loss: 138.0544 - t_output_loss: 89.7263
34688/60000 [================>.............] - ETA: 5s - loss: 227.6862 - s_output_loss: 137.9929 - t_output_loss: 89.6933
34944/60000 [================>.............] - ETA: 5s - loss: 227.5606 - s_output_loss: 137.9216 - t_output_loss: 89.6391
35200/60000 [================>.............] - ETA: 4s - loss: 227.4541 - s_output_loss: 137.8731 - t_output_loss: 89.5811
35456/60000 [================>.............] - ETA: 4s - loss: 227.3983 - s_output_loss: 137.8411 - t_output_loss: 89.5572
35712/60000 [================>.............] - ETA: 4s - loss: 227.3214 - s_output_loss: 137.7818 - t_output_loss: 89.5396
35968/60000 [================>.............] - ETA: 4s - loss: 227.2594 - s_output_loss: 137.7357 - t_output_loss: 89.5238
36224/60000 [=================>............] - ETA: 4s - loss: 227.1548 - s_output_loss: 137.6543 - t_output_loss: 89.5006
36480/60000 [=================>............] - ETA: 4s - loss: 227.0738 - s_output_loss: 137.5731 - t_output_loss: 89.5007
36864/60000 [=================>............] - ETA: 4s - loss: 226.9615 - s_output_loss: 137.4819 - t_output_loss: 89.4796
37248/60000 [=================>............] - ETA: 4s - loss: 226.8798 - s_output_loss: 137.4135 - t_output_loss: 89.4663
37632/60000 [=================>............] - ETA: 4s - loss: 226.7672 - s_output_loss: 137.3382 - t_output_loss: 89.4289
37888/60000 [=================>............] - ETA: 4s - loss: 226.6578 - s_output_loss: 137.2669 - t_output_loss: 89.3909
38144/60000 [==================>...........] - ETA: 4s - loss: 226.6137 - s_output_loss: 137.2381 - t_output_loss: 89.3756
38400/60000 [==================>...........] - ETA: 4s - loss: 226.5265 - s_output_loss: 137.1803 - t_output_loss: 89.3462
38656/60000 [==================>...........] - ETA: 4s - loss: 226.4110 - s_output_loss: 137.1067 - t_output_loss: 89.3044
39040/60000 [==================>...........] - ETA: 4s - loss: 226.2600 - s_output_loss: 137.0116 - t_output_loss: 89.2484
39296/60000 [==================>...........] - ETA: 4s - loss: 226.2371 - s_output_loss: 137.0257 - t_output_loss: 89.2115
39552/60000 [==================>...........] - ETA: 4s - loss: 226.3242 - s_output_loss: 137.1414 - t_output_loss: 89.1829
39936/60000 [==================>...........] - ETA: 4s - loss: 226.4271 - s_output_loss: 137.2983 - t_output_loss: 89.1289
40320/60000 [===================>..........] - ETA: 3s - loss: 226.4202 - s_output_loss: 137.3458 - t_output_loss: 89.0744
40576/60000 [===================>..........] - ETA: 3s - loss: 226.4400 - s_output_loss: 137.3858 - t_output_loss: 89.0542
40832/60000 [===================>..........] - ETA: 3s - loss: 226.4263 - s_output_loss: 137.4147 - t_output_loss: 89.0116
41216/60000 [===================>..........] - ETA: 3s - loss: 226.3760 - s_output_loss: 137.4284 - t_output_loss: 88.9476
41472/60000 [===================>..........] - ETA: 3s - loss: 226.3134 - s_output_loss: 137.4052 - t_output_loss: 88.9082
41728/60000 [===================>..........] - ETA: 3s - loss: 226.2874 - s_output_loss: 137.4076 - t_output_loss: 88.8798
41984/60000 [===================>..........] - ETA: 3s - loss: 226.2640 - s_output_loss: 137.4130 - t_output_loss: 88.8510
42240/60000 [====================>.........] - ETA: 3s - loss: 226.2109 - s_output_loss: 137.3984 - t_output_loss: 88.8125
42496/60000 [====================>.........] - ETA: 3s - loss: 226.1569 - s_output_loss: 137.3750 - t_output_loss: 88.7820
42752/60000 [====================>.........] - ETA: 3s - loss: 226.1347 - s_output_loss: 137.3739 - t_output_loss: 88.7609
43008/60000 [====================>.........] - ETA: 3s - loss: 226.0825 - s_output_loss: 137.3644 - t_output_loss: 88.7181
43264/60000 [====================>.........] - ETA: 3s - loss: 226.0369 - s_output_loss: 137.3473 - t_output_loss: 88.6895
43648/60000 [====================>.........] - ETA: 3s - loss: 225.9267 - s_output_loss: 137.3066 - t_output_loss: 88.6201
44032/60000 [=====================>........] - ETA: 3s - loss: 225.8049 - s_output_loss: 137.2488 - t_output_loss: 88.5561
44288/60000 [=====================>........] - ETA: 3s - loss: 225.7670 - s_output_loss: 137.2412 - t_output_loss: 88.5258
44672/60000 [=====================>........] - ETA: 3s - loss: 225.6868 - s_output_loss: 137.2274 - t_output_loss: 88.4595
44928/60000 [=====================>........] - ETA: 3s - loss: 225.6594 - s_output_loss: 137.2359 - t_output_loss: 88.4234
45184/60000 [=====================>........] - ETA: 2s - loss: 225.6011 - s_output_loss: 137.2192 - t_output_loss: 88.3819
45440/60000 [=====================>........] - ETA: 2s - loss: 225.5420 - s_output_loss: 137.2039 - t_output_loss: 88.3381
45696/60000 [=====================>........] - ETA: 2s - loss: 225.4792 - s_output_loss: 137.1955 - t_output_loss: 88.2837
45952/60000 [=====================>........] - ETA: 2s - loss: 225.4274 - s_output_loss: 137.1899 - t_output_loss: 88.2374
46208/60000 [======================>.......] - ETA: 2s - loss: 225.4337 - s_output_loss: 137.2267 - t_output_loss: 88.2070
46464/60000 [======================>.......] - ETA: 2s - loss: 225.3903 - s_output_loss: 137.2344 - t_output_loss: 88.1558
46720/60000 [======================>.......] - ETA: 2s - loss: 225.3378 - s_output_loss: 137.2362 - t_output_loss: 88.1016
46976/60000 [======================>.......] - ETA: 2s - loss: 225.2722 - s_output_loss: 137.2139 - t_output_loss: 88.0583
47232/60000 [======================>.......] - ETA: 2s - loss: 225.2220 - s_output_loss: 137.2060 - t_output_loss: 88.0160
47488/60000 [======================>.......] - ETA: 2s - loss: 225.1407 - s_output_loss: 137.1731 - t_output_loss: 87.9676
47872/60000 [======================>.......] - ETA: 2s - loss: 225.0443 - s_output_loss: 137.1355 - t_output_loss: 87.9088
48256/60000 [=======================>......] - ETA: 2s - loss: 224.9529 - s_output_loss: 137.0910 - t_output_loss: 87.8619
48512/60000 [=======================>......] - ETA: 2s - loss: 224.9206 - s_output_loss: 137.0847 - t_output_loss: 87.8359
48896/60000 [=======================>......] - ETA: 2s - loss: 224.8019 - s_output_loss: 137.0381 - t_output_loss: 87.7638
49280/60000 [=======================>......] - ETA: 2s - loss: 224.6743 - s_output_loss: 136.9873 - t_output_loss: 87.6870
49536/60000 [=======================>......] - ETA: 2s - loss: 224.6203 - s_output_loss: 136.9704 - t_output_loss: 87.6499
49792/60000 [=======================>......] - ETA: 2s - loss: 224.5656 - s_output_loss: 136.9466 - t_output_loss: 87.6191
50048/60000 [========================>.....] - ETA: 2s - loss: 224.5017 - s_output_loss: 136.9227 - t_output_loss: 87.5790
50304/60000 [========================>.....] - ETA: 1s - loss: 224.4188 - s_output_loss: 136.8770 - t_output_loss: 87.5418
50560/60000 [========================>.....] - ETA: 1s - loss: 224.3361 - s_output_loss: 136.8316 - t_output_loss: 87.5045
50816/60000 [========================>.....] - ETA: 1s - loss: 224.2460 - s_output_loss: 136.7895 - t_output_loss: 87.4565
51072/60000 [========================>.....] - ETA: 1s - loss: 224.1634 - s_output_loss: 136.7485 - t_output_loss: 87.4149
51328/60000 [========================>.....] - ETA: 1s - loss: 224.0676 - s_output_loss: 136.7058 - t_output_loss: 87.3619
51584/60000 [========================>.....] - ETA: 1s - loss: 223.9250 - s_output_loss: 136.6336 - t_output_loss: 87.2914
51840/60000 [========================>.....] - ETA: 1s - loss: 223.8574 - s_output_loss: 136.6010 - t_output_loss: 87.2564
52096/60000 [=========================>....] - ETA: 1s - loss: 223.7627 - s_output_loss: 136.5616 - t_output_loss: 87.2011
52352/60000 [=========================>....] - ETA: 1s - loss: 223.7191 - s_output_loss: 136.5594 - t_output_loss: 87.1598
52736/60000 [=========================>....] - ETA: 1s - loss: 223.7180 - s_output_loss: 136.6368 - t_output_loss: 87.0812
53120/60000 [=========================>....] - ETA: 1s - loss: 223.7457 - s_output_loss: 136.7185 - t_output_loss: 87.0271
53504/60000 [=========================>....] - ETA: 1s - loss: 223.7523 - s_output_loss: 136.7784 - t_output_loss: 86.9739
53760/60000 [=========================>....] - ETA: 1s - loss: 223.7275 - s_output_loss: 136.7940 - t_output_loss: 86.9335
54144/60000 [==========================>...] - ETA: 1s - loss: 223.6605 - s_output_loss: 136.7980 - t_output_loss: 86.8625
54400/60000 [==========================>...] - ETA: 1s - loss: 223.6219 - s_output_loss: 136.7998 - t_output_loss: 86.8221
54656/60000 [==========================>...] - ETA: 1s - loss: 223.5713 - s_output_loss: 136.7882 - t_output_loss: 86.7831
55040/60000 [==========================>...] - ETA: 0s - loss: 223.5011 - s_output_loss: 136.7699 - t_output_loss: 86.7312
55424/60000 [==========================>...] - ETA: 0s - loss: 223.4092 - s_output_loss: 136.7468 - t_output_loss: 86.6624
55680/60000 [==========================>...] - ETA: 0s - loss: 223.3153 - s_output_loss: 136.7027 - t_output_loss: 86.6125
56064/60000 [===========================>..] - ETA: 0s - loss: 223.2257 - s_output_loss: 136.6751 - t_output_loss: 86.5506
56320/60000 [===========================>..] - ETA: 0s - loss: 223.1403 - s_output_loss: 136.6358 - t_output_loss: 86.5045
56576/60000 [===========================>..] - ETA: 0s - loss: 223.1001 - s_output_loss: 136.6257 - t_output_loss: 86.4744
56832/60000 [===========================>..] - ETA: 0s - loss: 223.0226 - s_output_loss: 136.5940 - t_output_loss: 86.4286
57088/60000 [===========================>..] - ETA: 0s - loss: 222.9527 - s_output_loss: 136.5621 - t_output_loss: 86.3907
57344/60000 [===========================>..] - ETA: 0s - loss: 222.9048 - s_output_loss: 136.5321 - t_output_loss: 86.3726
57600/60000 [===========================>..] - ETA: 0s - loss: 222.8607 - s_output_loss: 136.5150 - t_output_loss: 86.3456
57856/60000 [===========================>..] - ETA: 0s - loss: 222.7877 - s_output_loss: 136.4849 - t_output_loss: 86.3028
58112/60000 [============================>.] - ETA: 0s - loss: 222.6801 - s_output_loss: 136.4266 - t_output_loss: 86.2535
58368/60000 [============================>.] - ETA: 0s - loss: 222.5915 - s_output_loss: 136.3808 - t_output_loss: 86.2107
58624/60000 [============================>.] - ETA: 0s - loss: 222.5312 - s_output_loss: 136.3608 - t_output_loss: 86.1704
58880/60000 [============================>.] - ETA: 0s - loss: 222.4694 - s_output_loss: 136.3269 - t_output_loss: 86.1424
59264/60000 [============================>.] - ETA: 0s - loss: 222.3711 - s_output_loss: 136.2782 - t_output_loss: 86.0929
59520/60000 [============================>.] - ETA: 0s - loss: 222.2926 - s_output_loss: 136.2441 - t_output_loss: 86.0485
59776/60000 [============================>.] - ETA: 0s - loss: 222.2150 - s_output_loss: 136.2044 - t_output_loss: 86.0106
60000/60000 [==============================] - 13s 212us/step - loss: 222.1400 - s_output_loss: 136.1648 - t_output_loss: 85.9752 - val_loss: 207.2806 - val_s_output_loss: 126.7197 - val_t_output_loss: 80.5610
Epoch 7/10

  128/60000 [..............................] - ETA: 14s - loss: 205.2570 - s_output_loss: 127.8795 - t_output_loss: 77.3775
  384/60000 [..............................] - ETA: 13s - loss: 207.8860 - s_output_loss: 129.3417 - t_output_loss: 78.5443
  640/60000 [..............................] - ETA: 12s - loss: 206.4848 - s_output_loss: 128.5804 - t_output_loss: 77.9044
  896/60000 [..............................] - ETA: 12s - loss: 208.2709 - s_output_loss: 129.3918 - t_output_loss: 78.8792
 1280/60000 [..............................] - ETA: 12s - loss: 206.4747 - s_output_loss: 128.2147 - t_output_loss: 78.2600
 1536/60000 [..............................] - ETA: 12s - loss: 205.7795 - s_output_loss: 127.8266 - t_output_loss: 77.9529
 1792/60000 [..............................] - ETA: 12s - loss: 205.4088 - s_output_loss: 127.6043 - t_output_loss: 77.8045
 2176/60000 [>.............................] - ETA: 12s - loss: 205.6889 - s_output_loss: 127.9400 - t_output_loss: 77.7488
 2560/60000 [>.............................] - ETA: 11s - loss: 205.3859 - s_output_loss: 127.8506 - t_output_loss: 77.5353
 2816/60000 [>.............................] - ETA: 11s - loss: 205.1629 - s_output_loss: 127.7566 - t_output_loss: 77.4063
 3072/60000 [>.............................] - ETA: 11s - loss: 204.7192 - s_output_loss: 127.5579 - t_output_loss: 77.1613
 3456/60000 [>.............................] - ETA: 11s - loss: 205.0630 - s_output_loss: 127.9180 - t_output_loss: 77.1450
 3712/60000 [>.............................] - ETA: 11s - loss: 205.1637 - s_output_loss: 127.9479 - t_output_loss: 77.2157
 3968/60000 [>.............................] - ETA: 11s - loss: 204.8819 - s_output_loss: 127.7120 - t_output_loss: 77.1699
 4224/60000 [=>............................] - ETA: 11s - loss: 204.9437 - s_output_loss: 127.6707 - t_output_loss: 77.2730
 4480/60000 [=>............................] - ETA: 11s - loss: 204.8041 - s_output_loss: 127.5327 - t_output_loss: 77.2714
 4864/60000 [=>............................] - ETA: 11s - loss: 204.7805 - s_output_loss: 127.5382 - t_output_loss: 77.2424
 5120/60000 [=>............................] - ETA: 11s - loss: 204.5849 - s_output_loss: 127.4262 - t_output_loss: 77.1588
 5504/60000 [=>............................] - ETA: 11s - loss: 204.7072 - s_output_loss: 127.5415 - t_output_loss: 77.1657
 5888/60000 [=>............................] - ETA: 11s - loss: 204.8362 - s_output_loss: 127.6901 - t_output_loss: 77.1461
 6272/60000 [==>...........................] - ETA: 10s - loss: 204.6994 - s_output_loss: 127.6420 - t_output_loss: 77.0574
 6656/60000 [==>...........................] - ETA: 10s - loss: 204.8247 - s_output_loss: 127.8101 - t_output_loss: 77.0146
 6912/60000 [==>...........................] - ETA: 10s - loss: 205.6705 - s_output_loss: 128.5230 - t_output_loss: 77.1475
 7168/60000 [==>...........................] - ETA: 10s - loss: 206.6531 - s_output_loss: 129.4810 - t_output_loss: 77.1722
 7424/60000 [==>...........................] - ETA: 10s - loss: 207.2158 - s_output_loss: 130.0543 - t_output_loss: 77.1615
 7680/60000 [==>...........................] - ETA: 10s - loss: 207.4777 - s_output_loss: 130.3195 - t_output_loss: 77.1582
 7936/60000 [==>...........................] - ETA: 10s - loss: 207.5203 - s_output_loss: 130.4026 - t_output_loss: 77.1177
 8192/60000 [===>..........................] - ETA: 10s - loss: 207.8059 - s_output_loss: 130.6572 - t_output_loss: 77.1487
 8448/60000 [===>..........................] - ETA: 10s - loss: 207.9403 - s_output_loss: 130.8843 - t_output_loss: 77.0560
 8704/60000 [===>..........................] - ETA: 10s - loss: 208.0902 - s_output_loss: 131.0655 - t_output_loss: 77.0246
 8960/60000 [===>..........................] - ETA: 10s - loss: 208.2856 - s_output_loss: 131.2571 - t_output_loss: 77.0285
 9216/60000 [===>..........................] - ETA: 10s - loss: 208.2179 - s_output_loss: 131.2301 - t_output_loss: 76.9878
 9472/60000 [===>..........................] - ETA: 10s - loss: 208.2142 - s_output_loss: 131.2403 - t_output_loss: 76.9739
 9728/60000 [===>..........................] - ETA: 10s - loss: 208.1330 - s_output_loss: 131.1598 - t_output_loss: 76.9732
 9984/60000 [===>..........................] - ETA: 10s - loss: 208.0654 - s_output_loss: 131.0961 - t_output_loss: 76.9692
10240/60000 [====>.........................] - ETA: 10s - loss: 207.9910 - s_output_loss: 131.0614 - t_output_loss: 76.9296
10624/60000 [====>.........................] - ETA: 10s - loss: 207.7545 - s_output_loss: 130.9781 - t_output_loss: 76.7764
11008/60000 [====>.........................] - ETA: 9s - loss: 207.7536 - s_output_loss: 130.9939 - t_output_loss: 76.7597 
11264/60000 [====>.........................] - ETA: 9s - loss: 207.7643 - s_output_loss: 131.0368 - t_output_loss: 76.7275
11520/60000 [====>.........................] - ETA: 9s - loss: 207.7195 - s_output_loss: 130.9847 - t_output_loss: 76.7348
11776/60000 [====>.........................] - ETA: 9s - loss: 207.6685 - s_output_loss: 130.9870 - t_output_loss: 76.6815
12032/60000 [=====>........................] - ETA: 9s - loss: 207.5275 - s_output_loss: 130.9020 - t_output_loss: 76.6254
12288/60000 [=====>........................] - ETA: 9s - loss: 207.3458 - s_output_loss: 130.8199 - t_output_loss: 76.5259
12544/60000 [=====>........................] - ETA: 9s - loss: 207.2303 - s_output_loss: 130.7349 - t_output_loss: 76.4954
12800/60000 [=====>........................] - ETA: 9s - loss: 207.1683 - s_output_loss: 130.7162 - t_output_loss: 76.4521
13056/60000 [=====>........................] - ETA: 9s - loss: 207.2027 - s_output_loss: 130.7573 - t_output_loss: 76.4454
13312/60000 [=====>........................] - ETA: 9s - loss: 207.2329 - s_output_loss: 130.7760 - t_output_loss: 76.4569
13568/60000 [=====>........................] - ETA: 9s - loss: 207.1548 - s_output_loss: 130.7334 - t_output_loss: 76.4214
13952/60000 [=====>........................] - ETA: 9s - loss: 206.9312 - s_output_loss: 130.5866 - t_output_loss: 76.3446
14336/60000 [======>.......................] - ETA: 9s - loss: 206.7715 - s_output_loss: 130.4845 - t_output_loss: 76.2870
14592/60000 [======>.......................] - ETA: 9s - loss: 206.7251 - s_output_loss: 130.4454 - t_output_loss: 76.2797
14848/60000 [======>.......................] - ETA: 9s - loss: 206.6255 - s_output_loss: 130.3701 - t_output_loss: 76.2554
15104/60000 [======>.......................] - ETA: 9s - loss: 206.5875 - s_output_loss: 130.3342 - t_output_loss: 76.2533
15360/60000 [======>.......................] - ETA: 9s - loss: 206.5310 - s_output_loss: 130.2690 - t_output_loss: 76.2619
15616/60000 [======>.......................] - ETA: 8s - loss: 206.4350 - s_output_loss: 130.1936 - t_output_loss: 76.2414
15872/60000 [======>.......................] - ETA: 8s - loss: 206.7470 - s_output_loss: 130.2627 - t_output_loss: 76.4844
16256/60000 [=======>......................] - ETA: 8s - loss: 207.9454 - s_output_loss: 130.2407 - t_output_loss: 77.7047
16512/60000 [=======>......................] - ETA: 8s - loss: 208.7787 - s_output_loss: 130.2202 - t_output_loss: 78.5586
16768/60000 [=======>......................] - ETA: 8s - loss: 209.3500 - s_output_loss: 130.1882 - t_output_loss: 79.1618
17152/60000 [=======>......................] - ETA: 8s - loss: 210.0856 - s_output_loss: 130.2034 - t_output_loss: 79.8822
17408/60000 [=======>......................] - ETA: 8s - loss: 210.2861 - s_output_loss: 130.1091 - t_output_loss: 80.1770
17664/60000 [=======>......................] - ETA: 8s - loss: 210.5180 - s_output_loss: 130.1431 - t_output_loss: 80.3749
18048/60000 [========>.....................] - ETA: 8s - loss: 210.9991 - s_output_loss: 130.2377 - t_output_loss: 80.7613
18432/60000 [========>.....................] - ETA: 8s - loss: 211.5335 - s_output_loss: 130.3848 - t_output_loss: 81.1487
18816/60000 [========>.....................] - ETA: 8s - loss: 211.8824 - s_output_loss: 130.4545 - t_output_loss: 81.4279
19200/60000 [========>.....................] - ETA: 8s - loss: 212.1133 - s_output_loss: 130.4979 - t_output_loss: 81.6155
19584/60000 [========>.....................] - ETA: 8s - loss: 212.2295 - s_output_loss: 130.4703 - t_output_loss: 81.7593
19968/60000 [========>.....................] - ETA: 8s - loss: 212.3567 - s_output_loss: 130.4856 - t_output_loss: 81.8711
20352/60000 [=========>....................] - ETA: 8s - loss: 212.3663 - s_output_loss: 130.4285 - t_output_loss: 81.9378
20608/60000 [=========>....................] - ETA: 7s - loss: 212.3226 - s_output_loss: 130.3417 - t_output_loss: 81.9809
20992/60000 [=========>....................] - ETA: 7s - loss: 212.3511 - s_output_loss: 130.3157 - t_output_loss: 82.0355
21248/60000 [=========>....................] - ETA: 7s - loss: 212.2742 - s_output_loss: 130.2394 - t_output_loss: 82.0349
21632/60000 [=========>....................] - ETA: 7s - loss: 212.4281 - s_output_loss: 130.3713 - t_output_loss: 82.0567
21888/60000 [=========>....................] - ETA: 7s - loss: 212.5635 - s_output_loss: 130.4884 - t_output_loss: 82.0751
22144/60000 [==========>...................] - ETA: 7s - loss: 212.6958 - s_output_loss: 130.6118 - t_output_loss: 82.0840
22400/60000 [==========>...................] - ETA: 7s - loss: 212.7588 - s_output_loss: 130.6862 - t_output_loss: 82.0726
22656/60000 [==========>...................] - ETA: 7s - loss: 212.8069 - s_output_loss: 130.7290 - t_output_loss: 82.0779
22912/60000 [==========>...................] - ETA: 7s - loss: 212.8698 - s_output_loss: 130.8131 - t_output_loss: 82.0567
23168/60000 [==========>...................] - ETA: 7s - loss: 212.8723 - s_output_loss: 130.8392 - t_output_loss: 82.0331
23424/60000 [==========>...................] - ETA: 7s - loss: 212.9184 - s_output_loss: 130.8741 - t_output_loss: 82.0443
23680/60000 [==========>...................] - ETA: 7s - loss: 213.0096 - s_output_loss: 130.9568 - t_output_loss: 82.0528
23936/60000 [==========>...................] - ETA: 7s - loss: 213.1436 - s_output_loss: 131.1146 - t_output_loss: 82.0290
24192/60000 [===========>..................] - ETA: 7s - loss: 213.3206 - s_output_loss: 131.2936 - t_output_loss: 82.0270
24448/60000 [===========>..................] - ETA: 7s - loss: 213.5662 - s_output_loss: 131.5009 - t_output_loss: 82.0653
24704/60000 [===========>..................] - ETA: 7s - loss: 213.8135 - s_output_loss: 131.7059 - t_output_loss: 82.1076
24960/60000 [===========>..................] - ETA: 7s - loss: 213.8799 - s_output_loss: 131.8007 - t_output_loss: 82.0792
25216/60000 [===========>..................] - ETA: 7s - loss: 213.9207 - s_output_loss: 131.8676 - t_output_loss: 82.0531
25472/60000 [===========>..................] - ETA: 7s - loss: 214.0066 - s_output_loss: 131.9483 - t_output_loss: 82.0583
25728/60000 [===========>..................] - ETA: 7s - loss: 214.0747 - s_output_loss: 132.0175 - t_output_loss: 82.0572
25984/60000 [===========>..................] - ETA: 6s - loss: 214.1094 - s_output_loss: 132.0765 - t_output_loss: 82.0328
26240/60000 [============>.................] - ETA: 6s - loss: 214.1095 - s_output_loss: 132.1009 - t_output_loss: 82.0086
26496/60000 [============>.................] - ETA: 6s - loss: 214.1516 - s_output_loss: 132.1510 - t_output_loss: 82.0006
26880/60000 [============>.................] - ETA: 6s - loss: 214.1259 - s_output_loss: 132.1478 - t_output_loss: 81.9780
27136/60000 [============>.................] - ETA: 6s - loss: 214.1195 - s_output_loss: 132.1398 - t_output_loss: 81.9797
27392/60000 [============>.................] - ETA: 6s - loss: 214.1797 - s_output_loss: 132.1856 - t_output_loss: 81.9942
27648/60000 [============>.................] - ETA: 6s - loss: 214.1728 - s_output_loss: 132.1880 - t_output_loss: 81.9848
27904/60000 [============>.................] - ETA: 6s - loss: 214.0915 - s_output_loss: 132.1366 - t_output_loss: 81.9549
28160/60000 [=============>................] - ETA: 6s - loss: 214.0181 - s_output_loss: 132.0931 - t_output_loss: 81.9249
28416/60000 [=============>................] - ETA: 6s - loss: 213.8750 - s_output_loss: 132.0191 - t_output_loss: 81.8559
28800/60000 [=============>................] - ETA: 6s - loss: 213.8102 - s_output_loss: 132.0002 - t_output_loss: 81.8100
29056/60000 [=============>................] - ETA: 6s - loss: 213.8022 - s_output_loss: 132.0043 - t_output_loss: 81.7979
29312/60000 [=============>................] - ETA: 6s - loss: 213.7249 - s_output_loss: 131.9589 - t_output_loss: 81.7660
29568/60000 [=============>................] - ETA: 6s - loss: 213.6341 - s_output_loss: 131.9050 - t_output_loss: 81.7291
29824/60000 [=============>................] - ETA: 6s - loss: 213.6140 - s_output_loss: 131.8970 - t_output_loss: 81.7169
30080/60000 [==============>...............] - ETA: 6s - loss: 213.5288 - s_output_loss: 131.8541 - t_output_loss: 81.6747
30336/60000 [==============>...............] - ETA: 6s - loss: 213.4601 - s_output_loss: 131.8117 - t_output_loss: 81.6484
30592/60000 [==============>...............] - ETA: 6s - loss: 213.4168 - s_output_loss: 131.8040 - t_output_loss: 81.6128
30848/60000 [==============>...............] - ETA: 5s - loss: 213.3710 - s_output_loss: 131.7729 - t_output_loss: 81.5981
31104/60000 [==============>...............] - ETA: 5s - loss: 213.2681 - s_output_loss: 131.7179 - t_output_loss: 81.5501
31360/60000 [==============>...............] - ETA: 5s - loss: 213.2204 - s_output_loss: 131.6992 - t_output_loss: 81.5212
31744/60000 [==============>...............] - ETA: 5s - loss: 213.0705 - s_output_loss: 131.6090 - t_output_loss: 81.4616
32000/60000 [===============>..............] - ETA: 5s - loss: 213.0026 - s_output_loss: 131.5871 - t_output_loss: 81.4156
32256/60000 [===============>..............] - ETA: 5s - loss: 212.9352 - s_output_loss: 131.5569 - t_output_loss: 81.3783
32512/60000 [===============>..............] - ETA: 5s - loss: 212.8877 - s_output_loss: 131.5356 - t_output_loss: 81.3521
32768/60000 [===============>..............] - ETA: 5s - loss: 212.8365 - s_output_loss: 131.5056 - t_output_loss: 81.3309
33024/60000 [===============>..............] - ETA: 5s - loss: 212.7418 - s_output_loss: 131.4529 - t_output_loss: 81.2888
33280/60000 [===============>..............] - ETA: 5s - loss: 212.6951 - s_output_loss: 131.4227 - t_output_loss: 81.2723
33536/60000 [===============>..............] - ETA: 5s - loss: 212.6472 - s_output_loss: 131.4069 - t_output_loss: 81.2403
33792/60000 [===============>..............] - ETA: 5s - loss: 212.5668 - s_output_loss: 131.3625 - t_output_loss: 81.2043
34048/60000 [================>.............] - ETA: 5s - loss: 212.5078 - s_output_loss: 131.3310 - t_output_loss: 81.1768
34304/60000 [================>.............] - ETA: 5s - loss: 212.4448 - s_output_loss: 131.2934 - t_output_loss: 81.1514
34688/60000 [================>.............] - ETA: 5s - loss: 212.3299 - s_output_loss: 131.2162 - t_output_loss: 81.1137
34944/60000 [================>.............] - ETA: 5s - loss: 212.2922 - s_output_loss: 131.1947 - t_output_loss: 81.0975
35200/60000 [================>.............] - ETA: 5s - loss: 212.2295 - s_output_loss: 131.1709 - t_output_loss: 81.0587
35456/60000 [================>.............] - ETA: 5s - loss: 212.1667 - s_output_loss: 131.1318 - t_output_loss: 81.0349
35712/60000 [================>.............] - ETA: 4s - loss: 212.1188 - s_output_loss: 131.1042 - t_output_loss: 81.0146
35968/60000 [================>.............] - ETA: 4s - loss: 212.0561 - s_output_loss: 131.0709 - t_output_loss: 80.9852
36224/60000 [=================>............] - ETA: 4s - loss: 211.9978 - s_output_loss: 131.0331 - t_output_loss: 80.9647
36480/60000 [=================>............] - ETA: 4s - loss: 211.9089 - s_output_loss: 130.9870 - t_output_loss: 80.9219
36736/60000 [=================>............] - ETA: 4s - loss: 211.8291 - s_output_loss: 130.9393 - t_output_loss: 80.8899
36992/60000 [=================>............] - ETA: 4s - loss: 211.7965 - s_output_loss: 130.9233 - t_output_loss: 80.8732
37248/60000 [=================>............] - ETA: 4s - loss: 211.7403 - s_output_loss: 130.9006 - t_output_loss: 80.8397
37504/60000 [=================>............] - ETA: 4s - loss: 211.6639 - s_output_loss: 130.8574 - t_output_loss: 80.8065
37760/60000 [=================>............] - ETA: 4s - loss: 211.6369 - s_output_loss: 130.8515 - t_output_loss: 80.7854
38016/60000 [==================>...........] - ETA: 4s - loss: 211.5868 - s_output_loss: 130.8311 - t_output_loss: 80.7556
38272/60000 [==================>...........] - ETA: 4s - loss: 211.4899 - s_output_loss: 130.7815 - t_output_loss: 80.7085
38528/60000 [==================>...........] - ETA: 4s - loss: 211.4203 - s_output_loss: 130.7362 - t_output_loss: 80.6840
38784/60000 [==================>...........] - ETA: 4s - loss: 211.3194 - s_output_loss: 130.6873 - t_output_loss: 80.6322
39040/60000 [==================>...........] - ETA: 4s - loss: 211.2235 - s_output_loss: 130.6304 - t_output_loss: 80.5931
39296/60000 [==================>...........] - ETA: 4s - loss: 211.1781 - s_output_loss: 130.5985 - t_output_loss: 80.5795
39680/60000 [==================>...........] - ETA: 4s - loss: 211.1057 - s_output_loss: 130.5601 - t_output_loss: 80.5456
39936/60000 [==================>...........] - ETA: 4s - loss: 211.0114 - s_output_loss: 130.4999 - t_output_loss: 80.5115
40320/60000 [===================>..........] - ETA: 4s - loss: 210.9224 - s_output_loss: 130.4443 - t_output_loss: 80.4781
40576/60000 [===================>..........] - ETA: 3s - loss: 210.8457 - s_output_loss: 130.3945 - t_output_loss: 80.4512
40832/60000 [===================>..........] - ETA: 3s - loss: 210.7715 - s_output_loss: 130.3459 - t_output_loss: 80.4256
41088/60000 [===================>..........] - ETA: 3s - loss: 210.7577 - s_output_loss: 130.3494 - t_output_loss: 80.4084
41344/60000 [===================>..........] - ETA: 3s - loss: 210.7197 - s_output_loss: 130.3333 - t_output_loss: 80.3863
41600/60000 [===================>..........] - ETA: 3s - loss: 210.6236 - s_output_loss: 130.2866 - t_output_loss: 80.3370
41984/60000 [===================>..........] - ETA: 3s - loss: 210.5063 - s_output_loss: 130.2125 - t_output_loss: 80.2938
42240/60000 [====================>.........] - ETA: 3s - loss: 210.4620 - s_output_loss: 130.1802 - t_output_loss: 80.2818
42496/60000 [====================>.........] - ETA: 3s - loss: 210.4308 - s_output_loss: 130.1556 - t_output_loss: 80.2752
42752/60000 [====================>.........] - ETA: 3s - loss: 210.3586 - s_output_loss: 130.1135 - t_output_loss: 80.2451
43008/60000 [====================>.........] - ETA: 3s - loss: 210.2788 - s_output_loss: 130.0703 - t_output_loss: 80.2084
43264/60000 [====================>.........] - ETA: 3s - loss: 210.2280 - s_output_loss: 130.0537 - t_output_loss: 80.1742
43520/60000 [====================>.........] - ETA: 3s - loss: 210.1486 - s_output_loss: 130.0062 - t_output_loss: 80.1423
43776/60000 [====================>.........] - ETA: 3s - loss: 210.0747 - s_output_loss: 129.9662 - t_output_loss: 80.1085
44032/60000 [=====================>........] - ETA: 3s - loss: 210.0151 - s_output_loss: 129.9455 - t_output_loss: 80.0696
44288/60000 [=====================>........] - ETA: 3s - loss: 209.9336 - s_output_loss: 129.8996 - t_output_loss: 80.0340
44544/60000 [=====================>........] - ETA: 3s - loss: 209.8793 - s_output_loss: 129.8735 - t_output_loss: 80.0058
44800/60000 [=====================>........] - ETA: 3s - loss: 209.8010 - s_output_loss: 129.8396 - t_output_loss: 79.9614
45056/60000 [=====================>........] - ETA: 3s - loss: 209.7274 - s_output_loss: 129.8023 - t_output_loss: 79.9252
45312/60000 [=====================>........] - ETA: 3s - loss: 209.6663 - s_output_loss: 129.7766 - t_output_loss: 79.8897
45568/60000 [=====================>........] - ETA: 2s - loss: 209.6178 - s_output_loss: 129.7572 - t_output_loss: 79.8606
45952/60000 [=====================>........] - ETA: 2s - loss: 209.5272 - s_output_loss: 129.6964 - t_output_loss: 79.8307
46208/60000 [======================>.......] - ETA: 2s - loss: 209.4734 - s_output_loss: 129.6648 - t_output_loss: 79.8087
46464/60000 [======================>.......] - ETA: 2s - loss: 209.3979 - s_output_loss: 129.6303 - t_output_loss: 79.7676
46720/60000 [======================>.......] - ETA: 2s - loss: 209.3802 - s_output_loss: 129.6180 - t_output_loss: 79.7622
47104/60000 [======================>.......] - ETA: 2s - loss: 209.2834 - s_output_loss: 129.5630 - t_output_loss: 79.7204
47488/60000 [======================>.......] - ETA: 2s - loss: 209.2321 - s_output_loss: 129.5255 - t_output_loss: 79.7066
47744/60000 [======================>.......] - ETA: 2s - loss: 209.1596 - s_output_loss: 129.4866 - t_output_loss: 79.6731
48128/60000 [=======================>......] - ETA: 2s - loss: 209.0972 - s_output_loss: 129.4669 - t_output_loss: 79.6303
48384/60000 [=======================>......] - ETA: 2s - loss: 209.0260 - s_output_loss: 129.4314 - t_output_loss: 79.5946
48640/60000 [=======================>......] - ETA: 2s - loss: 208.9791 - s_output_loss: 129.4012 - t_output_loss: 79.5778
48896/60000 [=======================>......] - ETA: 2s - loss: 208.9307 - s_output_loss: 129.3728 - t_output_loss: 79.5579
49152/60000 [=======================>......] - ETA: 2s - loss: 208.8629 - s_output_loss: 129.3292 - t_output_loss: 79.5337
49408/60000 [=======================>......] - ETA: 2s - loss: 208.8147 - s_output_loss: 129.3047 - t_output_loss: 79.5100
49792/60000 [=======================>......] - ETA: 2s - loss: 208.7445 - s_output_loss: 129.2638 - t_output_loss: 79.4807
50048/60000 [========================>.....] - ETA: 2s - loss: 208.7086 - s_output_loss: 129.2437 - t_output_loss: 79.4649
50304/60000 [========================>.....] - ETA: 2s - loss: 208.6577 - s_output_loss: 129.2164 - t_output_loss: 79.4413
50560/60000 [========================>.....] - ETA: 1s - loss: 208.5928 - s_output_loss: 129.1784 - t_output_loss: 79.4144
50816/60000 [========================>.....] - ETA: 1s - loss: 208.5226 - s_output_loss: 129.1390 - t_output_loss: 79.3836
51200/60000 [========================>.....] - ETA: 1s - loss: 208.4602 - s_output_loss: 129.1136 - t_output_loss: 79.3466
51584/60000 [========================>.....] - ETA: 1s - loss: 208.3801 - s_output_loss: 129.0720 - t_output_loss: 79.3081
51840/60000 [========================>.....] - ETA: 1s - loss: 208.3180 - s_output_loss: 129.0415 - t_output_loss: 79.2765
52096/60000 [=========================>....] - ETA: 1s - loss: 208.2712 - s_output_loss: 129.0207 - t_output_loss: 79.2504
52352/60000 [=========================>....] - ETA: 1s - loss: 208.2135 - s_output_loss: 128.9864 - t_output_loss: 79.2271
52608/60000 [=========================>....] - ETA: 1s - loss: 208.1561 - s_output_loss: 128.9582 - t_output_loss: 79.1980
52864/60000 [=========================>....] - ETA: 1s - loss: 208.1282 - s_output_loss: 128.9509 - t_output_loss: 79.1773
53120/60000 [=========================>....] - ETA: 1s - loss: 208.0841 - s_output_loss: 128.9385 - t_output_loss: 79.1457
53376/60000 [=========================>....] - ETA: 1s - loss: 208.0610 - s_output_loss: 128.9496 - t_output_loss: 79.1114
53632/60000 [=========================>....] - ETA: 1s - loss: 208.0098 - s_output_loss: 128.9351 - t_output_loss: 79.0747
53888/60000 [=========================>....] - ETA: 1s - loss: 207.9960 - s_output_loss: 128.9491 - t_output_loss: 79.0468
54144/60000 [==========================>...] - ETA: 1s - loss: 208.0120 - s_output_loss: 128.9724 - t_output_loss: 79.0396
54400/60000 [==========================>...] - ETA: 1s - loss: 207.9729 - s_output_loss: 128.9567 - t_output_loss: 79.0162
54656/60000 [==========================>...] - ETA: 1s - loss: 207.9827 - s_output_loss: 128.9745 - t_output_loss: 79.0082
54912/60000 [==========================>...] - ETA: 1s - loss: 207.9714 - s_output_loss: 128.9628 - t_output_loss: 79.0086
55168/60000 [==========================>...] - ETA: 0s - loss: 207.9888 - s_output_loss: 128.9618 - t_output_loss: 79.0271
55424/60000 [==========================>...] - ETA: 0s - loss: 207.9624 - s_output_loss: 128.9421 - t_output_loss: 79.0204
55680/60000 [==========================>...] - ETA: 0s - loss: 207.9323 - s_output_loss: 128.9055 - t_output_loss: 79.0268
55936/60000 [==========================>...] - ETA: 0s - loss: 207.9081 - s_output_loss: 128.8964 - t_output_loss: 79.0117
56192/60000 [===========================>..] - ETA: 0s - loss: 207.8716 - s_output_loss: 128.8756 - t_output_loss: 78.9960
56448/60000 [===========================>..] - ETA: 0s - loss: 207.8452 - s_output_loss: 128.8586 - t_output_loss: 78.9866
56832/60000 [===========================>..] - ETA: 0s - loss: 207.8255 - s_output_loss: 128.8505 - t_output_loss: 78.9750
57216/60000 [===========================>..] - ETA: 0s - loss: 207.7631 - s_output_loss: 128.8112 - t_output_loss: 78.9519
57472/60000 [===========================>..] - ETA: 0s - loss: 207.7319 - s_output_loss: 128.7969 - t_output_loss: 78.9350
57728/60000 [===========================>..] - ETA: 0s - loss: 207.6887 - s_output_loss: 128.7736 - t_output_loss: 78.9151
58112/60000 [============================>.] - ETA: 0s - loss: 207.6454 - s_output_loss: 128.7598 - t_output_loss: 78.8856
58368/60000 [============================>.] - ETA: 0s - loss: 207.6066 - s_output_loss: 128.7385 - t_output_loss: 78.8681
58624/60000 [============================>.] - ETA: 0s - loss: 207.5582 - s_output_loss: 128.7126 - t_output_loss: 78.8455
58880/60000 [============================>.] - ETA: 0s - loss: 207.5211 - s_output_loss: 128.6988 - t_output_loss: 78.8224
59136/60000 [============================>.] - ETA: 0s - loss: 207.4762 - s_output_loss: 128.6754 - t_output_loss: 78.8008
59392/60000 [============================>.] - ETA: 0s - loss: 207.4571 - s_output_loss: 128.6744 - t_output_loss: 78.7826
59648/60000 [============================>.] - ETA: 0s - loss: 207.4248 - s_output_loss: 128.6586 - t_output_loss: 78.7662
59904/60000 [============================>.] - ETA: 0s - loss: 207.3907 - s_output_loss: 128.6420 - t_output_loss: 78.7488
60000/60000 [==============================] - 13s 219us/step - loss: 207.3660 - s_output_loss: 128.6277 - t_output_loss: 78.7383 - val_loss: 199.8017 - val_s_output_loss: 122.3043 - val_t_output_loss: 77.4973
Epoch 8/10

  128/60000 [..............................] - ETA: 15s - loss: 193.6599 - s_output_loss: 122.0039 - t_output_loss: 71.6560
  384/60000 [..............................] - ETA: 13s - loss: 198.9011 - s_output_loss: 123.3188 - t_output_loss: 75.5823
  640/60000 [..............................] - ETA: 12s - loss: 197.2319 - s_output_loss: 123.4251 - t_output_loss: 73.8068
  896/60000 [..............................] - ETA: 12s - loss: 196.4345 - s_output_loss: 122.8429 - t_output_loss: 73.5916
 1152/60000 [..............................] - ETA: 12s - loss: 196.4519 - s_output_loss: 122.7937 - t_output_loss: 73.6582
 1408/60000 [..............................] - ETA: 12s - loss: 197.9331 - s_output_loss: 123.9135 - t_output_loss: 74.0196
 1792/60000 [..............................] - ETA: 11s - loss: 197.4407 - s_output_loss: 124.1212 - t_output_loss: 73.3194
 2048/60000 [>.............................] - ETA: 11s - loss: 197.5752 - s_output_loss: 124.3208 - t_output_loss: 73.2545
 2304/60000 [>.............................] - ETA: 11s - loss: 198.2505 - s_output_loss: 124.8874 - t_output_loss: 73.3631
 2560/60000 [>.............................] - ETA: 11s - loss: 198.9256 - s_output_loss: 125.4696 - t_output_loss: 73.4560
 2944/60000 [>.............................] - ETA: 11s - loss: 199.6660 - s_output_loss: 126.0932 - t_output_loss: 73.5727
 3328/60000 [>.............................] - ETA: 11s - loss: 199.8872 - s_output_loss: 126.4518 - t_output_loss: 73.4354
 3584/60000 [>.............................] - ETA: 11s - loss: 199.3998 - s_output_loss: 126.1426 - t_output_loss: 73.2572
 3840/60000 [>.............................] - ETA: 11s - loss: 199.2905 - s_output_loss: 126.0089 - t_output_loss: 73.2816
 4096/60000 [=>............................] - ETA: 11s - loss: 199.0553 - s_output_loss: 125.8229 - t_output_loss: 73.2325
 4352/60000 [=>............................] - ETA: 11s - loss: 199.0428 - s_output_loss: 125.8612 - t_output_loss: 73.1816
 4608/60000 [=>............................] - ETA: 11s - loss: 198.5004 - s_output_loss: 125.4964 - t_output_loss: 73.0039
 4992/60000 [=>............................] - ETA: 11s - loss: 198.1129 - s_output_loss: 125.2203 - t_output_loss: 72.8926
 5248/60000 [=>............................] - ETA: 11s - loss: 198.0864 - s_output_loss: 125.1521 - t_output_loss: 72.9343
 5504/60000 [=>............................] - ETA: 10s - loss: 198.4875 - s_output_loss: 125.4209 - t_output_loss: 73.0665
 5760/60000 [=>............................] - ETA: 10s - loss: 198.9330 - s_output_loss: 125.7608 - t_output_loss: 73.1722
 6016/60000 [==>...........................] - ETA: 10s - loss: 199.2126 - s_output_loss: 126.0256 - t_output_loss: 73.1869
 6272/60000 [==>...........................] - ETA: 10s - loss: 199.2885 - s_output_loss: 126.2113 - t_output_loss: 73.0771
 6528/60000 [==>...........................] - ETA: 10s - loss: 199.4235 - s_output_loss: 126.3800 - t_output_loss: 73.0435
 6784/60000 [==>...........................] - ETA: 10s - loss: 199.8111 - s_output_loss: 126.5720 - t_output_loss: 73.2391
 7040/60000 [==>...........................] - ETA: 10s - loss: 200.4161 - s_output_loss: 126.6930 - t_output_loss: 73.7230
 7424/60000 [==>...........................] - ETA: 10s - loss: 201.2815 - s_output_loss: 126.8632 - t_output_loss: 74.4183
 7808/60000 [==>...........................] - ETA: 10s - loss: 201.4514 - s_output_loss: 126.6775 - t_output_loss: 74.7740
 8064/60000 [===>..........................] - ETA: 10s - loss: 201.3484 - s_output_loss: 126.5327 - t_output_loss: 74.8156
 8320/60000 [===>..........................] - ETA: 10s - loss: 201.4048 - s_output_loss: 126.5567 - t_output_loss: 74.8482
 8704/60000 [===>..........................] - ETA: 10s - loss: 201.5374 - s_output_loss: 126.5005 - t_output_loss: 75.0368
 8960/60000 [===>..........................] - ETA: 10s - loss: 201.6216 - s_output_loss: 126.4746 - t_output_loss: 75.1471
 9216/60000 [===>..........................] - ETA: 10s - loss: 201.6872 - s_output_loss: 126.4877 - t_output_loss: 75.1995
 9472/60000 [===>..........................] - ETA: 10s - loss: 201.8251 - s_output_loss: 126.5308 - t_output_loss: 75.2944
 9728/60000 [===>..........................] - ETA: 10s - loss: 201.8079 - s_output_loss: 126.4934 - t_output_loss: 75.3145
 9984/60000 [===>..........................] - ETA: 10s - loss: 201.6770 - s_output_loss: 126.3815 - t_output_loss: 75.2955
10240/60000 [====>.........................] - ETA: 10s - loss: 201.6673 - s_output_loss: 126.3323 - t_output_loss: 75.3350
10496/60000 [====>.........................] - ETA: 9s - loss: 201.6410 - s_output_loss: 126.2889 - t_output_loss: 75.3521 
10752/60000 [====>.........................] - ETA: 9s - loss: 201.6121 - s_output_loss: 126.2648 - t_output_loss: 75.3474
11136/60000 [====>.........................] - ETA: 9s - loss: 201.5725 - s_output_loss: 126.2660 - t_output_loss: 75.3064
11392/60000 [====>.........................] - ETA: 9s - loss: 201.3767 - s_output_loss: 126.1305 - t_output_loss: 75.2461
11648/60000 [====>.........................] - ETA: 9s - loss: 201.4656 - s_output_loss: 126.1472 - t_output_loss: 75.3184
11904/60000 [====>.........................] - ETA: 9s - loss: 201.4289 - s_output_loss: 126.1427 - t_output_loss: 75.2861
12160/60000 [=====>........................] - ETA: 9s - loss: 201.4182 - s_output_loss: 126.1098 - t_output_loss: 75.3084
12544/60000 [=====>........................] - ETA: 9s - loss: 201.4761 - s_output_loss: 126.0489 - t_output_loss: 75.4272
12928/60000 [=====>........................] - ETA: 9s - loss: 201.4691 - s_output_loss: 125.9641 - t_output_loss: 75.5050
13184/60000 [=====>........................] - ETA: 9s - loss: 201.4469 - s_output_loss: 125.9190 - t_output_loss: 75.5279
13440/60000 [=====>........................] - ETA: 9s - loss: 201.4431 - s_output_loss: 125.8780 - t_output_loss: 75.5651
13696/60000 [=====>........................] - ETA: 9s - loss: 201.3623 - s_output_loss: 125.8044 - t_output_loss: 75.5579
13952/60000 [=====>........................] - ETA: 9s - loss: 201.3090 - s_output_loss: 125.7532 - t_output_loss: 75.5557
14336/60000 [======>.......................] - ETA: 9s - loss: 201.2843 - s_output_loss: 125.7203 - t_output_loss: 75.5639
14592/60000 [======>.......................] - ETA: 9s - loss: 201.2713 - s_output_loss: 125.7040 - t_output_loss: 75.5673
14848/60000 [======>.......................] - ETA: 9s - loss: 201.1062 - s_output_loss: 125.6151 - t_output_loss: 75.4911
15104/60000 [======>.......................] - ETA: 9s - loss: 200.9692 - s_output_loss: 125.5368 - t_output_loss: 75.4324
15360/60000 [======>.......................] - ETA: 9s - loss: 200.8797 - s_output_loss: 125.4694 - t_output_loss: 75.4103
15616/60000 [======>.......................] - ETA: 8s - loss: 200.9224 - s_output_loss: 125.5154 - t_output_loss: 75.4070
15872/60000 [======>.......................] - ETA: 8s - loss: 201.0607 - s_output_loss: 125.6556 - t_output_loss: 75.4051
16128/60000 [=======>......................] - ETA: 8s - loss: 201.1658 - s_output_loss: 125.7771 - t_output_loss: 75.3887
16384/60000 [=======>......................] - ETA: 8s - loss: 201.2291 - s_output_loss: 125.8463 - t_output_loss: 75.3828
16768/60000 [=======>......................] - ETA: 8s - loss: 201.2219 - s_output_loss: 125.8858 - t_output_loss: 75.3361
17024/60000 [=======>......................] - ETA: 8s - loss: 201.3169 - s_output_loss: 126.0088 - t_output_loss: 75.3082
17280/60000 [=======>......................] - ETA: 8s - loss: 201.2318 - s_output_loss: 126.0036 - t_output_loss: 75.2281
17536/60000 [=======>......................] - ETA: 8s - loss: 201.1575 - s_output_loss: 125.9981 - t_output_loss: 75.1594
17792/60000 [=======>......................] - ETA: 8s - loss: 201.1125 - s_output_loss: 126.0009 - t_output_loss: 75.1117
18048/60000 [========>.....................] - ETA: 8s - loss: 201.1271 - s_output_loss: 126.0076 - t_output_loss: 75.1195
18304/60000 [========>.....................] - ETA: 8s - loss: 201.1435 - s_output_loss: 126.0464 - t_output_loss: 75.0970
18688/60000 [========>.....................] - ETA: 8s - loss: 200.9599 - s_output_loss: 125.9683 - t_output_loss: 74.9916
18944/60000 [========>.....................] - ETA: 8s - loss: 200.8954 - s_output_loss: 125.9578 - t_output_loss: 74.9376
19200/60000 [========>.....................] - ETA: 8s - loss: 200.8728 - s_output_loss: 125.9609 - t_output_loss: 74.9119
19456/60000 [========>.....................] - ETA: 8s - loss: 200.8033 - s_output_loss: 125.9203 - t_output_loss: 74.8830
19712/60000 [========>.....................] - ETA: 8s - loss: 200.7589 - s_output_loss: 125.8855 - t_output_loss: 74.8734
19968/60000 [========>.....................] - ETA: 8s - loss: 200.7286 - s_output_loss: 125.8770 - t_output_loss: 74.8516
20224/60000 [=========>....................] - ETA: 8s - loss: 200.6390 - s_output_loss: 125.8145 - t_output_loss: 74.8245
20480/60000 [=========>....................] - ETA: 8s - loss: 200.4240 - s_output_loss: 125.6780 - t_output_loss: 74.7459
20736/60000 [=========>....................] - ETA: 7s - loss: 200.2827 - s_output_loss: 125.5962 - t_output_loss: 74.6865
20992/60000 [=========>....................] - ETA: 7s - loss: 200.1950 - s_output_loss: 125.5443 - t_output_loss: 74.6507
21248/60000 [=========>....................] - ETA: 7s - loss: 200.1980 - s_output_loss: 125.5437 - t_output_loss: 74.6543
21504/60000 [=========>....................] - ETA: 7s - loss: 200.1517 - s_output_loss: 125.5163 - t_output_loss: 74.6354
21888/60000 [=========>....................] - ETA: 7s - loss: 200.1908 - s_output_loss: 125.6062 - t_output_loss: 74.5846
22144/60000 [==========>...................] - ETA: 7s - loss: 200.1596 - s_output_loss: 125.6179 - t_output_loss: 74.5417
22400/60000 [==========>...................] - ETA: 7s - loss: 200.1735 - s_output_loss: 125.6704 - t_output_loss: 74.5031
22656/60000 [==========>...................] - ETA: 7s - loss: 200.1227 - s_output_loss: 125.6739 - t_output_loss: 74.4489
22912/60000 [==========>...................] - ETA: 7s - loss: 200.1101 - s_output_loss: 125.6984 - t_output_loss: 74.4117
23296/60000 [==========>...................] - ETA: 7s - loss: 200.1605 - s_output_loss: 125.7437 - t_output_loss: 74.4168
23552/60000 [==========>...................] - ETA: 7s - loss: 200.1386 - s_output_loss: 125.7464 - t_output_loss: 74.3921
23808/60000 [==========>...................] - ETA: 7s - loss: 200.1236 - s_output_loss: 125.7480 - t_output_loss: 74.3757
24064/60000 [===========>..................] - ETA: 7s - loss: 200.1881 - s_output_loss: 125.7709 - t_output_loss: 74.4172
24448/60000 [===========>..................] - ETA: 7s - loss: 200.2360 - s_output_loss: 125.7317 - t_output_loss: 74.5042
24704/60000 [===========>..................] - ETA: 7s - loss: 200.3841 - s_output_loss: 125.7474 - t_output_loss: 74.6367
24960/60000 [===========>..................] - ETA: 7s - loss: 200.7190 - s_output_loss: 125.8159 - t_output_loss: 74.9031
25216/60000 [===========>..................] - ETA: 7s - loss: 201.1424 - s_output_loss: 125.9689 - t_output_loss: 75.1735
25472/60000 [===========>..................] - ETA: 7s - loss: 201.5075 - s_output_loss: 126.0657 - t_output_loss: 75.4418
25728/60000 [===========>..................] - ETA: 6s - loss: 201.8211 - s_output_loss: 126.1683 - t_output_loss: 75.6528
26112/60000 [============>.................] - ETA: 6s - loss: 202.3015 - s_output_loss: 126.3711 - t_output_loss: 75.9303
26368/60000 [============>.................] - ETA: 6s - loss: 202.4585 - s_output_loss: 126.4047 - t_output_loss: 76.0538
26624/60000 [============>.................] - ETA: 6s - loss: 202.6418 - s_output_loss: 126.4776 - t_output_loss: 76.1641
26880/60000 [============>.................] - ETA: 6s - loss: 202.8152 - s_output_loss: 126.5273 - t_output_loss: 76.2879
27136/60000 [============>.................] - ETA: 6s - loss: 202.9652 - s_output_loss: 126.5655 - t_output_loss: 76.3996
27392/60000 [============>.................] - ETA: 6s - loss: 203.1456 - s_output_loss: 126.6258 - t_output_loss: 76.5199
27648/60000 [============>.................] - ETA: 6s - loss: 203.2205 - s_output_loss: 126.6263 - t_output_loss: 76.5942
27904/60000 [============>.................] - ETA: 6s - loss: 203.3302 - s_output_loss: 126.6618 - t_output_loss: 76.6685
28160/60000 [=============>................] - ETA: 6s - loss: 203.4916 - s_output_loss: 126.7283 - t_output_loss: 76.7633
28544/60000 [=============>................] - ETA: 6s - loss: 203.5911 - s_output_loss: 126.7472 - t_output_loss: 76.8440
28800/60000 [=============>................] - ETA: 6s - loss: 203.6463 - s_output_loss: 126.7525 - t_output_loss: 76.8938
29056/60000 [=============>................] - ETA: 6s - loss: 203.7715 - s_output_loss: 126.8166 - t_output_loss: 76.9550
29312/60000 [=============>................] - ETA: 6s - loss: 203.8103 - s_output_loss: 126.8138 - t_output_loss: 76.9965
29568/60000 [=============>................] - ETA: 6s - loss: 203.8027 - s_output_loss: 126.8045 - t_output_loss: 76.9982
29824/60000 [=============>................] - ETA: 6s - loss: 203.8456 - s_output_loss: 126.8061 - t_output_loss: 77.0395
30080/60000 [==============>...............] - ETA: 6s - loss: 203.8559 - s_output_loss: 126.7902 - t_output_loss: 77.0658
30336/60000 [==============>...............] - ETA: 6s - loss: 203.9015 - s_output_loss: 126.7913 - t_output_loss: 77.1103
30592/60000 [==============>...............] - ETA: 5s - loss: 203.9556 - s_output_loss: 126.7974 - t_output_loss: 77.1581
30848/60000 [==============>...............] - ETA: 5s - loss: 203.9354 - s_output_loss: 126.7686 - t_output_loss: 77.1668
31232/60000 [==============>...............] - ETA: 5s - loss: 203.9892 - s_output_loss: 126.7753 - t_output_loss: 77.2139
31616/60000 [==============>...............] - ETA: 5s - loss: 204.0031 - s_output_loss: 126.7630 - t_output_loss: 77.2401
32000/60000 [===============>..............] - ETA: 5s - loss: 203.9844 - s_output_loss: 126.7330 - t_output_loss: 77.2513
32256/60000 [===============>..............] - ETA: 5s - loss: 203.9816 - s_output_loss: 126.7416 - t_output_loss: 77.2400
32512/60000 [===============>..............] - ETA: 5s - loss: 204.0130 - s_output_loss: 126.7722 - t_output_loss: 77.2408
32896/60000 [===============>..............] - ETA: 5s - loss: 204.0155 - s_output_loss: 126.7838 - t_output_loss: 77.2317
33152/60000 [===============>..............] - ETA: 5s - loss: 203.9944 - s_output_loss: 126.7887 - t_output_loss: 77.2057
33408/60000 [===============>..............] - ETA: 5s - loss: 204.0269 - s_output_loss: 126.8057 - t_output_loss: 77.2212
33664/60000 [===============>..............] - ETA: 5s - loss: 203.9471 - s_output_loss: 126.7748 - t_output_loss: 77.1723
33920/60000 [===============>..............] - ETA: 5s - loss: 203.9375 - s_output_loss: 126.7848 - t_output_loss: 77.1527
34176/60000 [================>.............] - ETA: 5s - loss: 203.9023 - s_output_loss: 126.7763 - t_output_loss: 77.1260
34432/60000 [================>.............] - ETA: 5s - loss: 203.8834 - s_output_loss: 126.7740 - t_output_loss: 77.1093
34816/60000 [================>.............] - ETA: 5s - loss: 203.8392 - s_output_loss: 126.7451 - t_output_loss: 77.0940
35072/60000 [================>.............] - ETA: 5s - loss: 203.8179 - s_output_loss: 126.7358 - t_output_loss: 77.0821
35456/60000 [================>.............] - ETA: 4s - loss: 203.8228 - s_output_loss: 126.7637 - t_output_loss: 77.0591
35712/60000 [================>.............] - ETA: 4s - loss: 203.8145 - s_output_loss: 126.7578 - t_output_loss: 77.0567
35968/60000 [================>.............] - ETA: 4s - loss: 203.7829 - s_output_loss: 126.7474 - t_output_loss: 77.0355
36224/60000 [=================>............] - ETA: 4s - loss: 203.7621 - s_output_loss: 126.7402 - t_output_loss: 77.0219
36480/60000 [=================>............] - ETA: 4s - loss: 203.7525 - s_output_loss: 126.7379 - t_output_loss: 77.0146
36736/60000 [=================>............] - ETA: 4s - loss: 203.7337 - s_output_loss: 126.7241 - t_output_loss: 77.0096
36992/60000 [=================>............] - ETA: 4s - loss: 203.6856 - s_output_loss: 126.6887 - t_output_loss: 76.9969
37376/60000 [=================>............] - ETA: 4s - loss: 203.6667 - s_output_loss: 126.6745 - t_output_loss: 76.9922
37760/60000 [=================>............] - ETA: 4s - loss: 203.5854 - s_output_loss: 126.6249 - t_output_loss: 76.9605
38016/60000 [==================>...........] - ETA: 4s - loss: 203.5425 - s_output_loss: 126.5977 - t_output_loss: 76.9448
38272/60000 [==================>...........] - ETA: 4s - loss: 203.4989 - s_output_loss: 126.5729 - t_output_loss: 76.9260
38528/60000 [==================>...........] - ETA: 4s - loss: 203.4746 - s_output_loss: 126.5580 - t_output_loss: 76.9166
38784/60000 [==================>...........] - ETA: 4s - loss: 203.4361 - s_output_loss: 126.5328 - t_output_loss: 76.9033
39168/60000 [==================>...........] - ETA: 4s - loss: 203.3392 - s_output_loss: 126.4926 - t_output_loss: 76.8466
39552/60000 [==================>...........] - ETA: 4s - loss: 203.2456 - s_output_loss: 126.4435 - t_output_loss: 76.8021
39808/60000 [==================>...........] - ETA: 4s - loss: 203.1888 - s_output_loss: 126.4126 - t_output_loss: 76.7761
40064/60000 [===================>..........] - ETA: 4s - loss: 203.1765 - s_output_loss: 126.4098 - t_output_loss: 76.7667
40320/60000 [===================>..........] - ETA: 4s - loss: 203.1295 - s_output_loss: 126.3848 - t_output_loss: 76.7447
40576/60000 [===================>..........] - ETA: 3s - loss: 203.0946 - s_output_loss: 126.3691 - t_output_loss: 76.7255
40832/60000 [===================>..........] - ETA: 3s - loss: 203.0903 - s_output_loss: 126.3610 - t_output_loss: 76.7293
41088/60000 [===================>..........] - ETA: 3s - loss: 203.0647 - s_output_loss: 126.3561 - t_output_loss: 76.7086
41344/60000 [===================>..........] - ETA: 3s - loss: 203.0465 - s_output_loss: 126.3417 - t_output_loss: 76.7048
41600/60000 [===================>..........] - ETA: 3s - loss: 203.0236 - s_output_loss: 126.3508 - t_output_loss: 76.6728
41856/60000 [===================>..........] - ETA: 3s - loss: 203.0639 - s_output_loss: 126.4088 - t_output_loss: 76.6552
42112/60000 [====================>.........] - ETA: 3s - loss: 203.0847 - s_output_loss: 126.4467 - t_output_loss: 76.6380
42368/60000 [====================>.........] - ETA: 3s - loss: 203.0975 - s_output_loss: 126.4854 - t_output_loss: 76.6121
42624/60000 [====================>.........] - ETA: 3s - loss: 203.0931 - s_output_loss: 126.4895 - t_output_loss: 76.6036
43008/60000 [====================>.........] - ETA: 3s - loss: 203.0232 - s_output_loss: 126.4651 - t_output_loss: 76.5581
43392/60000 [====================>.........] - ETA: 3s - loss: 203.0392 - s_output_loss: 126.4904 - t_output_loss: 76.5488
43776/60000 [====================>.........] - ETA: 3s - loss: 203.0252 - s_output_loss: 126.5031 - t_output_loss: 76.5221
44032/60000 [=====================>........] - ETA: 3s - loss: 203.0172 - s_output_loss: 126.5082 - t_output_loss: 76.5090
44416/60000 [=====================>........] - ETA: 3s - loss: 202.9892 - s_output_loss: 126.5068 - t_output_loss: 76.4823
44800/60000 [=====================>........] - ETA: 3s - loss: 202.9494 - s_output_loss: 126.4985 - t_output_loss: 76.4510
45056/60000 [=====================>........] - ETA: 3s - loss: 202.9277 - s_output_loss: 126.4907 - t_output_loss: 76.4370
45312/60000 [=====================>........] - ETA: 2s - loss: 202.9063 - s_output_loss: 126.4740 - t_output_loss: 76.4323
45568/60000 [=====================>........] - ETA: 2s - loss: 202.8412 - s_output_loss: 126.4321 - t_output_loss: 76.4092
45824/60000 [=====================>........] - ETA: 2s - loss: 202.8124 - s_output_loss: 126.4294 - t_output_loss: 76.3830
46080/60000 [======================>.......] - ETA: 2s - loss: 202.7382 - s_output_loss: 126.3883 - t_output_loss: 76.3500
46336/60000 [======================>.......] - ETA: 2s - loss: 202.7242 - s_output_loss: 126.3755 - t_output_loss: 76.3488
46592/60000 [======================>.......] - ETA: 2s - loss: 202.7065 - s_output_loss: 126.3729 - t_output_loss: 76.3336
46848/60000 [======================>.......] - ETA: 2s - loss: 202.7058 - s_output_loss: 126.3710 - t_output_loss: 76.3347
47104/60000 [======================>.......] - ETA: 2s - loss: 202.7048 - s_output_loss: 126.3668 - t_output_loss: 76.3380
47360/60000 [======================>.......] - ETA: 2s - loss: 202.7364 - s_output_loss: 126.3712 - t_output_loss: 76.3652
47616/60000 [======================>.......] - ETA: 2s - loss: 202.7425 - s_output_loss: 126.3573 - t_output_loss: 76.3852
48000/60000 [=======================>......] - ETA: 2s - loss: 202.7338 - s_output_loss: 126.3483 - t_output_loss: 76.3855
48256/60000 [=======================>......] - ETA: 2s - loss: 202.7060 - s_output_loss: 126.3263 - t_output_loss: 76.3797
48512/60000 [=======================>......] - ETA: 2s - loss: 202.7038 - s_output_loss: 126.3192 - t_output_loss: 76.3847
48768/60000 [=======================>......] - ETA: 2s - loss: 202.7194 - s_output_loss: 126.3222 - t_output_loss: 76.3972
49024/60000 [=======================>......] - ETA: 2s - loss: 202.7130 - s_output_loss: 126.3207 - t_output_loss: 76.3923
49408/60000 [=======================>......] - ETA: 2s - loss: 202.6933 - s_output_loss: 126.3017 - t_output_loss: 76.3916
49664/60000 [=======================>......] - ETA: 2s - loss: 202.6615 - s_output_loss: 126.2817 - t_output_loss: 76.3799
49920/60000 [=======================>......] - ETA: 2s - loss: 202.6149 - s_output_loss: 126.2493 - t_output_loss: 76.3656
50304/60000 [========================>.....] - ETA: 1s - loss: 202.6281 - s_output_loss: 126.2651 - t_output_loss: 76.3630
50560/60000 [========================>.....] - ETA: 1s - loss: 202.6056 - s_output_loss: 126.2528 - t_output_loss: 76.3528
50816/60000 [========================>.....] - ETA: 1s - loss: 202.5425 - s_output_loss: 126.2123 - t_output_loss: 76.3302
51200/60000 [========================>.....] - ETA: 1s - loss: 202.4978 - s_output_loss: 126.1887 - t_output_loss: 76.3091
51456/60000 [========================>.....] - ETA: 1s - loss: 202.4889 - s_output_loss: 126.1867 - t_output_loss: 76.3022
51840/60000 [========================>.....] - ETA: 1s - loss: 202.4242 - s_output_loss: 126.1447 - t_output_loss: 76.2796
52096/60000 [=========================>....] - ETA: 1s - loss: 202.3771 - s_output_loss: 126.1206 - t_output_loss: 76.2566
52352/60000 [=========================>....] - ETA: 1s - loss: 202.3544 - s_output_loss: 126.1008 - t_output_loss: 76.2536
52736/60000 [=========================>....] - ETA: 1s - loss: 202.3551 - s_output_loss: 126.1050 - t_output_loss: 76.2501
52992/60000 [=========================>....] - ETA: 1s - loss: 202.3139 - s_output_loss: 126.0802 - t_output_loss: 76.2337
53248/60000 [=========================>....] - ETA: 1s - loss: 202.2853 - s_output_loss: 126.0507 - t_output_loss: 76.2346
53632/60000 [=========================>....] - ETA: 1s - loss: 202.2586 - s_output_loss: 126.0284 - t_output_loss: 76.2302
53888/60000 [=========================>....] - ETA: 1s - loss: 202.2365 - s_output_loss: 126.0106 - t_output_loss: 76.2258
54144/60000 [==========================>...] - ETA: 1s - loss: 202.2309 - s_output_loss: 126.0099 - t_output_loss: 76.2210
54528/60000 [==========================>...] - ETA: 1s - loss: 202.1713 - s_output_loss: 125.9740 - t_output_loss: 76.1973
54784/60000 [==========================>...] - ETA: 1s - loss: 202.1268 - s_output_loss: 125.9554 - t_output_loss: 76.1714
55168/60000 [==========================>...] - ETA: 0s - loss: 202.0978 - s_output_loss: 125.9527 - t_output_loss: 76.1450
55424/60000 [==========================>...] - ETA: 0s - loss: 202.0627 - s_output_loss: 125.9410 - t_output_loss: 76.1216
55680/60000 [==========================>...] - ETA: 0s - loss: 202.0119 - s_output_loss: 125.9179 - t_output_loss: 76.0939
55936/60000 [==========================>...] - ETA: 0s - loss: 201.9384 - s_output_loss: 125.8794 - t_output_loss: 76.0591
56192/60000 [===========================>..] - ETA: 0s - loss: 201.9276 - s_output_loss: 125.8747 - t_output_loss: 76.0529
56448/60000 [===========================>..] - ETA: 0s - loss: 201.8976 - s_output_loss: 125.8639 - t_output_loss: 76.0337
56832/60000 [===========================>..] - ETA: 0s - loss: 201.9300 - s_output_loss: 125.9224 - t_output_loss: 76.0076
57088/60000 [===========================>..] - ETA: 0s - loss: 202.0422 - s_output_loss: 126.0471 - t_output_loss: 75.9952
57344/60000 [===========================>..] - ETA: 0s - loss: 202.2011 - s_output_loss: 126.1928 - t_output_loss: 76.0083
57600/60000 [===========================>..] - ETA: 0s - loss: 202.2732 - s_output_loss: 126.2498 - t_output_loss: 76.0234
57984/60000 [===========================>..] - ETA: 0s - loss: 202.4506 - s_output_loss: 126.4146 - t_output_loss: 76.0361
58368/60000 [============================>.] - ETA: 0s - loss: 202.7480 - s_output_loss: 126.6976 - t_output_loss: 76.0504
58624/60000 [============================>.] - ETA: 0s - loss: 202.9218 - s_output_loss: 126.8501 - t_output_loss: 76.0716
58880/60000 [============================>.] - ETA: 0s - loss: 203.0484 - s_output_loss: 126.9604 - t_output_loss: 76.0880
59136/60000 [============================>.] - ETA: 0s - loss: 203.1223 - s_output_loss: 127.0465 - t_output_loss: 76.0757
59392/60000 [============================>.] - ETA: 0s - loss: 203.2243 - s_output_loss: 127.1505 - t_output_loss: 76.0738
59648/60000 [============================>.] - ETA: 0s - loss: 203.2938 - s_output_loss: 127.2310 - t_output_loss: 76.0628
59904/60000 [============================>.] - ETA: 0s - loss: 203.3638 - s_output_loss: 127.3038 - t_output_loss: 76.0600
60000/60000 [==============================] - 13s 215us/step - loss: 203.3892 - s_output_loss: 127.3292 - t_output_loss: 76.0600 - val_loss: 218.0741 - val_s_output_loss: 139.7397 - val_t_output_loss: 78.3344
Epoch 9/10

  128/60000 [..............................] - ETA: 16s - loss: 215.8630 - s_output_loss: 142.7409 - t_output_loss: 73.1221
  384/60000 [..............................] - ETA: 14s - loss: 215.1768 - s_output_loss: 140.6245 - t_output_loss: 74.5523
  640/60000 [..............................] - ETA: 14s - loss: 215.4296 - s_output_loss: 139.1254 - t_output_loss: 76.3042
  896/60000 [..............................] - ETA: 14s - loss: 215.2489 - s_output_loss: 139.2340 - t_output_loss: 76.0150
 1152/60000 [..............................] - ETA: 13s - loss: 214.1387 - s_output_loss: 138.5499 - t_output_loss: 75.5888
 1408/60000 [..............................] - ETA: 13s - loss: 213.7131 - s_output_loss: 138.1563 - t_output_loss: 75.5568
 1664/60000 [..............................] - ETA: 13s - loss: 212.8263 - s_output_loss: 137.4570 - t_output_loss: 75.3693
 1920/60000 [..............................] - ETA: 12s - loss: 210.9693 - s_output_loss: 135.9778 - t_output_loss: 74.9915
 2176/60000 [>.............................] - ETA: 12s - loss: 210.3890 - s_output_loss: 135.6375 - t_output_loss: 74.7516
 2432/60000 [>.............................] - ETA: 12s - loss: 210.1487 - s_output_loss: 135.4638 - t_output_loss: 74.6848
 2688/60000 [>.............................] - ETA: 12s - loss: 209.4633 - s_output_loss: 134.9395 - t_output_loss: 74.5238
 2944/60000 [>.............................] - ETA: 12s - loss: 209.0468 - s_output_loss: 134.5810 - t_output_loss: 74.4657
 3200/60000 [>.............................] - ETA: 12s - loss: 208.7124 - s_output_loss: 134.3035 - t_output_loss: 74.4089
 3456/60000 [>.............................] - ETA: 12s - loss: 207.9416 - s_output_loss: 133.6842 - t_output_loss: 74.2574
 3712/60000 [>.............................] - ETA: 12s - loss: 207.1768 - s_output_loss: 133.1367 - t_output_loss: 74.0401
 3968/60000 [>.............................] - ETA: 11s - loss: 207.2120 - s_output_loss: 133.0182 - t_output_loss: 74.1938
 4224/60000 [=>............................] - ETA: 11s - loss: 207.4891 - s_output_loss: 133.2817 - t_output_loss: 74.2074
 4480/60000 [=>............................] - ETA: 11s - loss: 207.9927 - s_output_loss: 133.7736 - t_output_loss: 74.2192
 4736/60000 [=>............................] - ETA: 11s - loss: 208.5165 - s_output_loss: 134.2220 - t_output_loss: 74.2946
 5120/60000 [=>............................] - ETA: 11s - loss: 208.9003 - s_output_loss: 134.7658 - t_output_loss: 74.1345
 5376/60000 [=>............................] - ETA: 11s - loss: 209.3598 - s_output_loss: 135.1648 - t_output_loss: 74.1949
 5632/60000 [=>............................] - ETA: 11s - loss: 209.2698 - s_output_loss: 135.1915 - t_output_loss: 74.0783
 5888/60000 [=>............................] - ETA: 11s - loss: 209.5969 - s_output_loss: 135.2254 - t_output_loss: 74.3716
 6144/60000 [==>...........................] - ETA: 11s - loss: 209.7437 - s_output_loss: 135.0832 - t_output_loss: 74.6605
 6400/60000 [==>...........................] - ETA: 11s - loss: 209.9902 - s_output_loss: 135.0513 - t_output_loss: 74.9389
 6656/60000 [==>...........................] - ETA: 11s - loss: 210.2844 - s_output_loss: 135.2711 - t_output_loss: 75.0132
 6912/60000 [==>...........................] - ETA: 11s - loss: 211.8318 - s_output_loss: 136.7146 - t_output_loss: 75.1172
 7168/60000 [==>...........................] - ETA: 11s - loss: 213.3929 - s_output_loss: 138.0991 - t_output_loss: 75.2938
 7552/60000 [==>...........................] - ETA: 11s - loss: 214.7062 - s_output_loss: 139.2987 - t_output_loss: 75.4075
 7808/60000 [==>...........................] - ETA: 11s - loss: 215.5884 - s_output_loss: 140.1435 - t_output_loss: 75.4449
 8064/60000 [===>..........................] - ETA: 11s - loss: 216.3190 - s_output_loss: 140.9059 - t_output_loss: 75.4131
 8320/60000 [===>..........................] - ETA: 10s - loss: 217.1757 - s_output_loss: 141.6793 - t_output_loss: 75.4964
 8704/60000 [===>..........................] - ETA: 10s - loss: 217.6208 - s_output_loss: 142.2930 - t_output_loss: 75.3279
 9088/60000 [===>..........................] - ETA: 10s - loss: 218.5355 - s_output_loss: 143.3223 - t_output_loss: 75.2132
 9472/60000 [===>..........................] - ETA: 10s - loss: 220.0952 - s_output_loss: 144.9037 - t_output_loss: 75.1915
 9728/60000 [===>..........................] - ETA: 10s - loss: 220.9941 - s_output_loss: 145.8353 - t_output_loss: 75.1588
 9984/60000 [===>..........................] - ETA: 10s - loss: 221.6564 - s_output_loss: 146.5210 - t_output_loss: 75.1354
10240/60000 [====>.........................] - ETA: 10s - loss: 222.2249 - s_output_loss: 147.0959 - t_output_loss: 75.1290
10496/60000 [====>.........................] - ETA: 10s - loss: 222.7078 - s_output_loss: 147.5928 - t_output_loss: 75.1149
10752/60000 [====>.........................] - ETA: 10s - loss: 222.9752 - s_output_loss: 147.9488 - t_output_loss: 75.0263
11008/60000 [====>.........................] - ETA: 10s - loss: 223.0405 - s_output_loss: 148.1126 - t_output_loss: 74.9279
11264/60000 [====>.........................] - ETA: 10s - loss: 223.0397 - s_output_loss: 148.1814 - t_output_loss: 74.8583
11520/60000 [====>.........................] - ETA: 10s - loss: 223.1872 - s_output_loss: 148.3046 - t_output_loss: 74.8826
11776/60000 [====>.........................] - ETA: 10s - loss: 223.2839 - s_output_loss: 148.2677 - t_output_loss: 75.0163
12032/60000 [=====>........................] - ETA: 10s - loss: 223.3586 - s_output_loss: 148.2344 - t_output_loss: 75.1242
12288/60000 [=====>........................] - ETA: 10s - loss: 223.2750 - s_output_loss: 148.0881 - t_output_loss: 75.1869
12544/60000 [=====>........................] - ETA: 9s - loss: 223.4195 - s_output_loss: 148.0742 - t_output_loss: 75.3453 
12928/60000 [=====>........................] - ETA: 9s - loss: 223.5206 - s_output_loss: 147.9644 - t_output_loss: 75.5563
13184/60000 [=====>........................] - ETA: 9s - loss: 223.5039 - s_output_loss: 147.8267 - t_output_loss: 75.6772
13568/60000 [=====>........................] - ETA: 9s - loss: 223.3629 - s_output_loss: 147.6281 - t_output_loss: 75.7348
13824/60000 [=====>........................] - ETA: 9s - loss: 223.6768 - s_output_loss: 147.9018 - t_output_loss: 75.7750
14080/60000 [======>.......................] - ETA: 9s - loss: 224.0177 - s_output_loss: 148.2590 - t_output_loss: 75.7587
14336/60000 [======>.......................] - ETA: 9s - loss: 224.4584 - s_output_loss: 148.7059 - t_output_loss: 75.7526
14592/60000 [======>.......................] - ETA: 9s - loss: 224.8305 - s_output_loss: 149.0947 - t_output_loss: 75.7358
14848/60000 [======>.......................] - ETA: 9s - loss: 225.2310 - s_output_loss: 149.5244 - t_output_loss: 75.7067
15232/60000 [======>.......................] - ETA: 9s - loss: 225.8949 - s_output_loss: 150.2107 - t_output_loss: 75.6842
15616/60000 [======>.......................] - ETA: 9s - loss: 226.4497 - s_output_loss: 150.6993 - t_output_loss: 75.7504
15872/60000 [======>.......................] - ETA: 9s - loss: 226.7801 - s_output_loss: 150.9544 - t_output_loss: 75.8258
16128/60000 [=======>......................] - ETA: 9s - loss: 227.0640 - s_output_loss: 151.1481 - t_output_loss: 75.9158
16512/60000 [=======>......................] - ETA: 9s - loss: 227.3457 - s_output_loss: 151.3388 - t_output_loss: 76.0069
16768/60000 [=======>......................] - ETA: 9s - loss: 227.4068 - s_output_loss: 151.4222 - t_output_loss: 75.9846
17024/60000 [=======>......................] - ETA: 8s - loss: 227.3683 - s_output_loss: 151.4026 - t_output_loss: 75.9657
17280/60000 [=======>......................] - ETA: 8s - loss: 227.3322 - s_output_loss: 151.3641 - t_output_loss: 75.9680
17536/60000 [=======>......................] - ETA: 8s - loss: 227.2782 - s_output_loss: 151.3232 - t_output_loss: 75.9550
17792/60000 [=======>......................] - ETA: 8s - loss: 227.2620 - s_output_loss: 151.2937 - t_output_loss: 75.9683
18048/60000 [========>.....................] - ETA: 8s - loss: 227.1390 - s_output_loss: 151.2033 - t_output_loss: 75.9357
18304/60000 [========>.....................] - ETA: 8s - loss: 227.0104 - s_output_loss: 151.1046 - t_output_loss: 75.9058
18560/60000 [========>.....................] - ETA: 8s - loss: 226.8287 - s_output_loss: 150.9401 - t_output_loss: 75.8887
18816/60000 [========>.....................] - ETA: 8s - loss: 226.6740 - s_output_loss: 150.8146 - t_output_loss: 75.8594
19200/60000 [========>.....................] - ETA: 8s - loss: 226.4246 - s_output_loss: 150.6356 - t_output_loss: 75.7890
19456/60000 [========>.....................] - ETA: 8s - loss: 226.3030 - s_output_loss: 150.5205 - t_output_loss: 75.7826
19712/60000 [========>.....................] - ETA: 8s - loss: 226.1718 - s_output_loss: 150.3873 - t_output_loss: 75.7846
20096/60000 [=========>....................] - ETA: 8s - loss: 225.8911 - s_output_loss: 150.1579 - t_output_loss: 75.7332
20352/60000 [=========>....................] - ETA: 8s - loss: 225.7959 - s_output_loss: 150.0497 - t_output_loss: 75.7462
20608/60000 [=========>....................] - ETA: 8s - loss: 225.5928 - s_output_loss: 149.9034 - t_output_loss: 75.6894
20864/60000 [=========>....................] - ETA: 8s - loss: 225.4957 - s_output_loss: 149.8475 - t_output_loss: 75.6481
21248/60000 [=========>....................] - ETA: 8s - loss: 225.3848 - s_output_loss: 149.7676 - t_output_loss: 75.6173
21504/60000 [=========>....................] - ETA: 8s - loss: 225.2200 - s_output_loss: 149.6680 - t_output_loss: 75.5520
21760/60000 [=========>....................] - ETA: 7s - loss: 225.1867 - s_output_loss: 149.6263 - t_output_loss: 75.5604
22144/60000 [==========>...................] - ETA: 7s - loss: 225.0358 - s_output_loss: 149.5239 - t_output_loss: 75.5119
22528/60000 [==========>...................] - ETA: 7s - loss: 224.8373 - s_output_loss: 149.3773 - t_output_loss: 75.4599
22912/60000 [==========>...................] - ETA: 7s - loss: 224.5426 - s_output_loss: 149.1559 - t_output_loss: 75.3867
23168/60000 [==========>...................] - ETA: 7s - loss: 224.3516 - s_output_loss: 149.0168 - t_output_loss: 75.3349
23552/60000 [==========>...................] - ETA: 7s - loss: 224.0707 - s_output_loss: 148.7824 - t_output_loss: 75.2884
23808/60000 [==========>...................] - ETA: 7s - loss: 223.9365 - s_output_loss: 148.6543 - t_output_loss: 75.2822
24064/60000 [===========>..................] - ETA: 7s - loss: 223.7880 - s_output_loss: 148.5211 - t_output_loss: 75.2669
24448/60000 [===========>..................] - ETA: 7s - loss: 223.5587 - s_output_loss: 148.3288 - t_output_loss: 75.2299
24704/60000 [===========>..................] - ETA: 7s - loss: 223.3351 - s_output_loss: 148.1538 - t_output_loss: 75.1813
24960/60000 [===========>..................] - ETA: 7s - loss: 223.1780 - s_output_loss: 147.9949 - t_output_loss: 75.1831
25216/60000 [===========>..................] - ETA: 7s - loss: 223.0005 - s_output_loss: 147.8594 - t_output_loss: 75.1411
25472/60000 [===========>..................] - ETA: 7s - loss: 222.8548 - s_output_loss: 147.7381 - t_output_loss: 75.1167
25728/60000 [===========>..................] - ETA: 7s - loss: 222.7173 - s_output_loss: 147.6317 - t_output_loss: 75.0856
26112/60000 [============>.................] - ETA: 6s - loss: 222.5957 - s_output_loss: 147.5226 - t_output_loss: 75.0731
26368/60000 [============>.................] - ETA: 6s - loss: 222.4182 - s_output_loss: 147.3945 - t_output_loss: 75.0237
26752/60000 [============>.................] - ETA: 6s - loss: 222.1952 - s_output_loss: 147.1964 - t_output_loss: 74.9988
27008/60000 [============>.................] - ETA: 6s - loss: 221.9944 - s_output_loss: 147.0676 - t_output_loss: 74.9268
27264/60000 [============>.................] - ETA: 6s - loss: 221.8423 - s_output_loss: 146.9465 - t_output_loss: 74.8958
27648/60000 [============>.................] - ETA: 6s - loss: 221.5391 - s_output_loss: 146.7000 - t_output_loss: 74.8391
27904/60000 [============>.................] - ETA: 6s - loss: 221.3860 - s_output_loss: 146.5775 - t_output_loss: 74.8084
28288/60000 [=============>................] - ETA: 6s - loss: 221.2154 - s_output_loss: 146.4210 - t_output_loss: 74.7944
28544/60000 [=============>................] - ETA: 6s - loss: 221.0635 - s_output_loss: 146.2875 - t_output_loss: 74.7760
28800/60000 [=============>................] - ETA: 6s - loss: 220.8874 - s_output_loss: 146.1444 - t_output_loss: 74.7429
29056/60000 [=============>................] - ETA: 6s - loss: 220.7357 - s_output_loss: 146.0114 - t_output_loss: 74.7243
29312/60000 [=============>................] - ETA: 6s - loss: 220.5606 - s_output_loss: 145.8684 - t_output_loss: 74.6923
29568/60000 [=============>................] - ETA: 6s - loss: 220.4148 - s_output_loss: 145.7416 - t_output_loss: 74.6731
29824/60000 [=============>................] - ETA: 6s - loss: 220.2618 - s_output_loss: 145.6092 - t_output_loss: 74.6526
30080/60000 [==============>...............] - ETA: 6s - loss: 220.1238 - s_output_loss: 145.4934 - t_output_loss: 74.6304
30336/60000 [==============>...............] - ETA: 6s - loss: 219.9851 - s_output_loss: 145.3745 - t_output_loss: 74.6106
30720/60000 [==============>...............] - ETA: 6s - loss: 219.7714 - s_output_loss: 145.1928 - t_output_loss: 74.5787
30976/60000 [==============>...............] - ETA: 5s - loss: 219.6434 - s_output_loss: 145.0733 - t_output_loss: 74.5700
31360/60000 [==============>...............] - ETA: 5s - loss: 219.4928 - s_output_loss: 144.9117 - t_output_loss: 74.5811
31616/60000 [==============>...............] - ETA: 5s - loss: 219.3539 - s_output_loss: 144.7780 - t_output_loss: 74.5759
31872/60000 [==============>...............] - ETA: 5s - loss: 219.2239 - s_output_loss: 144.6542 - t_output_loss: 74.5697
32128/60000 [===============>..............] - ETA: 5s - loss: 219.1118 - s_output_loss: 144.5528 - t_output_loss: 74.5590
32384/60000 [===============>..............] - ETA: 5s - loss: 219.0165 - s_output_loss: 144.4692 - t_output_loss: 74.5474
32640/60000 [===============>..............] - ETA: 5s - loss: 218.8581 - s_output_loss: 144.3436 - t_output_loss: 74.5145
32896/60000 [===============>..............] - ETA: 5s - loss: 218.7082 - s_output_loss: 144.2323 - t_output_loss: 74.4759
33152/60000 [===============>..............] - ETA: 5s - loss: 218.5940 - s_output_loss: 144.1260 - t_output_loss: 74.4679
33408/60000 [===============>..............] - ETA: 5s - loss: 218.4911 - s_output_loss: 144.0489 - t_output_loss: 74.4422
33664/60000 [===============>..............] - ETA: 5s - loss: 218.3293 - s_output_loss: 143.9283 - t_output_loss: 74.4010
33920/60000 [===============>..............] - ETA: 5s - loss: 218.1834 - s_output_loss: 143.8051 - t_output_loss: 74.3783
34304/60000 [================>.............] - ETA: 5s - loss: 218.0338 - s_output_loss: 143.6190 - t_output_loss: 74.4149
34560/60000 [================>.............] - ETA: 5s - loss: 217.9994 - s_output_loss: 143.5133 - t_output_loss: 74.4861
34816/60000 [================>.............] - ETA: 5s - loss: 217.9438 - s_output_loss: 143.3909 - t_output_loss: 74.5529
35200/60000 [================>.............] - ETA: 5s - loss: 217.8992 - s_output_loss: 143.2519 - t_output_loss: 74.6473
35456/60000 [================>.............] - ETA: 5s - loss: 217.8493 - s_output_loss: 143.1351 - t_output_loss: 74.7142
35712/60000 [================>.............] - ETA: 4s - loss: 217.8223 - s_output_loss: 143.0480 - t_output_loss: 74.7743
35968/60000 [================>.............] - ETA: 4s - loss: 217.7253 - s_output_loss: 142.9235 - t_output_loss: 74.8017
36224/60000 [=================>............] - ETA: 4s - loss: 217.6283 - s_output_loss: 142.8020 - t_output_loss: 74.8263
36480/60000 [=================>............] - ETA: 4s - loss: 217.5484 - s_output_loss: 142.6971 - t_output_loss: 74.8513
36736/60000 [=================>............] - ETA: 4s - loss: 217.5225 - s_output_loss: 142.6167 - t_output_loss: 74.9058
37120/60000 [=================>............] - ETA: 4s - loss: 217.4201 - s_output_loss: 142.4683 - t_output_loss: 74.9518
37504/60000 [=================>............] - ETA: 4s - loss: 217.3800 - s_output_loss: 142.3760 - t_output_loss: 75.0040
37760/60000 [=================>............] - ETA: 4s - loss: 217.2973 - s_output_loss: 142.2802 - t_output_loss: 75.0172
38016/60000 [==================>...........] - ETA: 4s - loss: 217.2656 - s_output_loss: 142.2396 - t_output_loss: 75.0260
38272/60000 [==================>...........] - ETA: 4s - loss: 217.3152 - s_output_loss: 142.2699 - t_output_loss: 75.0453
38528/60000 [==================>...........] - ETA: 4s - loss: 217.3268 - s_output_loss: 142.2856 - t_output_loss: 75.0412
38912/60000 [==================>...........] - ETA: 4s - loss: 217.3500 - s_output_loss: 142.3153 - t_output_loss: 75.0347
39168/60000 [==================>...........] - ETA: 4s - loss: 217.3319 - s_output_loss: 142.3045 - t_output_loss: 75.0274
39424/60000 [==================>...........] - ETA: 4s - loss: 217.3553 - s_output_loss: 142.3173 - t_output_loss: 75.0380
39680/60000 [==================>...........] - ETA: 4s - loss: 217.3517 - s_output_loss: 142.3224 - t_output_loss: 75.0294
39936/60000 [==================>...........] - ETA: 4s - loss: 217.3293 - s_output_loss: 142.3146 - t_output_loss: 75.0147
40192/60000 [===================>..........] - ETA: 4s - loss: 217.3033 - s_output_loss: 142.3085 - t_output_loss: 74.9949
40448/60000 [===================>..........] - ETA: 4s - loss: 217.2739 - s_output_loss: 142.2937 - t_output_loss: 74.9802
40704/60000 [===================>..........] - ETA: 3s - loss: 217.2344 - s_output_loss: 142.2642 - t_output_loss: 74.9702
40960/60000 [===================>..........] - ETA: 3s - loss: 217.2120 - s_output_loss: 142.2497 - t_output_loss: 74.9623
41216/60000 [===================>..........] - ETA: 3s - loss: 217.1800 - s_output_loss: 142.2227 - t_output_loss: 74.9573
41600/60000 [===================>..........] - ETA: 3s - loss: 217.1124 - s_output_loss: 142.1711 - t_output_loss: 74.9412
41856/60000 [===================>..........] - ETA: 3s - loss: 217.0354 - s_output_loss: 142.1044 - t_output_loss: 74.9310
42112/60000 [====================>.........] - ETA: 3s - loss: 217.0025 - s_output_loss: 142.0677 - t_output_loss: 74.9347
42368/60000 [====================>.........] - ETA: 3s - loss: 216.9338 - s_output_loss: 142.0146 - t_output_loss: 74.9192
42624/60000 [====================>.........] - ETA: 3s - loss: 216.8820 - s_output_loss: 141.9695 - t_output_loss: 74.9125
42880/60000 [====================>.........] - ETA: 3s - loss: 216.8258 - s_output_loss: 141.9246 - t_output_loss: 74.9012
43136/60000 [====================>.........] - ETA: 3s - loss: 216.7743 - s_output_loss: 141.8755 - t_output_loss: 74.8988
43392/60000 [====================>.........] - ETA: 3s - loss: 216.6950 - s_output_loss: 141.8198 - t_output_loss: 74.8751
43776/60000 [====================>.........] - ETA: 3s - loss: 216.5641 - s_output_loss: 141.7279 - t_output_loss: 74.8362
44160/60000 [=====================>........] - ETA: 3s - loss: 216.4209 - s_output_loss: 141.6064 - t_output_loss: 74.8145
44544/60000 [=====================>........] - ETA: 3s - loss: 216.3173 - s_output_loss: 141.5140 - t_output_loss: 74.8033
44800/60000 [=====================>........] - ETA: 3s - loss: 216.2498 - s_output_loss: 141.4554 - t_output_loss: 74.7944
45184/60000 [=====================>........] - ETA: 3s - loss: 216.1617 - s_output_loss: 141.3734 - t_output_loss: 74.7883
45440/60000 [=====================>........] - ETA: 2s - loss: 216.1117 - s_output_loss: 141.3142 - t_output_loss: 74.7975
45696/60000 [=====================>........] - ETA: 2s - loss: 216.0118 - s_output_loss: 141.2280 - t_output_loss: 74.7838
45952/60000 [=====================>........] - ETA: 2s - loss: 215.9467 - s_output_loss: 141.1504 - t_output_loss: 74.7963
46336/60000 [======================>.......] - ETA: 2s - loss: 215.7775 - s_output_loss: 141.0137 - t_output_loss: 74.7638
46592/60000 [======================>.......] - ETA: 2s - loss: 215.6958 - s_output_loss: 140.9438 - t_output_loss: 74.7520
46848/60000 [======================>.......] - ETA: 2s - loss: 215.5804 - s_output_loss: 140.8587 - t_output_loss: 74.7217
47104/60000 [======================>.......] - ETA: 2s - loss: 215.4755 - s_output_loss: 140.7807 - t_output_loss: 74.6948
47360/60000 [======================>.......] - ETA: 2s - loss: 215.3892 - s_output_loss: 140.7037 - t_output_loss: 74.6855
47616/60000 [======================>.......] - ETA: 2s - loss: 215.2998 - s_output_loss: 140.6291 - t_output_loss: 74.6707
47872/60000 [======================>.......] - ETA: 2s - loss: 215.2015 - s_output_loss: 140.5493 - t_output_loss: 74.6521
48128/60000 [=======================>......] - ETA: 2s - loss: 215.1140 - s_output_loss: 140.4804 - t_output_loss: 74.6336
48512/60000 [=======================>......] - ETA: 2s - loss: 215.0137 - s_output_loss: 140.4076 - t_output_loss: 74.6061
48768/60000 [=======================>......] - ETA: 2s - loss: 214.9674 - s_output_loss: 140.3689 - t_output_loss: 74.5986
49024/60000 [=======================>......] - ETA: 2s - loss: 214.9008 - s_output_loss: 140.3154 - t_output_loss: 74.5853
49280/60000 [=======================>......] - ETA: 2s - loss: 214.7997 - s_output_loss: 140.2329 - t_output_loss: 74.5668
49536/60000 [=======================>......] - ETA: 2s - loss: 214.7355 - s_output_loss: 140.1732 - t_output_loss: 74.5623
49792/60000 [=======================>......] - ETA: 2s - loss: 214.6324 - s_output_loss: 140.0995 - t_output_loss: 74.5330
50176/60000 [========================>.....] - ETA: 2s - loss: 214.5247 - s_output_loss: 140.0077 - t_output_loss: 74.5170
50432/60000 [========================>.....] - ETA: 1s - loss: 214.4205 - s_output_loss: 139.9363 - t_output_loss: 74.4842
50816/60000 [========================>.....] - ETA: 1s - loss: 214.3163 - s_output_loss: 139.8494 - t_output_loss: 74.4669
51072/60000 [========================>.....] - ETA: 1s - loss: 214.2356 - s_output_loss: 139.7781 - t_output_loss: 74.4575
51328/60000 [========================>.....] - ETA: 1s - loss: 214.1786 - s_output_loss: 139.7263 - t_output_loss: 74.4524
51584/60000 [========================>.....] - ETA: 1s - loss: 214.1183 - s_output_loss: 139.6718 - t_output_loss: 74.4465
51840/60000 [========================>.....] - ETA: 1s - loss: 214.0297 - s_output_loss: 139.6006 - t_output_loss: 74.4292
52096/60000 [=========================>....] - ETA: 1s - loss: 213.9323 - s_output_loss: 139.5268 - t_output_loss: 74.4054
52352/60000 [=========================>....] - ETA: 1s - loss: 213.8840 - s_output_loss: 139.4809 - t_output_loss: 74.4031
52608/60000 [=========================>....] - ETA: 1s - loss: 213.8464 - s_output_loss: 139.4350 - t_output_loss: 74.4113
52864/60000 [=========================>....] - ETA: 1s - loss: 213.7719 - s_output_loss: 139.3611 - t_output_loss: 74.4107
53120/60000 [=========================>....] - ETA: 1s - loss: 213.7163 - s_output_loss: 139.3090 - t_output_loss: 74.4073
53376/60000 [=========================>....] - ETA: 1s - loss: 213.6471 - s_output_loss: 139.2498 - t_output_loss: 74.3973
53632/60000 [=========================>....] - ETA: 1s - loss: 213.5701 - s_output_loss: 139.1774 - t_output_loss: 74.3927
53888/60000 [=========================>....] - ETA: 1s - loss: 213.5067 - s_output_loss: 139.1252 - t_output_loss: 74.3815
54144/60000 [==========================>...] - ETA: 1s - loss: 213.4498 - s_output_loss: 139.0699 - t_output_loss: 74.3800
54400/60000 [==========================>...] - ETA: 1s - loss: 213.3566 - s_output_loss: 138.9896 - t_output_loss: 74.3670
54656/60000 [==========================>...] - ETA: 1s - loss: 213.2894 - s_output_loss: 138.9282 - t_output_loss: 74.3612
54912/60000 [==========================>...] - ETA: 1s - loss: 213.2426 - s_output_loss: 138.8833 - t_output_loss: 74.3593
55168/60000 [==========================>...] - ETA: 0s - loss: 213.1826 - s_output_loss: 138.8272 - t_output_loss: 74.3554
55424/60000 [==========================>...] - ETA: 0s - loss: 213.1110 - s_output_loss: 138.7665 - t_output_loss: 74.3444
55808/60000 [==========================>...] - ETA: 0s - loss: 212.9459 - s_output_loss: 138.6397 - t_output_loss: 74.3062
56192/60000 [===========================>..] - ETA: 0s - loss: 212.8395 - s_output_loss: 138.5445 - t_output_loss: 74.2950
56576/60000 [===========================>..] - ETA: 0s - loss: 212.7653 - s_output_loss: 138.4803 - t_output_loss: 74.2849
56832/60000 [===========================>..] - ETA: 0s - loss: 212.6801 - s_output_loss: 138.4245 - t_output_loss: 74.2556
57216/60000 [===========================>..] - ETA: 0s - loss: 212.5838 - s_output_loss: 138.3544 - t_output_loss: 74.2295
57472/60000 [===========================>..] - ETA: 0s - loss: 212.5387 - s_output_loss: 138.3147 - t_output_loss: 74.2240
57728/60000 [===========================>..] - ETA: 0s - loss: 212.4511 - s_output_loss: 138.2517 - t_output_loss: 74.1994
58112/60000 [============================>.] - ETA: 0s - loss: 212.3422 - s_output_loss: 138.1713 - t_output_loss: 74.1709
58368/60000 [============================>.] - ETA: 0s - loss: 212.2721 - s_output_loss: 138.1201 - t_output_loss: 74.1519
58624/60000 [============================>.] - ETA: 0s - loss: 212.1760 - s_output_loss: 138.0466 - t_output_loss: 74.1293
58880/60000 [============================>.] - ETA: 0s - loss: 212.0936 - s_output_loss: 137.9920 - t_output_loss: 74.1016
59136/60000 [============================>.] - ETA: 0s - loss: 211.9888 - s_output_loss: 137.9189 - t_output_loss: 74.0699
59520/60000 [============================>.] - ETA: 0s - loss: 211.8715 - s_output_loss: 137.8291 - t_output_loss: 74.0425
59776/60000 [============================>.] - ETA: 0s - loss: 211.8138 - s_output_loss: 137.7791 - t_output_loss: 74.0347
60000/60000 [==============================] - 13s 215us/step - loss: 211.7459 - s_output_loss: 137.7259 - t_output_loss: 74.0199 - val_loss: 198.1702 - val_s_output_loss: 123.6722 - val_t_output_loss: 74.4980
Epoch 10/10

  128/60000 [..............................] - ETA: 15s - loss: 186.1476 - s_output_loss: 120.3025 - t_output_loss: 65.8451
  512/60000 [..............................] - ETA: 12s - loss: 195.6738 - s_output_loss: 125.5299 - t_output_loss: 70.1439
  768/60000 [..............................] - ETA: 12s - loss: 194.2904 - s_output_loss: 123.9827 - t_output_loss: 70.3077
 1024/60000 [..............................] - ETA: 12s - loss: 194.5205 - s_output_loss: 124.3698 - t_output_loss: 70.1507
 1280/60000 [..............................] - ETA: 12s - loss: 193.6200 - s_output_loss: 123.6686 - t_output_loss: 69.9514
 1664/60000 [..............................] - ETA: 11s - loss: 192.6352 - s_output_loss: 123.1718 - t_output_loss: 69.4635
 1920/60000 [..............................] - ETA: 11s - loss: 193.8330 - s_output_loss: 123.8311 - t_output_loss: 70.0019
 2304/60000 [>.............................] - ETA: 11s - loss: 195.1257 - s_output_loss: 125.0824 - t_output_loss: 70.0432
 2688/60000 [>.............................] - ETA: 11s - loss: 195.4502 - s_output_loss: 125.3868 - t_output_loss: 70.0633
 2944/60000 [>.............................] - ETA: 11s - loss: 195.9384 - s_output_loss: 125.8403 - t_output_loss: 70.0981
 3200/60000 [>.............................] - ETA: 11s - loss: 196.3319 - s_output_loss: 126.0995 - t_output_loss: 70.2324
 3584/60000 [>.............................] - ETA: 11s - loss: 197.0407 - s_output_loss: 126.8454 - t_output_loss: 70.1953
 3968/60000 [>.............................] - ETA: 11s - loss: 197.3305 - s_output_loss: 127.1690 - t_output_loss: 70.1616
 4224/60000 [=>............................] - ETA: 11s - loss: 197.8081 - s_output_loss: 127.5815 - t_output_loss: 70.2266
 4608/60000 [=>............................] - ETA: 10s - loss: 198.1121 - s_output_loss: 127.8601 - t_output_loss: 70.2520
 4864/60000 [=>............................] - ETA: 10s - loss: 198.1484 - s_output_loss: 127.9874 - t_output_loss: 70.1610
 5120/60000 [=>............................] - ETA: 10s - loss: 197.8450 - s_output_loss: 127.8613 - t_output_loss: 69.9838
 5376/60000 [=>............................] - ETA: 10s - loss: 197.7700 - s_output_loss: 127.7978 - t_output_loss: 69.9722
 5632/60000 [=>............................] - ETA: 10s - loss: 197.8296 - s_output_loss: 127.8381 - t_output_loss: 69.9915
 5888/60000 [=>............................] - ETA: 10s - loss: 197.6505 - s_output_loss: 127.6815 - t_output_loss: 69.9690
 6272/60000 [==>...........................] - ETA: 10s - loss: 197.4943 - s_output_loss: 127.6078 - t_output_loss: 69.8865
 6528/60000 [==>...........................] - ETA: 10s - loss: 197.4701 - s_output_loss: 127.5727 - t_output_loss: 69.8974
 6912/60000 [==>...........................] - ETA: 10s - loss: 197.6128 - s_output_loss: 127.6903 - t_output_loss: 69.9226
 7168/60000 [==>...........................] - ETA: 10s - loss: 197.6774 - s_output_loss: 127.6830 - t_output_loss: 69.9944
 7424/60000 [==>...........................] - ETA: 10s - loss: 197.4425 - s_output_loss: 127.4902 - t_output_loss: 69.9524
 7680/60000 [==>...........................] - ETA: 10s - loss: 197.5101 - s_output_loss: 127.4487 - t_output_loss: 70.0614
 7936/60000 [==>...........................] - ETA: 10s - loss: 197.4639 - s_output_loss: 127.2242 - t_output_loss: 70.2397
 8320/60000 [===>..........................] - ETA: 10s - loss: 198.1283 - s_output_loss: 127.1075 - t_output_loss: 71.0208
 8576/60000 [===>..........................] - ETA: 10s - loss: 198.5116 - s_output_loss: 127.0756 - t_output_loss: 71.4360
 8832/60000 [===>..........................] - ETA: 10s - loss: 198.5867 - s_output_loss: 126.9692 - t_output_loss: 71.6175
 9088/60000 [===>..........................] - ETA: 10s - loss: 198.8197 - s_output_loss: 126.9982 - t_output_loss: 71.8215
 9344/60000 [===>..........................] - ETA: 10s - loss: 199.1234 - s_output_loss: 127.0674 - t_output_loss: 72.0560
 9600/60000 [===>..........................] - ETA: 10s - loss: 199.4246 - s_output_loss: 127.2172 - t_output_loss: 72.2075
 9856/60000 [===>..........................] - ETA: 10s - loss: 199.5036 - s_output_loss: 127.2225 - t_output_loss: 72.2811
10112/60000 [====>.........................] - ETA: 10s - loss: 199.6495 - s_output_loss: 127.3334 - t_output_loss: 72.3161
10496/60000 [====>.........................] - ETA: 9s - loss: 199.7675 - s_output_loss: 127.4142 - t_output_loss: 72.3533 
10880/60000 [====>.........................] - ETA: 9s - loss: 199.7992 - s_output_loss: 127.4424 - t_output_loss: 72.3568
11264/60000 [====>.........................] - ETA: 9s - loss: 199.9484 - s_output_loss: 127.5570 - t_output_loss: 72.3914
11520/60000 [====>.........................] - ETA: 9s - loss: 200.0011 - s_output_loss: 127.6210 - t_output_loss: 72.3801
11904/60000 [====>.........................] - ETA: 9s - loss: 200.0069 - s_output_loss: 127.6141 - t_output_loss: 72.3927
12288/60000 [=====>........................] - ETA: 9s - loss: 200.0809 - s_output_loss: 127.6402 - t_output_loss: 72.4407
12544/60000 [=====>........................] - ETA: 9s - loss: 200.0317 - s_output_loss: 127.6031 - t_output_loss: 72.4286
12800/60000 [=====>........................] - ETA: 9s - loss: 200.0114 - s_output_loss: 127.5932 - t_output_loss: 72.4182
13056/60000 [=====>........................] - ETA: 9s - loss: 199.9969 - s_output_loss: 127.5787 - t_output_loss: 72.4182
13312/60000 [=====>........................] - ETA: 9s - loss: 199.8939 - s_output_loss: 127.5303 - t_output_loss: 72.3636
13568/60000 [=====>........................] - ETA: 9s - loss: 199.8115 - s_output_loss: 127.4784 - t_output_loss: 72.3331
13824/60000 [=====>........................] - ETA: 9s - loss: 199.7853 - s_output_loss: 127.4764 - t_output_loss: 72.3089
14080/60000 [======>.......................] - ETA: 9s - loss: 199.7760 - s_output_loss: 127.4934 - t_output_loss: 72.2826
14464/60000 [======>.......................] - ETA: 9s - loss: 199.7560 - s_output_loss: 127.4696 - t_output_loss: 72.2864
14720/60000 [======>.......................] - ETA: 9s - loss: 199.7675 - s_output_loss: 127.4928 - t_output_loss: 72.2747
14976/60000 [======>.......................] - ETA: 9s - loss: 199.5728 - s_output_loss: 127.3710 - t_output_loss: 72.2018
15232/60000 [======>.......................] - ETA: 9s - loss: 199.5427 - s_output_loss: 127.3589 - t_output_loss: 72.1838
15488/60000 [======>.......................] - ETA: 8s - loss: 199.4222 - s_output_loss: 127.2906 - t_output_loss: 72.1316
15744/60000 [======>.......................] - ETA: 8s - loss: 199.3115 - s_output_loss: 127.2255 - t_output_loss: 72.0859
16000/60000 [=======>......................] - ETA: 8s - loss: 199.1981 - s_output_loss: 127.1463 - t_output_loss: 72.0518
16256/60000 [=======>......................] - ETA: 8s - loss: 199.0105 - s_output_loss: 127.0371 - t_output_loss: 71.9734
16640/60000 [=======>......................] - ETA: 8s - loss: 198.8692 - s_output_loss: 126.9776 - t_output_loss: 71.8916
16896/60000 [=======>......................] - ETA: 8s - loss: 198.8386 - s_output_loss: 126.9530 - t_output_loss: 71.8856
17152/60000 [=======>......................] - ETA: 8s - loss: 198.7477 - s_output_loss: 126.8868 - t_output_loss: 71.8608
17408/60000 [=======>......................] - ETA: 8s - loss: 198.7691 - s_output_loss: 126.9424 - t_output_loss: 71.8266
17664/60000 [=======>......................] - ETA: 8s - loss: 198.7134 - s_output_loss: 126.9298 - t_output_loss: 71.7835
17920/60000 [=======>......................] - ETA: 8s - loss: 198.6703 - s_output_loss: 126.9207 - t_output_loss: 71.7496
18304/60000 [========>.....................] - ETA: 8s - loss: 198.6640 - s_output_loss: 126.9409 - t_output_loss: 71.7231
18688/60000 [========>.....................] - ETA: 8s - loss: 198.5695 - s_output_loss: 126.9185 - t_output_loss: 71.6510
19072/60000 [========>.....................] - ETA: 8s - loss: 198.5107 - s_output_loss: 126.9005 - t_output_loss: 71.6101
19328/60000 [========>.....................] - ETA: 8s - loss: 198.4772 - s_output_loss: 126.8945 - t_output_loss: 71.5827
19584/60000 [========>.....................] - ETA: 8s - loss: 198.4033 - s_output_loss: 126.8690 - t_output_loss: 71.5343
19840/60000 [========>.....................] - ETA: 8s - loss: 198.3369 - s_output_loss: 126.8308 - t_output_loss: 71.5062
20096/60000 [=========>....................] - ETA: 8s - loss: 198.2434 - s_output_loss: 126.7624 - t_output_loss: 71.4810
20352/60000 [=========>....................] - ETA: 7s - loss: 198.1682 - s_output_loss: 126.7156 - t_output_loss: 71.4526
20608/60000 [=========>....................] - ETA: 7s - loss: 198.1622 - s_output_loss: 126.7013 - t_output_loss: 71.4609
20864/60000 [=========>....................] - ETA: 7s - loss: 198.1590 - s_output_loss: 126.6906 - t_output_loss: 71.4684
21120/60000 [=========>....................] - ETA: 7s - loss: 198.0287 - s_output_loss: 126.6101 - t_output_loss: 71.4186
21504/60000 [=========>....................] - ETA: 7s - loss: 197.9392 - s_output_loss: 126.5376 - t_output_loss: 71.4016
21760/60000 [=========>....................] - ETA: 7s - loss: 197.8589 - s_output_loss: 126.4900 - t_output_loss: 71.3689
22144/60000 [==========>...................] - ETA: 7s - loss: 197.7686 - s_output_loss: 126.4457 - t_output_loss: 71.3230
22400/60000 [==========>...................] - ETA: 7s - loss: 197.6926 - s_output_loss: 126.4124 - t_output_loss: 71.2802
22656/60000 [==========>...................] - ETA: 7s - loss: 197.5947 - s_output_loss: 126.3484 - t_output_loss: 71.2463
22912/60000 [==========>...................] - ETA: 7s - loss: 197.5372 - s_output_loss: 126.3106 - t_output_loss: 71.2266
23168/60000 [==========>...................] - ETA: 7s - loss: 197.5150 - s_output_loss: 126.3245 - t_output_loss: 71.1905
23424/60000 [==========>...................] - ETA: 7s - loss: 197.4162 - s_output_loss: 126.2553 - t_output_loss: 71.1609
23808/60000 [==========>...................] - ETA: 7s - loss: 197.3775 - s_output_loss: 126.2129 - t_output_loss: 71.1647
24064/60000 [===========>..................] - ETA: 7s - loss: 197.2373 - s_output_loss: 126.1174 - t_output_loss: 71.1199
24448/60000 [===========>..................] - ETA: 7s - loss: 197.1646 - s_output_loss: 126.0786 - t_output_loss: 71.0860
24704/60000 [===========>..................] - ETA: 7s - loss: 197.1377 - s_output_loss: 126.0687 - t_output_loss: 71.0690
24960/60000 [===========>..................] - ETA: 7s - loss: 197.1356 - s_output_loss: 126.0507 - t_output_loss: 71.0850
25216/60000 [===========>..................] - ETA: 7s - loss: 197.0794 - s_output_loss: 126.0222 - t_output_loss: 71.0572
25472/60000 [===========>..................] - ETA: 6s - loss: 197.0285 - s_output_loss: 125.9793 - t_output_loss: 71.0492
25728/60000 [===========>..................] - ETA: 6s - loss: 196.9650 - s_output_loss: 125.9341 - t_output_loss: 71.0310
25984/60000 [===========>..................] - ETA: 6s - loss: 196.9261 - s_output_loss: 125.8956 - t_output_loss: 71.0306
26240/60000 [============>.................] - ETA: 6s - loss: 196.9017 - s_output_loss: 125.8860 - t_output_loss: 71.0157
26496/60000 [============>.................] - ETA: 6s - loss: 197.0723 - s_output_loss: 126.0424 - t_output_loss: 71.0299
26752/60000 [============>.................] - ETA: 6s - loss: 197.1655 - s_output_loss: 126.1363 - t_output_loss: 71.0292
27008/60000 [============>.................] - ETA: 6s - loss: 197.2758 - s_output_loss: 126.2609 - t_output_loss: 71.0148
27392/60000 [============>.................] - ETA: 6s - loss: 197.4881 - s_output_loss: 126.4920 - t_output_loss: 70.9961
27776/60000 [============>.................] - ETA: 6s - loss: 197.6912 - s_output_loss: 126.7380 - t_output_loss: 70.9532
28160/60000 [=============>................] - ETA: 6s - loss: 197.9687 - s_output_loss: 127.0151 - t_output_loss: 70.9536
28544/60000 [=============>................] - ETA: 6s - loss: 198.1791 - s_output_loss: 127.2667 - t_output_loss: 70.9124
28800/60000 [=============>................] - ETA: 6s - loss: 198.3275 - s_output_loss: 127.4075 - t_output_loss: 70.9200
29056/60000 [=============>................] - ETA: 6s - loss: 198.4912 - s_output_loss: 127.5519 - t_output_loss: 70.9392
29312/60000 [=============>................] - ETA: 6s - loss: 198.6377 - s_output_loss: 127.6814 - t_output_loss: 70.9563
29696/60000 [=============>................] - ETA: 6s - loss: 198.8029 - s_output_loss: 127.8475 - t_output_loss: 70.9555
29952/60000 [=============>................] - ETA: 6s - loss: 198.8861 - s_output_loss: 127.9475 - t_output_loss: 70.9387
30208/60000 [==============>...............] - ETA: 6s - loss: 199.0166 - s_output_loss: 128.0554 - t_output_loss: 70.9612
30464/60000 [==============>...............] - ETA: 5s - loss: 199.1244 - s_output_loss: 128.1417 - t_output_loss: 70.9828
30720/60000 [==============>...............] - ETA: 5s - loss: 199.1557 - s_output_loss: 128.1932 - t_output_loss: 70.9625
30976/60000 [==============>...............] - ETA: 5s - loss: 199.1756 - s_output_loss: 128.2206 - t_output_loss: 70.9550
31232/60000 [==============>...............] - ETA: 5s - loss: 199.2186 - s_output_loss: 128.2663 - t_output_loss: 70.9522
31616/60000 [==============>...............] - ETA: 5s - loss: 199.2558 - s_output_loss: 128.3073 - t_output_loss: 70.9485
31872/60000 [==============>...............] - ETA: 5s - loss: 199.3098 - s_output_loss: 128.3655 - t_output_loss: 70.9444
32128/60000 [===============>..............] - ETA: 5s - loss: 199.3090 - s_output_loss: 128.3799 - t_output_loss: 70.9291
32512/60000 [===============>..............] - ETA: 5s - loss: 199.3410 - s_output_loss: 128.4240 - t_output_loss: 70.9170
32896/60000 [===============>..............] - ETA: 5s - loss: 199.3023 - s_output_loss: 128.4342 - t_output_loss: 70.8681
33152/60000 [===============>..............] - ETA: 5s - loss: 199.3039 - s_output_loss: 128.4452 - t_output_loss: 70.8587
33408/60000 [===============>..............] - ETA: 5s - loss: 199.2978 - s_output_loss: 128.4605 - t_output_loss: 70.8374
33792/60000 [===============>..............] - ETA: 5s - loss: 199.2500 - s_output_loss: 128.4426 - t_output_loss: 70.8074
34048/60000 [================>.............] - ETA: 5s - loss: 199.2922 - s_output_loss: 128.4718 - t_output_loss: 70.8204
34304/60000 [================>.............] - ETA: 5s - loss: 199.2738 - s_output_loss: 128.4750 - t_output_loss: 70.7988
34688/60000 [================>.............] - ETA: 5s - loss: 199.2632 - s_output_loss: 128.4743 - t_output_loss: 70.7889
34944/60000 [================>.............] - ETA: 5s - loss: 199.2563 - s_output_loss: 128.4798 - t_output_loss: 70.7765
35200/60000 [================>.............] - ETA: 4s - loss: 199.2727 - s_output_loss: 128.4971 - t_output_loss: 70.7756
35456/60000 [================>.............] - ETA: 4s - loss: 199.2652 - s_output_loss: 128.5017 - t_output_loss: 70.7635
35840/60000 [================>.............] - ETA: 4s - loss: 199.2511 - s_output_loss: 128.5112 - t_output_loss: 70.7400
36096/60000 [=================>............] - ETA: 4s - loss: 199.1820 - s_output_loss: 128.4741 - t_output_loss: 70.7079
36352/60000 [=================>............] - ETA: 4s - loss: 199.1608 - s_output_loss: 128.4637 - t_output_loss: 70.6971
36736/60000 [=================>............] - ETA: 4s - loss: 199.1508 - s_output_loss: 128.4624 - t_output_loss: 70.6884
36992/60000 [=================>............] - ETA: 4s - loss: 199.1184 - s_output_loss: 128.4395 - t_output_loss: 70.6790
37248/60000 [=================>............] - ETA: 4s - loss: 199.0766 - s_output_loss: 128.4080 - t_output_loss: 70.6686
37632/60000 [=================>............] - ETA: 4s - loss: 199.0837 - s_output_loss: 128.4190 - t_output_loss: 70.6647
37888/60000 [=================>............] - ETA: 4s - loss: 199.0714 - s_output_loss: 128.4116 - t_output_loss: 70.6598
38144/60000 [==================>...........] - ETA: 4s - loss: 199.0543 - s_output_loss: 128.4028 - t_output_loss: 70.6515
38400/60000 [==================>...........] - ETA: 4s - loss: 199.0518 - s_output_loss: 128.4043 - t_output_loss: 70.6475
38656/60000 [==================>...........] - ETA: 4s - loss: 199.0246 - s_output_loss: 128.3940 - t_output_loss: 70.6305
38912/60000 [==================>...........] - ETA: 4s - loss: 198.9897 - s_output_loss: 128.3753 - t_output_loss: 70.6143
39168/60000 [==================>...........] - ETA: 4s - loss: 198.9487 - s_output_loss: 128.3480 - t_output_loss: 70.6008
39424/60000 [==================>...........] - ETA: 4s - loss: 198.8900 - s_output_loss: 128.3024 - t_output_loss: 70.5875
39680/60000 [==================>...........] - ETA: 4s - loss: 198.8879 - s_output_loss: 128.3091 - t_output_loss: 70.5789
40064/60000 [===================>..........] - ETA: 4s - loss: 198.8264 - s_output_loss: 128.2704 - t_output_loss: 70.5559
40320/60000 [===================>..........] - ETA: 3s - loss: 198.7697 - s_output_loss: 128.2354 - t_output_loss: 70.5343
40704/60000 [===================>..........] - ETA: 3s - loss: 198.7567 - s_output_loss: 128.2182 - t_output_loss: 70.5386
40960/60000 [===================>..........] - ETA: 3s - loss: 198.7355 - s_output_loss: 128.1976 - t_output_loss: 70.5379
41344/60000 [===================>..........] - ETA: 3s - loss: 198.7883 - s_output_loss: 128.2033 - t_output_loss: 70.5851
41728/60000 [===================>..........] - ETA: 3s - loss: 198.9024 - s_output_loss: 128.2569 - t_output_loss: 70.6455
42112/60000 [====================>.........] - ETA: 3s - loss: 199.0204 - s_output_loss: 128.2944 - t_output_loss: 70.7260
42368/60000 [====================>.........] - ETA: 3s - loss: 199.0837 - s_output_loss: 128.3026 - t_output_loss: 70.7811
42624/60000 [====================>.........] - ETA: 3s - loss: 199.1535 - s_output_loss: 128.3106 - t_output_loss: 70.8429
42880/60000 [====================>.........] - ETA: 3s - loss: 199.2161 - s_output_loss: 128.3180 - t_output_loss: 70.8982
43136/60000 [====================>.........] - ETA: 3s - loss: 199.2607 - s_output_loss: 128.3265 - t_output_loss: 70.9342
43392/60000 [====================>.........] - ETA: 3s - loss: 199.2899 - s_output_loss: 128.3237 - t_output_loss: 70.9662
43776/60000 [====================>.........] - ETA: 3s - loss: 199.2937 - s_output_loss: 128.2986 - t_output_loss: 70.9951
44032/60000 [=====================>........] - ETA: 3s - loss: 199.3595 - s_output_loss: 128.3353 - t_output_loss: 71.0242
44288/60000 [=====================>........] - ETA: 3s - loss: 199.3970 - s_output_loss: 128.3442 - t_output_loss: 71.0528
44672/60000 [=====================>........] - ETA: 3s - loss: 199.4278 - s_output_loss: 128.3576 - t_output_loss: 71.0702
45056/60000 [=====================>........] - ETA: 3s - loss: 199.4135 - s_output_loss: 128.3383 - t_output_loss: 71.0752
45440/60000 [=====================>........] - ETA: 2s - loss: 199.3728 - s_output_loss: 128.2973 - t_output_loss: 71.0756
45824/60000 [=====================>........] - ETA: 2s - loss: 199.3231 - s_output_loss: 128.2641 - t_output_loss: 71.0591
46080/60000 [======================>.......] - ETA: 2s - loss: 199.2805 - s_output_loss: 128.2330 - t_output_loss: 71.0476
46336/60000 [======================>.......] - ETA: 2s - loss: 199.2602 - s_output_loss: 128.2152 - t_output_loss: 71.0450
46720/60000 [======================>.......] - ETA: 2s - loss: 199.2295 - s_output_loss: 128.1799 - t_output_loss: 71.0496
46976/60000 [======================>.......] - ETA: 2s - loss: 199.2131 - s_output_loss: 128.1772 - t_output_loss: 71.0359
47360/60000 [======================>.......] - ETA: 2s - loss: 199.1449 - s_output_loss: 128.1254 - t_output_loss: 71.0195
47616/60000 [======================>.......] - ETA: 2s - loss: 199.1205 - s_output_loss: 128.1024 - t_output_loss: 71.0181
47872/60000 [======================>.......] - ETA: 2s - loss: 199.0624 - s_output_loss: 128.0659 - t_output_loss: 70.9965
48128/60000 [=======================>......] - ETA: 2s - loss: 199.0161 - s_output_loss: 128.0322 - t_output_loss: 70.9838
48384/60000 [=======================>......] - ETA: 2s - loss: 198.9833 - s_output_loss: 128.0155 - t_output_loss: 70.9678
48640/60000 [=======================>......] - ETA: 2s - loss: 198.9368 - s_output_loss: 127.9818 - t_output_loss: 70.9550
48896/60000 [=======================>......] - ETA: 2s - loss: 198.8867 - s_output_loss: 127.9577 - t_output_loss: 70.9290
49152/60000 [=======================>......] - ETA: 2s - loss: 198.8345 - s_output_loss: 127.9233 - t_output_loss: 70.9112
49408/60000 [=======================>......] - ETA: 2s - loss: 198.7710 - s_output_loss: 127.8904 - t_output_loss: 70.8806
49664/60000 [=======================>......] - ETA: 2s - loss: 198.7666 - s_output_loss: 127.8925 - t_output_loss: 70.8741
49920/60000 [=======================>......] - ETA: 2s - loss: 198.7118 - s_output_loss: 127.8545 - t_output_loss: 70.8574
50176/60000 [========================>.....] - ETA: 1s - loss: 198.6880 - s_output_loss: 127.8470 - t_output_loss: 70.8410
50432/60000 [========================>.....] - ETA: 1s - loss: 198.6762 - s_output_loss: 127.8310 - t_output_loss: 70.8452
50688/60000 [========================>.....] - ETA: 1s - loss: 198.6344 - s_output_loss: 127.8051 - t_output_loss: 70.8293
50944/60000 [========================>.....] - ETA: 1s - loss: 198.6058 - s_output_loss: 127.7900 - t_output_loss: 70.8159
51200/60000 [========================>.....] - ETA: 1s - loss: 198.5528 - s_output_loss: 127.7479 - t_output_loss: 70.8049
51584/60000 [========================>.....] - ETA: 1s - loss: 198.4957 - s_output_loss: 127.6951 - t_output_loss: 70.8007
51840/60000 [========================>.....] - ETA: 1s - loss: 198.4668 - s_output_loss: 127.6717 - t_output_loss: 70.7951
52224/60000 [=========================>....] - ETA: 1s - loss: 198.3980 - s_output_loss: 127.6348 - t_output_loss: 70.7632
52480/60000 [=========================>....] - ETA: 1s - loss: 198.3624 - s_output_loss: 127.6089 - t_output_loss: 70.7535
52736/60000 [=========================>....] - ETA: 1s - loss: 198.3281 - s_output_loss: 127.5976 - t_output_loss: 70.7305
53120/60000 [=========================>....] - ETA: 1s - loss: 198.2580 - s_output_loss: 127.5573 - t_output_loss: 70.7006
53376/60000 [=========================>....] - ETA: 1s - loss: 198.2194 - s_output_loss: 127.5301 - t_output_loss: 70.6892
53760/60000 [=========================>....] - ETA: 1s - loss: 198.1927 - s_output_loss: 127.5117 - t_output_loss: 70.6810
54016/60000 [==========================>...] - ETA: 1s - loss: 198.1650 - s_output_loss: 127.4920 - t_output_loss: 70.6730
54272/60000 [==========================>...] - ETA: 1s - loss: 198.1706 - s_output_loss: 127.4976 - t_output_loss: 70.6730
54656/60000 [==========================>...] - ETA: 1s - loss: 198.1296 - s_output_loss: 127.4577 - t_output_loss: 70.6719
55040/60000 [==========================>...] - ETA: 0s - loss: 198.0913 - s_output_loss: 127.4276 - t_output_loss: 70.6637
55296/60000 [==========================>...] - ETA: 0s - loss: 198.0708 - s_output_loss: 127.4127 - t_output_loss: 70.6581
55680/60000 [==========================>...] - ETA: 0s - loss: 198.0394 - s_output_loss: 127.3893 - t_output_loss: 70.6501
55936/60000 [==========================>...] - ETA: 0s - loss: 197.9938 - s_output_loss: 127.3562 - t_output_loss: 70.6377
56192/60000 [===========================>..] - ETA: 0s - loss: 197.9862 - s_output_loss: 127.3522 - t_output_loss: 70.6340
56448/60000 [===========================>..] - ETA: 0s - loss: 197.9756 - s_output_loss: 127.3385 - t_output_loss: 70.6371
56704/60000 [===========================>..] - ETA: 0s - loss: 197.9388 - s_output_loss: 127.3126 - t_output_loss: 70.6262
56960/60000 [===========================>..] - ETA: 0s - loss: 197.9142 - s_output_loss: 127.2946 - t_output_loss: 70.6196
57344/60000 [===========================>..] - ETA: 0s - loss: 197.8735 - s_output_loss: 127.2566 - t_output_loss: 70.6169
57728/60000 [===========================>..] - ETA: 0s - loss: 197.8224 - s_output_loss: 127.2128 - t_output_loss: 70.6096
58112/60000 [============================>.] - ETA: 0s - loss: 197.7909 - s_output_loss: 127.1878 - t_output_loss: 70.6031
58368/60000 [============================>.] - ETA: 0s - loss: 197.7672 - s_output_loss: 127.1675 - t_output_loss: 70.5997
58624/60000 [============================>.] - ETA: 0s - loss: 197.7137 - s_output_loss: 127.1263 - t_output_loss: 70.5874
58880/60000 [============================>.] - ETA: 0s - loss: 197.7018 - s_output_loss: 127.1086 - t_output_loss: 70.5932
59136/60000 [============================>.] - ETA: 0s - loss: 197.7040 - s_output_loss: 127.0794 - t_output_loss: 70.6245
59392/60000 [============================>.] - ETA: 0s - loss: 197.7171 - s_output_loss: 127.0539 - t_output_loss: 70.6632
59648/60000 [============================>.] - ETA: 0s - loss: 197.7186 - s_output_loss: 127.0260 - t_output_loss: 70.6926
59904/60000 [============================>.] - ETA: 0s - loss: 197.7421 - s_output_loss: 127.0098 - t_output_loss: 70.7324
60000/60000 [==============================] - 13s 211us/step - loss: 197.7528 - s_output_loss: 127.0095 - t_output_loss: 70.7433 - val_loss: 201.2111 - val_s_output_loss: 120.7092 - val_t_output_loss: 80.5019
variational_ae.py:276: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=Tensor("s_..., outputs=Tensor("mo...)`
  s_enc_cls_model = Model(input=self.s_encoder.input, output=self.classifier(self.s_encoder.output[2]))
variational_ae.py:282: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=Tensor("t_..., outputs=Tensor("mo...)`
  t_enc_cls_model = Model(input=self.t_encoder.input, output=self.classifier(self.t_encoder.output[2]))
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
s_input (InputLayer)            (None, 28, 28, 1)    0                                            
__________________________________________________________________________________________________
conv2d_1 (Conv2D)               (None, 28, 28, 16)   160         s_input[0][0]                    
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 14, 14, 16)   0           conv2d_1[0][0]                   
__________________________________________________________________________________________________
conv2d_2 (Conv2D)               (None, 14, 14, 32)   2080        max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
max_pooling2d_2 (MaxPooling2D)  (None, 7, 7, 32)     0           conv2d_2[0][0]                   
__________________________________________________________________________________________________
flatten_1 (Flatten)             (None, 1568)         0           max_pooling2d_2[0][0]            
__________________________________________________________________________________________________
s_z_mean (Dense)                (None, 10)           15690       flatten_1[0][0]                  
__________________________________________________________________________________________________
s_z_log_var (Dense)             (None, 10)           15690       flatten_1[0][0]                  
__________________________________________________________________________________________________
s_z (Lambda)                    (None, 10)           0           s_z_mean[0][0]                   
                                                                 s_z_log_var[0][0]                
__________________________________________________________________________________________________
model_2 (Model)                 (None, 10)           220         s_z[0][0]                        
==================================================================================================
Total params: 33,840
Trainable params: 33,840
Non-trainable params: 0
__________________________________________________________________________________________________
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
t_input (InputLayer)            (None, 16, 16, 1)    0                                            
__________________________________________________________________________________________________
conv2d_5 (Conv2D)               (None, 16, 16, 16)   160         t_input[0][0]                    
__________________________________________________________________________________________________
max_pooling2d_3 (MaxPooling2D)  (None, 8, 8, 16)     0           conv2d_5[0][0]                   
__________________________________________________________________________________________________
conv2d_6 (Conv2D)               (None, 8, 8, 32)     2080        max_pooling2d_3[0][0]            
__________________________________________________________________________________________________
max_pooling2d_4 (MaxPooling2D)  (None, 4, 4, 32)     0           conv2d_6[0][0]                   
__________________________________________________________________________________________________
flatten_2 (Flatten)             (None, 512)          0           max_pooling2d_4[0][0]            
__________________________________________________________________________________________________
t_z_mean (Dense)                (None, 10)           5130        flatten_2[0][0]                  
__________________________________________________________________________________________________
t_z_log_var (Dense)             (None, 10)           5130        flatten_2[0][0]                  
__________________________________________________________________________________________________
z (Lambda)                      (None, 10)           0           t_z_mean[0][0]                   
                                                                 t_z_log_var[0][0]                
__________________________________________________________________________________________________
model_2 (Model)                 (None, 10)           220         z[0][0]                          
==================================================================================================
Total params: 12,720
Trainable params: 12,720
Non-trainable params: 0
__________________________________________________________________________________________________
Using TensorFlow backend.
/home/mrahman/.local/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint8 = np.dtype([("qint8", np.int8, 1)])
/home/mrahman/.local/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint8 = np.dtype([("quint8", np.uint8, 1)])
/home/mrahman/.local/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint16 = np.dtype([("qint16", np.int16, 1)])
/home/mrahman/.local/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint16 = np.dtype([("quint16", np.uint16, 1)])
/home/mrahman/.local/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint32 = np.dtype([("qint32", np.int32, 1)])
/home/mrahman/.local/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  np_resource = np.dtype([("resource", np.ubyte, 1)])
/home/mrahman/.local/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint8 = np.dtype([("qint8", np.int8, 1)])
/home/mrahman/.local/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint8 = np.dtype([("quint8", np.uint8, 1)])
/home/mrahman/.local/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint16 = np.dtype([("qint16", np.int16, 1)])
/home/mrahman/.local/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint16 = np.dtype([("quint16", np.uint16, 1)])
/home/mrahman/.local/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint32 = np.dtype([("qint32", np.int32, 1)])
/home/mrahman/.local/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  np_resource = np.dtype([("resource", np.ubyte, 1)])
WARNING:tensorflow:From /home/mrahman/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.

WARNING:tensorflow:From /home/mrahman/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.

WARNING:tensorflow:From /home/mrahman/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.

WARNING:tensorflow:From /home/mrahman/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:3976: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.

WARNING:tensorflow:From /home/mrahman/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:4115: The name tf.random_normal is deprecated. Please use tf.random.normal instead.

WARNING:tensorflow:From /home/mrahman/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:2018: The name tf.image.resize_nearest_neighbor is deprecated. Please use tf.compat.v1.image.resize_nearest_neighbor instead.

__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
s_input (InputLayer)            (None, 28, 28, 1)    0                                            
__________________________________________________________________________________________________
conv2d_1 (Conv2D)               (None, 28, 28, 16)   160         s_input[0][0]                    
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 14, 14, 16)   0           conv2d_1[0][0]                   
__________________________________________________________________________________________________
conv2d_2 (Conv2D)               (None, 14, 14, 32)   2080        max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
max_pooling2d_2 (MaxPooling2D)  (None, 7, 7, 32)     0           conv2d_2[0][0]                   
__________________________________________________________________________________________________
flatten_1 (Flatten)             (None, 1568)         0           max_pooling2d_2[0][0]            
__________________________________________________________________________________________________
s_z_mean (Dense)                (None, 10)           15690       flatten_1[0][0]                  
__________________________________________________________________________________________________
s_z_log_var (Dense)             (None, 10)           15690       flatten_1[0][0]                  
__________________________________________________________________________________________________
s_z (Lambda)                    (None, 10)           0           s_z_mean[0][0]                   
                                                                 s_z_log_var[0][0]                
==================================================================================================
Total params: 33,620
Trainable params: 33,620
Non-trainable params: 0
__________________________________________________________________________________________________
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
t_input (InputLayer)            (None, 16, 16, 1)    0                                            
__________________________________________________________________________________________________
conv2d_5 (Conv2D)               (None, 16, 16, 16)   160         t_input[0][0]                    
__________________________________________________________________________________________________
max_pooling2d_3 (MaxPooling2D)  (None, 8, 8, 16)     0           conv2d_5[0][0]                   
__________________________________________________________________________________________________
conv2d_6 (Conv2D)               (None, 8, 8, 32)     2080        max_pooling2d_3[0][0]            
__________________________________________________________________________________________________
max_pooling2d_4 (MaxPooling2D)  (None, 4, 4, 32)     0           conv2d_6[0][0]                   
__________________________________________________________________________________________________
flatten_2 (Flatten)             (None, 512)          0           max_pooling2d_4[0][0]            
__________________________________________________________________________________________________
t_z_mean (Dense)                (None, 10)           5130        flatten_2[0][0]                  
__________________________________________________________________________________________________
t_z_log_var (Dense)             (None, 10)           5130        flatten_2[0][0]                  
__________________________________________________________________________________________________
z (Lambda)                      (None, 10)           0           t_z_mean[0][0]                   
                                                                 t_z_log_var[0][0]                
==================================================================================================
Total params: 12,500
Trainable params: 12,500
Non-trainable params: 0
__________________________________________________________________________________________________
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
s_input (InputLayer)            (None, 28, 28, 1)    0                                            
__________________________________________________________________________________________________
conv2d_1 (Conv2D)               (None, 28, 28, 16)   160         s_input[0][0]                    
__________________________________________________________________________________________________
t_input (InputLayer)            (None, 16, 16, 1)    0                                            
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 14, 14, 16)   0           conv2d_1[0][0]                   
__________________________________________________________________________________________________
conv2d_5 (Conv2D)               (None, 16, 16, 16)   160         t_input[0][0]                    
__________________________________________________________________________________________________
conv2d_2 (Conv2D)               (None, 14, 14, 32)   2080        max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
max_pooling2d_3 (MaxPooling2D)  (None, 8, 8, 16)     0           conv2d_5[0][0]                   
__________________________________________________________________________________________________
max_pooling2d_2 (MaxPooling2D)  (None, 7, 7, 32)     0           conv2d_2[0][0]                   
__________________________________________________________________________________________________
conv2d_6 (Conv2D)               (None, 8, 8, 32)     2080        max_pooling2d_3[0][0]            
__________________________________________________________________________________________________
flatten_1 (Flatten)             (None, 1568)         0           max_pooling2d_2[0][0]            
__________________________________________________________________________________________________
max_pooling2d_4 (MaxPooling2D)  (None, 4, 4, 32)     0           conv2d_6[0][0]                   
__________________________________________________________________________________________________
s_z_mean (Dense)                (None, 10)           15690       flatten_1[0][0]                  
__________________________________________________________________________________________________
s_z_log_var (Dense)             (None, 10)           15690       flatten_1[0][0]                  
__________________________________________________________________________________________________
flatten_2 (Flatten)             (None, 512)          0           max_pooling2d_4[0][0]            
__________________________________________________________________________________________________
s_z (Lambda)                    (None, 10)           0           s_z_mean[0][0]                   
                                                                 s_z_log_var[0][0]                
__________________________________________________________________________________________________
t_z_mean (Dense)                (None, 10)           5130        flatten_2[0][0]                  
__________________________________________________________________________________________________WARNING:tensorflow:From /home/mrahman/anaconda3/lib/python3.7/site-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.

WARNING:tensorflow:From /home/mrahman/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:3376: The name tf.log is deprecated. Please use tf.math.log instead.

WARNING:tensorflow:From /home/mrahman/.local/lib/python3.7/site-packages/tensorflow/python/ops/nn_impl.py:180: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use tf.where in 2.0, which has the same broadcast rule as np.where
2020-04-26 00:12:15.988313: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2000204999 Hz
2020-04-26 00:12:15.990949: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x555be39b7690 executing computations on platform Host. Devices:
2020-04-26 00:12:15.991008: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>
2020-04-26 00:12:15.993878: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcuda.so.1
2020-04-26 00:12:16.299791: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 0 with properties: 
name: GeForce GTX TITAN X major: 5 minor: 2 memoryClockRate(GHz): 1.076
pciBusID: 0000:05:00.0
2020-04-26 00:12:16.301060: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 1 with properties: 
name: Tesla K40c major: 3 minor: 5 memoryClockRate(GHz): 0.745
pciBusID: 0000:84:00.0
2020-04-26 00:12:16.302230: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 2 with properties: 
name: Tesla K40c major: 3 minor: 5 memoryClockRate(GHz): 0.745
pciBusID: 0000:88:00.0
2020-04-26 00:12:16.302665: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0
2020-04-26 00:12:16.304963: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0
2020-04-26 00:12:16.306750: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcufft.so.10.0
2020-04-26 00:12:16.307202: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcurand.so.10.0
2020-04-26 00:12:16.309940: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusolver.so.10.0
2020-04-26 00:12:16.312433: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusparse.so.10.0
2020-04-26 00:12:16.317894: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7
2020-04-26 00:12:16.324643: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1763] Adding visible gpu devices: 0, 1, 2
2020-04-26 00:12:16.324734: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0
2020-04-26 00:12:16.329256: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1181] Device interconnect StreamExecutor with strength 1 edge matrix:
2020-04-26 00:12:16.329291: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1187]      0 1 2 
2020-04-26 00:12:16.329309: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1200] 0:   N N N 
2020-04-26 00:12:16.329322: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1200] 1:   N N Y 
2020-04-26 00:12:16.329335: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1200] 2:   N Y N 
2020-04-26 00:12:16.335101: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1326] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 11497 MB memory) -> physical GPU (device: 0, name: GeForce GTX TITAN X, pci bus id: 0000:05:00.0, compute capability: 5.2)
2020-04-26 00:12:16.338004: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1326] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:1 with 11525 MB memory) -> physical GPU (device: 1, name: Tesla K40c, pci bus id: 0000:84:00.0, compute capability: 3.5)
2020-04-26 00:12:16.340929: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1326] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:2 with 11525 MB memory) -> physical GPU (device: 2, name: Tesla K40c, pci bus id: 0000:88:00.0, compute capability: 3.5)
2020-04-26 00:12:16.344398: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x555beae44fd0 executing computations on platform CUDA. Devices:
2020-04-26 00:12:16.344447: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): GeForce GTX TITAN X, Compute Capability 5.2
2020-04-26 00:12:16.344464: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (1): Tesla K40c, Compute Capability 3.5
2020-04-26 00:12:16.344490: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (2): Tesla K40c, Compute Capability 3.5
2020-04-26 00:12:19.173119: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0
2020-04-26 00:12:19.464645: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7

t_z_log_var (Dense)             (None, 10)           5130        flatten_2[0][0]                  
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 10)           110         s_z[0][0]                        
__________________________________________________________________________________________________
z (Lambda)                      (None, 10)           0           t_z_mean[0][0]                   
                                                                 t_z_log_var[0][0]                
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 20)           0           dense_2[0][0]                    
                                                                 z[0][0]                          
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 1568)         17248       s_z[0][0]                        
__________________________________________________________________________________________________
dense_3 (Dense)                 (None, 512)          10752       concatenate_1[0][0]              
__________________________________________________________________________________________________
reshape_1 (Reshape)             (None, 7, 7, 32)     0           dense_1[0][0]                    
__________________________________________________________________________________________________
reshape_2 (Reshape)             (None, 4, 4, 32)     0           dense_3[0][0]                    
__________________________________________________________________________________________________
conv2d_3 (Conv2D)               (None, 7, 7, 32)     4128        reshape_1[0][0]                  
__________________________________________________________________________________________________
conv2d_7 (Conv2D)               (None, 4, 4, 32)     4128        reshape_2[0][0]                  
__________________________________________________________________________________________________
up_sampling2d_1 (UpSampling2D)  (None, 14, 14, 32)   0           conv2d_3[0][0]                   
__________________________________________________________________________________________________
up_sampling2d_3 (UpSampling2D)  (None, 8, 8, 32)     0           conv2d_7[0][0]                   
__________________________________________________________________________________________________
conv2d_4 (Conv2D)               (None, 14, 14, 16)   4624        up_sampling2d_1[0][0]            
__________________________________________________________________________________________________
conv2d_8 (Conv2D)               (None, 8, 8, 16)     4624        up_sampling2d_3[0][0]            
__________________________________________________________________________________________________
up_sampling2d_2 (UpSampling2D)  (None, 28, 28, 16)   0           conv2d_4[0][0]                   
__________________________________________________________________________________________________
up_sampling2d_4 (UpSampling2D)  (None, 16, 16, 16)   0           conv2d_8[0][0]                   
__________________________________________________________________________________________________
s_output (Conv2D)               (None, 28, 28, 1)    145         up_sampling2d_2[0][0]            
__________________________________________________________________________________________________
t_output (Conv2D)               (None, 16, 16, 1)    145         up_sampling2d_4[0][0]            
==================================================================================================
Total params: 92,024
Trainable params: 92,024
Non-trainable params: 0
__________________________________________________________________________________________________
Train on 60000 samples, validate on 10000 samples
Epoch 1/100
 - 19s - loss: 300.3091 - s_output_loss: 187.7672 - t_output_loss: 112.5419 - val_loss: 254.4499 - val_s_output_loss: 148.7682 - val_t_output_loss: 105.6817
Epoch 2/100
 - 13s - loss: 256.4546 - s_output_loss: 165.4406 - t_output_loss: 91.0140 - val_loss: 232.8162 - val_s_output_loss: 149.5564 - val_t_output_loss: 83.2597
Epoch 3/100
 - 13s - loss: 238.8994 - s_output_loss: 152.4775 - t_output_loss: 86.4218 - val_loss: 242.8790 - val_s_output_loss: 139.3332 - val_t_output_loss: 103.5458
Epoch 4/100
 - 13s - loss: 233.1730 - s_output_loss: 150.1025 - t_output_loss: 83.0706 - val_loss: 245.5581 - val_s_output_loss: 164.7379 - val_t_output_loss: 80.8202
Epoch 5/100
 - 13s - loss: 223.6038 - s_output_loss: 148.6517 - t_output_loss: 74.9522 - val_loss: 216.2722 - val_s_output_loss: 141.8355 - val_t_output_loss: 74.4367
Epoch 6/100
 - 13s - loss: 247.6802 - s_output_loss: 171.6957 - t_output_loss: 75.9845 - val_loss: 226.7095 - val_s_output_loss: 151.7763 - val_t_output_loss: 74.9332
Epoch 7/100
 - 13s - loss: 224.5052 - s_output_loss: 152.7546 - t_output_loss: 71.7506 - val_loss: 210.7699 - val_s_output_loss: 138.6481 - val_t_output_loss: 72.1218
Epoch 8/100
 - 13s - loss: 227.9563 - s_output_loss: 143.3889 - t_output_loss: 84.5674 - val_loss: 257.0234 - val_s_output_loss: 170.9786 - val_t_output_loss: 86.0448
Epoch 9/100
 - 13s - loss: 220.0284 - s_output_loss: 138.0271 - t_output_loss: 82.0013 - val_loss: 210.0125 - val_s_output_loss: 131.1352 - val_t_output_loss: 78.8772
Epoch 10/100
 - 13s - loss: 235.6533 - s_output_loss: 142.2900 - t_output_loss: 93.3633 - val_loss: 218.9052 - val_s_output_loss: 131.6132 - val_t_output_loss: 87.2920
Epoch 11/100
 - 13s - loss: 228.8518 - s_output_loss: 149.6122 - t_output_loss: 79.2396 - val_loss: 212.5219 - val_s_output_loss: 136.4589 - val_t_output_loss: 76.0630
Epoch 12/100
 - 14s - loss: 206.1018 - s_output_loss: 134.7108 - t_output_loss: 71.3910 - val_loss: 211.0097 - val_s_output_loss: 131.8215 - val_t_output_loss: 79.1882
Epoch 13/100
 - 13s - loss: 210.5493 - s_output_loss: 140.7310 - t_output_loss: 69.8184 - val_loss: 262.5637 - val_s_output_loss: 136.1725 - val_t_output_loss: 126.3912
Epoch 14/100
 - 13s - loss: 210.4661 - s_output_loss: 137.4018 - t_output_loss: 73.0644 - val_loss: 219.1929 - val_s_output_loss: 135.0788 - val_t_output_loss: 84.1141
Epoch 15/100
 - 13s - loss: 210.7805 - s_output_loss: 140.5055 - t_output_loss: 70.2750 - val_loss: 213.7137 - val_s_output_loss: 142.6652 - val_t_output_loss: 71.0484
Epoch 16/100
 - 13s - loss: 213.1222 - s_output_loss: 141.7190 - t_output_loss: 71.4032 - val_loss: 205.4828 - val_s_output_loss: 129.8507 - val_t_output_loss: 75.6321
Epoch 17/100
 - 13s - loss: 226.0974 - s_output_loss: 150.3971 - t_output_loss: 75.7003 - val_loss: 262.1229 - val_s_output_loss: 180.7012 - val_t_output_loss: 81.4217
Epoch 18/100
 - 13s - loss: 230.7856 - s_output_loss: 149.4798 - t_output_loss: 81.3059 - val_loss: 238.0742 - val_s_output_loss: 136.3659 - val_t_output_loss: 101.7083
Epoch 19/100
 - 13s - loss: 220.7590 - s_output_loss: 142.1727 - t_output_loss: 78.5862 - val_loss: 224.0688 - val_s_output_loss: 138.3907 - val_t_output_loss: 85.6781
Epoch 20/100
 - 13s - loss: 224.5707 - s_output_loss: 154.6419 - t_output_loss: 69.9287 - val_loss: 207.7495 - val_s_output_loss: 136.8464 - val_t_output_loss: 70.9031
Epoch 21/100
 - 13s - loss: 207.3535 - s_output_loss: 138.1964 - t_output_loss: 69.1571 - val_loss: 227.3532 - val_s_output_loss: 137.8352 - val_t_output_loss: 89.5180
Epoch 22/100
 - 13s - loss: 209.3169 - s_output_loss: 135.2608 - t_output_loss: 74.0562 - val_loss: 202.1907 - val_s_output_loss: 130.0757 - val_t_output_loss: 72.1150
Epoch 23/100
 - 13s - loss: 205.3428 - s_output_loss: 132.0003 - t_output_loss: 73.3425 - val_loss: 205.2922 - val_s_output_loss: 128.5821 - val_t_output_loss: 76.7102
Epoch 24/100
 - 13s - loss: 212.6481 - s_output_loss: 129.4559 - t_output_loss: 83.1922 - val_loss: 226.6232 - val_s_output_loss: 148.3684 - val_t_output_loss: 78.2548
Epoch 25/100
 - 13s - loss: 210.5048 - s_output_loss: 130.1198 - t_output_loss: 80.3850 - val_loss: 205.6685 - val_s_output_loss: 123.6178 - val_t_output_loss: 82.0508
Epoch 26/100
 - 13s - loss: 227.2541 - s_output_loss: 142.2842 - t_output_loss: 84.9700 - val_loss: 205.1387 - val_s_output_loss: 126.8208 - val_t_output_loss: 78.3179
Epoch 27/100
 - 13s - loss: 196.6465 - s_output_loss: 125.9455 - t_output_loss: 70.7010 - val_loss: 194.1743 - val_s_output_loss: 122.4197 - val_t_output_loss: 71.7547
Epoch 28/100
 - 14s - loss: 194.1782 - s_output_loss: 126.7391 - t_output_loss: 67.4390 - val_loss: 195.2869 - val_s_output_loss: 123.5286 - val_t_output_loss: 71.7584
Epoch 29/100
 - 14s - loss: 191.2182 - s_output_loss: 124.4524 - t_output_loss: 66.7658 - val_loss: 192.4328 - val_s_output_loss: 122.9383 - val_t_output_loss: 69.4945
Epoch 30/100
 - 14s - loss: 208.3962 - s_output_loss: 127.3125 - t_output_loss: 81.0837 - val_loss: 210.8574 - val_s_output_loss: 124.8695 - val_t_output_loss: 85.9878
Epoch 31/100
 - 14s - loss: 228.2710 - s_output_loss: 152.6307 - t_output_loss: 75.6403 - val_loss: 212.4812 - val_s_output_loss: 136.9611 - val_t_output_loss: 75.5200
Epoch 32/100
 - 14s - loss: 206.8783 - s_output_loss: 133.8275 - t_output_loss: 73.0508 - val_loss: 199.9632 - val_s_output_loss: 127.2043 - val_t_output_loss: 72.7589
Epoch 33/100
 - 13s - loss: 205.2286 - s_output_loss: 133.9236 - t_output_loss: 71.3051 - val_loss: 197.7482 - val_s_output_loss: 125.4017 - val_t_output_loss: 72.3465
Epoch 34/100
 - 13s - loss: 199.2997 - s_output_loss: 131.5759 - t_output_loss: 67.7238 - val_loss: 196.3283 - val_s_output_loss: 126.0733 - val_t_output_loss: 70.2550
Epoch 35/100
 - 13s - loss: 194.1774 - s_output_loss: 127.3097 - t_output_loss: 66.8677 - val_loss: 193.5914 - val_s_output_loss: 121.5210 - val_t_output_loss: 72.0704
Epoch 36/100
 - 13s - loss: 189.3927 - s_output_loss: 121.5214 - t_output_loss: 67.8714 - val_loss: 190.0325 - val_s_output_loss: 119.4294 - val_t_output_loss: 70.6031
Epoch 37/100
 - 13s - loss: 190.7365 - s_output_loss: 122.7308 - t_output_loss: 68.0057 - val_loss: 189.5408 - val_s_output_loss: 119.3834 - val_t_output_loss: 70.1574
Epoch 38/100
 - 13s - loss: 202.6830 - s_output_loss: 138.3060 - t_output_loss: 64.3770 - val_loss: 227.0745 - val_s_output_loss: 159.4106 - val_t_output_loss: 67.6639
Epoch 39/100
 - 13s - loss: 188.5464 - s_output_loss: 125.0486 - t_output_loss: 63.4978 - val_loss: 186.6696 - val_s_output_loss: 120.0535 - val_t_output_loss: 66.6160
Epoch 40/100
 - 13s - loss: 216.8026 - s_output_loss: 146.7140 - t_output_loss: 70.0887 - val_loss: 198.2055 - val_s_output_loss: 128.5811 - val_t_output_loss: 69.6244
Epoch 41/100
 - 13s - loss: 202.0861 - s_output_loss: 125.2962 - t_output_loss: 76.7899 - val_loss: 226.0613 - val_s_output_loss: 121.3419 - val_t_output_loss: 104.7193
Epoch 42/100
 - 13s - loss: 208.1676 - s_output_loss: 128.5632 - t_output_loss: 79.6043 - val_loss: 216.6447 - val_s_output_loss: 124.6966 - val_t_output_loss: 91.9481
Epoch 43/100
 - 13s - loss: 197.4410 - s_output_loss: 125.9001 - t_output_loss: 71.5409 - val_loss: 191.5297 - val_s_output_loss: 120.2295 - val_t_output_loss: 71.3002
Epoch 44/100
 - 13s - loss: 195.9248 - s_output_loss: 126.6879 - t_output_loss: 69.2370 - val_loss: 217.7106 - val_s_output_loss: 120.6686 - val_t_output_loss: 97.0419
Epoch 45/100
 - 13s - loss: 196.9423 - s_output_loss: 126.8570 - t_output_loss: 70.0853 - val_loss: 201.0398 - val_s_output_loss: 131.7195 - val_t_output_loss: 69.3203
Epoch 46/100
 - 13s - loss: 200.4456 - s_output_loss: 127.3750 - t_output_loss: 73.0705 - val_loss: 194.2591 - val_s_output_loss: 120.7468 - val_t_output_loss: 73.5122
Epoch 47/100
 - 13s - loss: 196.0849 - s_output_loss: 127.4466 - t_output_loss: 68.6383 - val_loss: 196.6340 - val_s_output_loss: 125.5942 - val_t_output_loss: 71.0398
Epoch 48/100
 - 13s - loss: 188.9116 - s_output_loss: 120.1343 - t_output_loss: 68.7774 - val_loss: 185.8479 - val_s_output_loss: 117.3516 - val_t_output_loss: 68.4963
Epoch 49/100
 - 13s - loss: 185.7556 - s_output_loss: 118.7660 - t_output_loss: 66.9895 - val_loss: 192.6982 - val_s_output_loss: 123.8075 - val_t_output_loss: 68.8906
Epoch 50/100
 - 13s - loss: 194.9841 - s_output_loss: 119.7872 - t_output_loss: 75.1969 - val_loss: 238.6255 - val_s_output_loss: 164.1294 - val_t_output_loss: 74.4961
Epoch 51/100
 - 13s - loss: 186.8038 - s_output_loss: 120.2496 - t_output_loss: 66.5543 - val_loss: 187.8003 - val_s_output_loss: 118.0373 - val_t_output_loss: 69.7630
Epoch 52/100
 - 13s - loss: 220.1555 - s_output_loss: 152.1961 - t_output_loss: 67.9595 - val_loss: 198.9540 - val_s_output_loss: 129.5414 - val_t_output_loss: 69.4127
Epoch 53/100
 - 13s - loss: 196.8562 - s_output_loss: 129.9899 - t_output_loss: 66.8663 - val_loss: 205.0135 - val_s_output_loss: 130.9173 - val_t_output_loss: 74.0962
Epoch 54/100
 - 13s - loss: 191.1649 - s_output_loss: 121.8646 - t_output_loss: 69.3004 - val_loss: 189.8730 - val_s_output_loss: 119.1869 - val_t_output_loss: 70.6860
Epoch 55/100
 - 13s - loss: 201.1224 - s_output_loss: 125.8114 - t_output_loss: 75.3110 - val_loss: 201.8850 - val_s_output_loss: 123.4997 - val_t_output_loss: 78.3853
Epoch 56/100
 - 13s - loss: 207.1689 - s_output_loss: 134.4194 - t_output_loss: 72.7495 - val_loss: 193.6101 - val_s_output_loss: 120.7087 - val_t_output_loss: 72.9014
Epoch 57/100
 - 13s - loss: 189.4138 - s_output_loss: 122.9190 - t_output_loss: 66.4948 - val_loss: 205.7220 - val_s_output_loss: 118.1390 - val_t_output_loss: 87.5830
Epoch 58/100
 - 13s - loss: 206.1640 - s_output_loss: 126.8800 - t_output_loss: 79.2840 - val_loss: 191.6506 - val_s_output_loss: 118.6376 - val_t_output_loss: 73.0130
Epoch 59/100
 - 13s - loss: 186.6832 - s_output_loss: 119.5338 - t_output_loss: 67.1494 - val_loss: 187.5310 - val_s_output_loss: 118.6414 - val_t_output_loss: 68.8896
Epoch 60/100
 - 13s - loss: 181.4382 - s_output_loss: 117.2419 - t_output_loss: 64.1963 - val_loss: 184.7726 - val_s_output_loss: 116.6636 - val_t_output_loss: 68.1090
Epoch 61/100
 - 13s - loss: 191.6338 - s_output_loss: 121.7393 - t_output_loss: 69.8945 - val_loss: 296.6872 - val_s_output_loss: 116.6123 - val_t_output_loss: 180.0749
Epoch 62/100
 - 14s - loss: 202.3710 - s_output_loss: 115.5977 - t_output_loss: 86.7733 - val_loss: 195.1695 - val_s_output_loss: 116.0832 - val_t_output_loss: 79.0863
Epoch 63/100
 - 13s - loss: 190.4280 - s_output_loss: 116.4287 - t_output_loss: 73.9993 - val_loss: 191.3758 - val_s_output_loss: 114.7807 - val_t_output_loss: 76.5951
Epoch 64/100
 - 13s - loss: 203.8553 - s_output_loss: 135.4960 - t_output_loss: 68.3592 - val_loss: 205.2048 - val_s_output_loss: 136.4266 - val_t_output_loss: 68.7782
Epoch 65/100
 - 13s - loss: 187.6262 - s_output_loss: 120.3520 - t_output_loss: 67.2742 - val_loss: 187.0586 - val_s_output_loss: 116.2301 - val_t_output_loss: 70.8285
Epoch 66/100
 - 13s - loss: 187.6597 - s_output_loss: 117.9989 - t_output_loss: 69.6608 - val_loss: 186.1907 - val_s_output_loss: 113.5508 - val_t_output_loss: 72.6398
Epoch 67/100
 - 13s - loss: 183.5392 - s_output_loss: 117.8389 - t_output_loss: 65.7003 - val_loss: 182.1185 - val_s_output_loss: 113.8417 - val_t_output_loss: 68.2768
Epoch 68/100
 - 13s - loss: 216.2427 - s_output_loss: 137.7883 - t_output_loss: 78.4544 - val_loss: 202.3415 - val_s_output_loss: 123.7524 - val_t_output_loss: 78.5891
Epoch 69/100
 - 13s - loss: 199.5900 - s_output_loss: 130.2857 - t_output_loss: 69.3043 - val_loss: 208.2261 - val_s_output_loss: 124.7344 - val_t_output_loss: 83.4917
Epoch 70/100
 - 13s - loss: 204.6423 - s_output_loss: 120.4512 - t_output_loss: 84.1912 - val_loss: 195.3416 - val_s_output_loss: 117.2140 - val_t_output_loss: 78.1276
Epoch 71/100
 - 13s - loss: 201.3714 - s_output_loss: 126.7616 - t_output_loss: 74.6097 - val_loss: 191.1283 - val_s_output_loss: 117.3954 - val_t_output_loss: 73.7328
Epoch 72/100
 - 13s - loss: 194.6643 - s_output_loss: 118.2649 - t_output_loss: 76.3994 - val_loss: 209.5082 - val_s_output_loss: 115.4578 - val_t_output_loss: 94.0504
Epoch 73/100
 - 14s - loss: 194.2981 - s_output_loss: 122.4075 - t_output_loss: 71.8907 - val_loss: 191.6952 - val_s_output_loss: 120.9856 - val_t_output_loss: 70.7096
Epoch 74/100
 - 13s - loss: 198.0049 - s_output_loss: 126.5070 - t_output_loss: 71.4979 - val_loss: 191.9031 - val_s_output_loss: 119.2564 - val_t_output_loss: 72.6466
Epoch 75/100
 - 13s - loss: 222.3012 - s_output_loss: 118.0584 - t_output_loss: 104.2429 - val_loss: 215.4545 - val_s_output_loss: 116.1151 - val_t_output_loss: 99.3393
Epoch 76/100
 - 13s - loss: 208.7976 - s_output_loss: 116.3629 - t_output_loss: 92.4347 - val_loss: 213.6146 - val_s_output_loss: 113.3298 - val_t_output_loss: 100.2847
Epoch 77/100
 - 13s - loss: 205.2985 - s_output_loss: 114.7520 - t_output_loss: 90.5465 - val_loss: 196.9233 - val_s_output_loss: 112.0624 - val_t_output_loss: 84.8610
Epoch 78/100
 - 13s - loss: 210.1550 - s_output_loss: 125.4238 - t_output_loss: 84.7312 - val_loss: 214.4107 - val_s_output_loss: 118.3967 - val_t_output_loss: 96.0140
Epoch 79/100
 - 13s - loss: 199.5128 - s_output_loss: 118.1420 - t_output_loss: 81.3708 - val_loss: 195.0370 - val_s_output_loss: 116.3408 - val_t_output_loss: 78.6963
Epoch 80/100
 - 13s - loss: 189.2545 - s_output_loss: 115.3951 - t_output_loss: 73.8594 - val_loss: 192.2984 - val_s_output_loss: 112.4852 - val_t_output_loss: 79.8132
Epoch 81/100
 - 14s - loss: 207.8023 - s_output_loss: 117.3951 - t_output_loss: 90.4072 - val_loss: 281.3276 - val_s_output_loss: 195.3938 - val_t_output_loss: 85.9338
Epoch 82/100
 - 14s - loss: 198.2135 - s_output_loss: 122.6844 - t_output_loss: 75.5291 - val_loss: 191.5683 - val_s_output_loss: 115.9570 - val_t_output_loss: 75.6113
Epoch 83/100
 - 14s - loss: 191.4425 - s_output_loss: 115.1665 - t_output_loss: 76.2760 - val_loss: 264.0297 - val_s_output_loss: 186.3659 - val_t_output_loss: 77.6639
Epoch 84/100
 - 13s - loss: 194.8786 - s_output_loss: 121.7901 - t_output_loss: 73.0885 - val_loss: 188.5934 - val_s_output_loss: 115.1519 - val_t_output_loss: 73.4415
Epoch 85/100
 - 13s - loss: 191.2171 - s_output_loss: 118.4599 - t_output_loss: 72.7572 - val_loss: 187.6557 - val_s_output_loss: 113.2061 - val_t_output_loss: 74.4496
Epoch 86/100
 - 13s - loss: 186.9811 - s_output_loss: 113.5487 - t_output_loss: 73.4324 - val_loss: 188.5098 - val_s_output_loss: 112.3169 - val_t_output_loss: 76.1929
Epoch 87/100
 - 13s - loss: 205.4500 - s_output_loss: 135.9931 - t_output_loss: 69.4569 - val_loss: 187.6094 - val_s_output_loss: 116.9977 - val_t_output_loss: 70.6117
Epoch 88/100
 - 13s - loss: 185.3236 - s_output_loss: 117.5749 - t_output_loss: 67.7486 - val_loss: 189.6002 - val_s_output_loss: 118.7396 - val_t_output_loss: 70.8605
Epoch 89/100
 - 13s - loss: 219.5573 - s_output_loss: 152.0949 - t_output_loss: 67.4624 - val_loss: 192.1296 - val_s_output_loss: 122.5858 - val_t_output_loss: 69.5439
Epoch 90/100
 - 13s - loss: 188.3976 - s_output_loss: 119.4914 - t_output_loss: 68.9062 - val_loss: 185.8208 - val_s_output_loss: 116.3263 - val_t_output_loss: 69.4945
Epoch 91/100
 - 13s - loss: 198.0175 - s_output_loss: 117.1569 - t_output_loss: 80.8606 - val_loss: 190.4662 - val_s_output_loss: 115.4976 - val_t_output_loss: 74.9686
Epoch 92/100
 - 13s - loss: 193.9329 - s_output_loss: 124.0914 - t_output_loss: 69.8415 - val_loss: 233.1835 - val_s_output_loss: 162.2856 - val_t_output_loss: 70.8980
Epoch 93/100
 - 13s - loss: 222.9899 - s_output_loss: 149.4251 - t_output_loss: 73.5648 - val_loss: 201.7050 - val_s_output_loss: 128.4055 - val_t_output_loss: 73.2994
Epoch 94/100
 - 13s - loss: 190.6305 - s_output_loss: 123.5530 - t_output_loss: 67.0775 - val_loss: 187.0825 - val_s_output_loss: 118.5120 - val_t_output_loss: 68.5705
Epoch 95/100
 - 13s - loss: 199.4524 - s_output_loss: 131.4791 - t_output_loss: 67.9733 - val_loss: 204.0680 - val_s_output_loss: 118.8361 - val_t_output_loss: 85.2319
Epoch 96/100
 - 13s - loss: 193.9420 - s_output_loss: 122.6929 - t_output_loss: 71.2491 - val_loss: 199.0882 - val_s_output_loss: 121.0655 - val_t_output_loss: 78.0227
Epoch 97/100
 - 13s - loss: 227.6956 - s_output_loss: 160.7453 - t_output_loss: 66.9503 - val_loss: 272.1336 - val_s_output_loss: 189.1278 - val_t_output_loss: 83.0057
Epoch 98/100
 - 13s - loss: 207.3881 - s_output_loss: 139.3259 - t_output_loss: 68.0622 - val_loss: 195.1559 - val_s_output_loss: 126.0143 - val_t_output_loss: 69.1416
Epoch 99/100
 - 13s - loss: 208.1675 - s_output_loss: 126.3368 - t_output_loss: 81.8307 - val_loss: 194.1692 - val_s_output_loss: 120.7373 - val_t_output_loss: 73.4319
Epoch 100/100
 - 13s - loss: 206.1526 - s_output_loss: 134.8667 - t_output_loss: 71.2859 - val_loss: 202.9667 - val_s_output_loss: 126.3405 - val_t_output_loss: 76.6262
variational_ae.py:276: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=Tensor("s_..., outputs=Tensor("mo...)`
  s_enc_cls_model = Model(input=self.s_encoder.input, output=self.classifier(self.s_encoder.output[2]))
variational_ae.py:282: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=Tensor("t_..., outputs=Tensor("mo...)`
  t_enc_cls_model = Model(input=self.t_encoder.input, output=self.classifier(self.t_encoder.output[2]))
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
s_input (InputLayer)            (None, 28, 28, 1)    0                                            
__________________________________________________________________________________________________
conv2d_1 (Conv2D)               (None, 28, 28, 16)   160         s_input[0][0]                    
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 14, 14, 16)   0           conv2d_1[0][0]                   
__________________________________________________________________________________________________
conv2d_2 (Conv2D)               (None, 14, 14, 32)   2080        max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
max_pooling2d_2 (MaxPooling2D)  (None, 7, 7, 32)     0           conv2d_2[0][0]                   
__________________________________________________________________________________________________
flatten_1 (Flatten)             (None, 1568)         0           max_pooling2d_2[0][0]            
__________________________________________________________________________________________________
s_z_mean (Dense)                (None, 10)           15690       flatten_1[0][0]                  
__________________________________________________________________________________________________
s_z_log_var (Dense)             (None, 10)           15690       flatten_1[0][0]                  
__________________________________________________________________________________________________
s_z (Lambda)                    (None, 10)           0           s_z_mean[0][0]                   
                                                                 s_z_log_var[0][0]                
__________________________________________________________________________________________________
model_2 (Model)                 (None, 10)           220         s_z[0][0]                        
==================================================================================================
Total params: 33,840
Trainable params: 33,840
Non-trainable params: 0
__________________________________________________________________________________________________
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
t_input (InputLayer)            (None, 16, 16, 1)    0                                            
__________________________________________________________________________________________________
conv2d_5 (Conv2D)               (None, 16, 16, 16)   160         t_input[0][0]                    
__________________________________________________________________________________________________
max_pooling2d_3 (MaxPooling2D)  (None, 8, 8, 16)     0           conv2d_5[0][0]                   
__________________________________________________________________________________________________
conv2d_6 (Conv2D)               (None, 8, 8, 32)     2080        max_pooling2d_3[0][0]            
__________________________________________________________________________________________________
max_pooling2d_4 (MaxPooling2D)  (None, 4, 4, 32)     0           conv2d_6[0][0]                   
__________________________________________________________________________________________________
flatten_2 (Flatten)             (None, 512)          0           max_pooling2d_4[0][0]            
__________________________________________________________________________________________________
t_z_mean (Dense)                (None, 10)           5130        flatten_2[0][0]                  
__________________________________________________________________________________________________
t_z_log_var (Dense)             (None, 10)           5130        flatten_2[0][0]                  
__________________________________________________________________________________________________
z (Lambda)                      (None, 10)           0           t_z_mean[0][0]                   
                                                                 t_z_log_var[0][0]                
__________________________________________________________________________________________________
model_2 (Model)                 (None, 10)           220         z[0][0]                          
==================================================================================================
Total params: 12,720
Trainable params: 12,720
Non-trainable params: 0
__________________________________________________________________________________________________
